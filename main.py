import json
import time
import hmac
import hashlib
import base64
import os
import asyncio
import uuid
import ssl
import re
from datetime import datetime, timedelta, timezone
from typing import List, Optional, Union, Dict, Any
from dataclasses import dataclass, field
from pathlib import Path
import logging

import httpx
from fastapi import FastAPI, HTTPException, Request, Depends, WebSocket, WebSocketDisconnect  # noqa: F401
from fastapi.responses import StreamingResponse, RedirectResponse
from fastapi.staticfiles import StaticFiles
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel
from sqlalchemy.orm import Session

from database import init_db, get_db, Admin, APIKey, APICallLog
from auth import (
    hash_password, verify_password, create_access_token, 
    generate_api_key, hash_api_key, get_current_admin, init_admin,
    encrypt_api_key, decrypt_api_key
)


# ---------- æœ¬åœ° .env åŠ è½½ï¼ˆä¾¿äºç›´æ¥ python main.py è¿è¡Œï¼‰ ----------
def _load_env_file(path: str = ".env") -> None:
    if not os.path.exists(path):
        return
    try:
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith("#"):
                    continue
                if "=" not in line:
                    continue
                key, value = line.split("=", 1)
                key = key.strip()
                value = value.strip()
                if key and key not in os.environ:
                    os.environ[key] = value
    except Exception:
        # æœ¬åœ°åŠ è½½å¤±è´¥ç›´æ¥å¿½ç•¥ï¼Œä¿æŒä¸åŸç¯å¢ƒä¸€è‡´
        pass


_load_env_file()


# ---------- æ—¥å¿—é…ç½® ----------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger("gemini")

# ---------- æ—¶åŒºé…ç½® ----------
# åŒ—äº¬æ—¶é—´ UTC+8
BEIJING_TZ = timezone(timedelta(hours=8))

def get_beijing_time():
    """è·å–å½“å‰åŒ—äº¬æ—¶é—´"""
    return datetime.now(BEIJING_TZ)

def ensure_aware(dt: datetime) -> datetime:
    """ç¡®ä¿ datetime æ˜¯ awareï¼ˆæœ‰æ—¶åŒºä¿¡æ¯ï¼‰"""
    if dt is None:
        return None
    if dt.tzinfo is None:
        # å¦‚æœæ˜¯ naive datetimeï¼Œå‡è®¾å®ƒæ˜¯åŒ—äº¬æ—¶é—´å¹¶æ·»åŠ æ—¶åŒºä¿¡æ¯
        return dt.replace(tzinfo=BEIJING_TZ)
    return dt

def ensure_naive(dt: datetime) -> datetime:
    """ç¡®ä¿ datetime æ˜¯ naiveï¼ˆæ— æ—¶åŒºä¿¡æ¯ï¼‰ï¼Œè½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´åç§»é™¤æ—¶åŒº"""
    if dt is None:
        return None
    if dt.tzinfo is not None:
        # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´åç§»é™¤æ—¶åŒºä¿¡æ¯
        return dt.astimezone(BEIJING_TZ).replace(tzinfo=None)
    return dt

# ---------- é…ç½® ----------
SECURE_C_SES = os.getenv("SECURE_C_SES")
HOST_C_OSES = os.getenv("HOST_C_OSES")
CSESIDX = os.getenv("CSESIDX")
CONFIG_ID = os.getenv("CONFIG_ID")
PROXY = os.getenv("PROXY") or None
TIMEOUT_SECONDS = int(os.getenv("TIMEOUT_SECONDS", "600"))

# ---------- å›¾ç‰‡ç”Ÿæˆç›¸å…³å¸¸é‡ ----------
BASE_DIR = Path(__file__).resolve().parent
IMAGE_SAVE_DIR = BASE_DIR / "generated_images"
LIST_FILE_METADATA_URL = "https://biz-discoveryengine.googleapis.com/v1alpha/locations/global/widgetListSessionFileMetadata"

# ---------- å›¾ç‰‡æ•°æ®ç±» ----------
@dataclass
class ChatImage:
    """è¡¨ç¤ºç”Ÿæˆçš„å›¾ç‰‡"""
    file_id: Optional[str] = None
    file_name: Optional[str] = None
    base64_data: Optional[str] = None
    url: Optional[str] = None
    local_path: Optional[str] = None
    mime_type: str = "image/png"

    def save_to_file(self, directory: Optional[Path] = None) -> str:
        """ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œè¿”å›æ–‡ä»¶è·¯å¾„"""
        if self.local_path and os.path.exists(self.local_path):
            return self.local_path

        save_dir = directory or IMAGE_SAVE_DIR
        os.makedirs(save_dir, exist_ok=True)

        ext = ".png"
        if self.mime_type:
            ext_map = {
                "image/png": ".png",
                "image/jpeg": ".jpg",
                "image/gif": ".gif",
                "image/webp": ".webp",
            }
            ext = ext_map.get(self.mime_type, ".png")

        if self.file_name:
            filename = self.file_name
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"gemini_{timestamp}_{uuid.uuid4().hex[:8]}{ext}"

        filepath = os.path.join(save_dir, filename)

        if self.base64_data:
            image_data = base64.b64decode(self.base64_data)
            with open(filepath, "wb") as f:
                f.write(image_data)
            self.local_path = filepath

        return filepath

# ---------- æ¨¡å‹æ˜ å°„é…ç½® ----------
MODEL_MAPPING: Dict[str, Optional[str]] = {
    "gemini-auto": None,
    "gemini-2.5-flash": "gemini-2.5-flash",
    "gemini-2.5-pro": "gemini-2.5-pro",
    "gemini-3-pro-preview": "gemini-3-pro-preview"
}

# ---------- å…¨å±€ Session ç¼“å­˜ ----------
# key: conversation_key -> {"session_id": str, "updated_at": float, "account": str}
SESSION_CACHE: Dict[str, Dict[str, Any]] = {}

# ---------- WebSocket ç®¡ç† ----------
class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            try:
                await connection.send_text(message)
            except Exception:
                pass

manager = ConnectionManager()

# ---------- HTTP å®¢æˆ·ç«¯ ----------
http_client = httpx.AsyncClient(
    proxies=PROXY,
    verify=False,
    http2=False,
    timeout=httpx.Timeout(TIMEOUT_SECONDS, connect=60.0),
    limits=httpx.Limits(max_keepalive_connections=20, max_connections=50),
)


# ---------- é€šç”¨å·¥å…·å‡½æ•° ----------
def get_common_headers(jwt: str) -> dict:
    return {
        "accept": "*/*",
        "accept-encoding": "gzip, deflate, br, zstd",
        "accept-language": "zh-CN,zh;q=0.9,en;q=0.8",
        "authorization": f"Bearer {jwt}",
        "content-type": "application/json",
        "origin": "https://business.gemini.google",
        "referer": "https://business.gemini.google/",
        "user-agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/140.0.0.0 Safari/537.36"
        ),
        "x-server-timeout": "1800",
        "sec-ch-ua": '"Chromium";v="124", "Google Chrome";v="124", "Not-A.Brand";v="99"',
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": '"Windows"',
        "sec-fetch-dest": "empty",
        "sec-fetch-mode": "cors",
        "sec-fetch-site": "cross-site",
    }


def urlsafe_b64encode(data: bytes) -> str:
    return base64.urlsafe_b64encode(data).decode().rstrip("=")


def kq_encode(s: str) -> str:
    b = bytearray()
    for ch in s:
        v = ord(ch)
        if v > 255:
            b.append(v & 255)
            b.append(v >> 8)
        else:
            b.append(v)
    return urlsafe_b64encode(bytes(b))


def create_jwt(key_bytes: bytes, key_id: str, csesidx: str) -> str:
    now = int(time.time())
    header = {"alg": "HS256", "typ": "JWT", "kid": key_id}
    payload = {
        "iss": "https://business.gemini.google",
        "aud": "https://biz-discoveryengine.googleapis.com",
        "sub": f"csesidx/{csesidx}",
        "iat": now,
        "exp": now + 300,
        "nbf": now,
    }
    header_b64 = kq_encode(json.dumps(header, separators=(",", ":")))
    payload_b64 = kq_encode(json.dumps(payload, separators=(",", ":")))
    message = f"{header_b64}.{payload_b64}"
    sig = hmac.new(key_bytes, message.encode(), hashlib.sha256).digest()
    return f"{message}.{urlsafe_b64encode(sig)}"


# ---------- JWT ä¸è´¦å·ç®¡ç† ----------
class JWTManager:
    def __init__(self, account: "Account") -> None:
        self.account = account
        self.jwt: str = ""
        self.expires: float = 0
        self._lock = asyncio.Lock()

    async def get(self) -> str:
        async with self._lock:
            if time.time() > self.expires:
                await self._refresh()
            return self.jwt

    async def _refresh(self) -> None:
        cookie = f"__Secure-C_SES={self.account.secure_c_ses}"
        if self.account.host_c_oses:
            cookie += f"; __Host-C_OSES={self.account.host_c_oses}"

        logger.debug(f"ğŸ”‘ æ­£åœ¨åˆ·æ–° JWT... è´¦å·={self.account.name}")
        r = await http_client.get(
            "https://business.gemini.google/auth/getoxsrf",
            params={"csesidx": self.account.csesidx},
            headers={
                "cookie": cookie,
                "user-agent": (
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 (KHTML, like Gecko) "
                    "Chrome/140.0.0.0 Safari/537.36"
                ),
                "referer": "https://business.gemini.google/",
            },
        )
        if r.status_code != 200:
            logger.error(
                f"getoxsrf å¤±è´¥ [{self.account.name}]: {r.status_code} {r.text}"
            )
            if r.status_code in (401, 403, 429):
                self.account.mark_quota_error(r.status_code, r.text)
            raise HTTPException(r.status_code, "getoxsrf failed")

        txt = r.text[4:] if r.text.startswith(")]}'") else r.text
        data = json.loads(txt)

        key_bytes = base64.urlsafe_b64decode(data["xsrfToken"] + "==")
        self.jwt = create_jwt(key_bytes, data["keyId"], self.account.csesidx)
        self.expires = time.time() + 270
        logger.info(f"JWT åˆ·æ–°æˆåŠŸ [{self.account.name}]")


class Account:
    def __init__(
        self,
        name: str,
        secure_c_ses: str,
        csesidx: str,
        config_id: str,
        host_c_oses: Optional[str] = None,
    ) -> None:
        self.name = name
        self.secure_c_ses = secure_c_ses
        self.host_c_oses = host_c_oses
        self.csesidx = csesidx
        self.config_id = config_id
        self.jwt_mgr = JWTManager(self)
        self.disabled_until: float = 0.0

    def is_available(self) -> bool:
        return time.time() >= self.disabled_until

    def mark_quota_error(self, status_code: int, detail: str = "") -> None:
        cooldown_seconds = 300  # æš‚åœ 5 åˆ†é’Ÿ
        self.disabled_until = max(self.disabled_until, time.time() + cooldown_seconds)
        logger.warning(f"è´¦å·[{self.name}] æš‚æ—¶æ ‡è®°ä¸ºä¸å¯ç”¨ (status={status_code})")
        if detail:
            logger.debug(f"è´¦å·[{self.name}] é”™è¯¯è¯¦æƒ…: {detail[:200]}")


class AccountPool:
    def __init__(self, accounts: List[Account]) -> None:
        if not accounts:
            raise RuntimeError("No Gemini business accounts configured")
        self.accounts = accounts
        self._rr_index = 0

    def _next_round_robin(self) -> Account:
        n = len(self.accounts)
        for _ in range(n):
            acc = self.accounts[self._rr_index % n]
            self._rr_index = (self._rr_index + 1) % n
            if acc.is_available():
                return acc
        # å¦‚æœéƒ½è¢«æ ‡è®°ä¸ºä¸å¯ç”¨ï¼Œä»ç„¶è¿”å›ä¸€ä¸ªè´¦å·é¿å…å®Œå…¨ç˜«ç—ª
        return self.accounts[0]

    def get_for_conversation(self, conv_key: str) -> Account:
        cached = SESSION_CACHE.get(conv_key)
        if cached:
            acc_name = cached.get("account")
            for acc in self.accounts:
                if acc.name == acc_name and acc.is_available():
                    return acc
        # æ²¡æœ‰ç¼“å­˜æˆ–è´¦å·ä¸å¯ç”¨ï¼Œèµ°è½®è¯¢
        return self._next_round_robin()

    def get_alternative(self, exclude_name: str) -> Optional[Account]:
        for acc in self.accounts:
            if acc.name != exclude_name and acc.is_available():
                return acc
        return None


def load_accounts_from_env() -> List[Account]:
    accounts: List[Account] = []

    # æ”¯æŒ ACCOUNT1_*, ACCOUNT2_*... å¤šè´¦å·é…ç½®
    account_indices = set()
    for key in os.environ.keys():
        if key.startswith("ACCOUNT") and key.endswith("_SECURE_C_SES"):
            idx_str = key[len("ACCOUNT") : -len("_SECURE_C_SES")]
            try:
                idx = int(idx_str)
            except ValueError:
                continue
            account_indices.add(idx)

    for idx in sorted(account_indices):
        prefix = f"ACCOUNT{idx}_"
        secure = os.getenv(prefix + "SECURE_C_SES")
        csesidx = os.getenv(prefix + "CSESIDX")
        config_id = os.getenv(prefix + "CONFIG_ID")
        host = os.getenv(prefix + "HOST_C_OSES")
        if not (secure and csesidx and config_id):
            logger.warning(f"è´¦å·ç´¢å¼• {idx} é…ç½®ä¸å®Œæ•´ï¼Œå·²è·³è¿‡")
            continue
        name = os.getenv(prefix + "NAME") or f"account-{idx}"
        accounts.append(
            Account(
                name=name,
                secure_c_ses=secure,
                csesidx=csesidx,
                config_id=config_id,
                host_c_oses=host,
            )
        )

    # å…¼å®¹æ—§çš„å•è´¦å·ç¯å¢ƒå˜é‡
    if not accounts and SECURE_C_SES and CSESIDX and CONFIG_ID:
        accounts.append(
            Account(
                name="default",
                secure_c_ses=SECURE_C_SES,
                csesidx=CSESIDX,
                config_id=CONFIG_ID,
                host_c_oses=HOST_C_OSES,
            )
        )

    return accounts


ACCOUNTS: List[Account] = load_accounts_from_env()
ACCOUNT_POOL: Optional["AccountPool"]
if ACCOUNTS:
    ACCOUNT_POOL = AccountPool(ACCOUNTS)
else:
    ACCOUNT_POOL = None


def reload_accounts_from_env_file() -> None:
    """ä» .env æ–‡ä»¶é‡æ–°åŠ è½½è´¦å·é…ç½®ï¼ˆåŠ¨æ€é‡è½½ï¼Œæ— éœ€é‡å¯ï¼‰"""
    global ACCOUNTS, ACCOUNT_POOL
    
    # é‡æ–°è¯»å– .env æ–‡ä»¶å¹¶æ›´æ–°ç¯å¢ƒå˜é‡
    lines = read_env_file()
    for line_data in lines:
        line = line_data["raw"].strip()
        if not line or line.startswith("#") or "=" not in line:
            continue
        key, value = line.split("=", 1)
        key = key.strip()
        value = value.strip().strip('"').strip("'")
        # æ›´æ–°ç¯å¢ƒå˜é‡
        os.environ[key] = value
    
    # é‡æ–°åŠ è½½è´¦å·
    ACCOUNTS = load_accounts_from_env()
    
    # é‡æ–°åˆ›å»ºè´¦å·æ± 
    if ACCOUNTS:
        ACCOUNT_POOL = AccountPool(ACCOUNTS)
        logger.info(f"ğŸ”„ è´¦å·é…ç½®å·²é‡æ–°åŠ è½½ï¼Œå…± {len(ACCOUNTS)} ä¸ªè´¦å·")
    else:
        ACCOUNT_POOL = None
        logger.warning("âš ï¸ é‡æ–°åŠ è½½åæ²¡æœ‰å¯ç”¨è´¦å·")


# ---------- Session & File ç®¡ç† ----------
async def create_google_session(account: Account) -> str:
    jwt = await account.jwt_mgr.get()
    headers = get_common_headers(jwt)
    body = {
        "configId": account.config_id,
        "additionalParams": {"token": "-"},
        "createSessionRequest": {"session": {"name": "", "displayName": ""}},
    }

    logger.debug(f"ğŸŒ ç”³è¯· Session... è´¦å·={account.name}")
    r = await http_client.post(
        "https://biz-discoveryengine.googleapis.com/v1alpha/locations/global/widgetCreateSession",
        headers=headers,
        json=body,
    )
    if r.status_code != 200:
        logger.error(
            f"createSession å¤±è´¥ [{account.name}]: {r.status_code} {r.text}"
        )
        if r.status_code in (401, 403, 429):
            account.mark_quota_error(r.status_code, r.text)
        raise HTTPException(r.status_code, "createSession failed")
    sess_name = r.json()["session"]["name"]
    return sess_name


async def upload_context_file(
    account: Account, session_name: str, mime_type: str, base64_content: str
) -> str:
    """ä¸Šä¼ æ–‡ä»¶åˆ°æŒ‡å®š Sessionï¼Œè¿”å› fileId"""
    jwt = await account.jwt_mgr.get()
    headers = get_common_headers(jwt)

    ext = mime_type.split("/")[-1] if "/" in mime_type else "bin"
    file_name = f"upload_{int(time.time())}_{uuid.uuid4().hex[:6]}.{ext}"

    body = {
        "configId": account.config_id,
        "additionalParams": {"token": "-"},
        "addContextFileRequest": {
            "name": session_name,
            "fileName": file_name,
            "mimeType": mime_type,
            "fileContents": base64_content,
        },
    }

    logger.info(f"ğŸ“¤ ä¸Šä¼ å›¾ç‰‡ [{mime_type}] åˆ° Sessionï¼Œè´¦å·={account.name}")
    r = await http_client.post(
        "https://biz-discoveryengine.googleapis.com/v1alpha/locations/global/widgetAddContextFile",
        headers=headers,
        json=body,
    )

    if r.status_code != 200:
        logger.error(
            f"ä¸Šä¼ æ–‡ä»¶å¤±è´¥ [{account.name}]: {r.status_code} {r.text}"
        )
        if r.status_code in (401, 403, 429):
            account.mark_quota_error(r.status_code, r.text)
        raise HTTPException(r.status_code, f"Upload failed: {r.text}")

    data = r.json()
    file_id = data.get("addContextFileResponse", {}).get("fileId")
    logger.info(f"å›¾ç‰‡ä¸Šä¼ æˆåŠŸ, ID: {file_id}, è´¦å·={account.name}")
    return file_id


# ---------- æ¶ˆæ¯å¤„ç†é€»è¾‘ ----------
def get_conversation_key(messages: List[dict]) -> str:
    if not messages:
        return "empty"
    first_msg = messages[0].copy()
    if isinstance(first_msg.get("content"), list):
        text_part = "".join(
            [x.get("text", "") for x in first_msg["content"] if x.get("type") == "text"]
        )
        first_msg["content"] = text_part

    key_str = json.dumps(first_msg, sort_keys=True, ensure_ascii=False)
    return hashlib.md5(key_str.encode("utf-8")).hexdigest()


def parse_last_message(messages: List["Message"]):
    """è§£ææœ€åä¸€æ¡æ¶ˆæ¯ï¼Œåˆ†ç¦»æ–‡æœ¬å’Œå›¾ç‰‡"""
    if not messages:
        return "", []

    last_msg = messages[-1]
    content = last_msg.content

    text_content = ""
    images = []  # List of {"mime": str, "data": str_base64}

    if isinstance(content, str):
        text_content = content
    elif isinstance(content, list):
        for part in content:
            if part.get("type") == "text":
                text_content += part.get("text", "")
            elif part.get("type") == "image_url":
                url = part.get("image_url", {}).get("url", "")
                match = re.match(r"data:(image/[^;]+);base64,(.+)", url)
                if match:
                    images.append(
                        {"mime": match.group(1), "data": match.group(2)}
                    )
                else:
                    logger.warning(
                        f"æš‚ä¸æ”¯æŒé Base64 å›¾ç‰‡é“¾æ¥: {url[:30]}..."
                    )

    return text_content, images


def build_full_context_text(messages: List["Message"]) -> str:
    """ä»…æ‹¼æ¥å†å²æ–‡æœ¬ï¼Œå›¾ç‰‡åªå¤„ç†å½“æ¬¡è¯·æ±‚çš„"""
    prompt = ""
    for msg in messages:
        role = "User" if msg.role in ["user", "system"] else "Assistant"
        content_str = ""
        if isinstance(msg.content, str):
            content_str = msg.content
        elif isinstance(msg.content, list):
            for part in msg.content:
                if part.get("type") == "text":
                    content_str += part.get("text", "")
                elif part.get("type") == "image_url":
                    content_str += "[å›¾ç‰‡]"

        prompt += f"{role}: {content_str}\n\n"
    return prompt


# ---------- å›¾ç‰‡ç”Ÿæˆå¤„ç†æ–¹æ³• ----------
async def get_session_file_metadata(account: Account, session_name: str) -> dict:
    """è·å– session ä¸­çš„æ–‡ä»¶å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬ä¸‹è½½é“¾æ¥"""
    jwt = await account.jwt_mgr.get()
    headers = get_common_headers(jwt)
    body = {
        "configId": account.config_id,
        "additionalParams": {"token": "-"},
        "listSessionFileMetadataRequest": {
            "name": session_name,
            "filter": "file_origin_type = AI_GENERATED"
        }
    }

    async with httpx.AsyncClient(proxy=PROXY, verify=False, timeout=30) as cli:
        resp = await cli.post(LIST_FILE_METADATA_URL, headers=headers, json=body)

        if resp.status_code == 401:
            # JWT è¿‡æœŸï¼Œåˆ·æ–°åé‡è¯•
            jwt = await account.jwt_mgr.get()
            headers = get_common_headers(jwt)
            resp = await cli.post(LIST_FILE_METADATA_URL, headers=headers, json=body)

        if resp.status_code != 200:
            logger.warning(f"è·å–æ–‡ä»¶å…ƒæ•°æ®å¤±è´¥ [{account.name}]: {resp.status_code}")
            return {}

        data = resp.json()
        result = {}
        file_metadata_list = data.get("listSessionFileMetadataResponse", {}).get("fileMetadata", [])
        for fm in file_metadata_list:
            fid = fm.get("fileId")
            if fid:
                result[fid] = fm

        return result


def build_image_download_url(session_name: str, file_id: str) -> str:
    """æ„é€ æ­£ç¡®çš„å›¾ç‰‡ä¸‹è½½ URL"""
    return f"https://biz-discoveryengine.googleapis.com/v1alpha/{session_name}:downloadFile?fileId={file_id}&alt=media"


async def download_image_with_jwt(account: Account, session_name: str, file_id: str) -> bytes:
    """ä½¿ç”¨ JWT è®¤è¯ä¸‹è½½å›¾ç‰‡"""
    url = build_image_download_url(session_name, file_id)
    jwt = await account.jwt_mgr.get()
    headers = get_common_headers(jwt)

    async with httpx.AsyncClient(proxy=PROXY, verify=False, timeout=120) as cli:
        resp = await cli.get(url, headers=headers, follow_redirects=True)

        if resp.status_code == 401:
            # JWT è¿‡æœŸï¼Œåˆ·æ–°åé‡è¯•
            jwt = await account.jwt_mgr.get()
            headers = get_common_headers(jwt)
            resp = await cli.get(url, headers=headers, follow_redirects=True)

        resp.raise_for_status()
        content = resp.content

        # æ£€æµ‹æ˜¯å¦ä¸º base64 ç¼–ç çš„å†…å®¹
        try:
            text_content = content.decode("utf-8", errors="ignore").strip()
            if text_content.startswith("iVBORw0KGgo") or text_content.startswith("/9j/"):
                # æ˜¯ base64 ç¼–ç ï¼Œéœ€è¦è§£ç 
                return base64.b64decode(text_content)
        except Exception:
            pass

        return content


async def save_generated_image(account: Account, session_name: str, file_id: str, file_name: Optional[str], mime_type: str, chat_id: str, image_index: int = 1) -> ChatImage:
    """ä¸‹è½½å¹¶ä¿å­˜ç”Ÿæˆçš„å›¾ç‰‡ï¼ŒæŒ‰ chat_id å‘½å"""
    img = ChatImage(
        file_id=file_id,
        file_name=file_name,
        mime_type=mime_type,
    )

    try:
        image_data = await download_image_with_jwt(account, session_name, file_id)
        os.makedirs(IMAGE_SAVE_DIR, exist_ok=True)

        ext = ".png"
        ext_map = {"image/png": ".png", "image/jpeg": ".jpg", "image/gif": ".gif", "image/webp": ".webp"}
        ext = ext_map.get(mime_type, ".png")

        # æŒ‰ {chat_id}_{åºå·}.png å‘½å
        filename = f"{chat_id}_{image_index}{ext}"
        filepath = IMAGE_SAVE_DIR / filename

        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³é¿å…è¦†ç›–
        if filepath.exists():
            timestamp = datetime.now().strftime("%H%M%S")
            filename = f"{chat_id}_{image_index}_{timestamp}{ext}"
            filepath = IMAGE_SAVE_DIR / filename

        with open(filepath, "wb") as f:
            f.write(image_data)

        img.local_path = str(filepath)
        img.file_name = filename
        img.base64_data = base64.b64encode(image_data).decode("utf-8")
        logger.info(f"å›¾ç‰‡å·²ä¿å­˜ [{account.name}]: {filepath}")
    except Exception as e:
        logger.error(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥ [{account.name}]: {e}")

    return img


def parse_images_from_response(data_list: list) -> tuple[list, Optional[str]]:
    """
    ä» API å“åº”ä¸­è§£æå›¾ç‰‡æ–‡ä»¶å¼•ç”¨
    è¿”å›: (file_ids_list, current_session)
    file_ids_list: [{"fileId": str, "mimeType": str}, ...]
    """
    file_ids = []
    current_session = None

    for data in data_list:
        sar = data.get("streamAssistResponse")
        if not sar:
            continue

        # è·å– session ä¿¡æ¯
        session_info = sar.get("sessionInfo", {})
        if session_info.get("session"):
            current_session = session_info["session"]

        answer = sar.get("answer") or {}
        replies = answer.get("replies") or []

        for reply in replies:
            gc = reply.get("groundedContent", {})
            content = gc.get("content", {})

            # æ£€æŸ¥ file å­—æ®µï¼ˆå›¾ç‰‡ç”Ÿæˆçš„å…³é”®ï¼‰
            file_info = content.get("file")
            if file_info and file_info.get("fileId"):
                file_ids.append({
                    "fileId": file_info["fileId"],
                    "mimeType": file_info.get("mimeType", "image/png")
                })

    return file_ids, current_session


# ---------- OpenAI å…¼å®¹æ¥å£ ----------
app = FastAPI(title="Gemini-Business OpenAI Gateway")

# æŒ‚è½½é™æ€æ–‡ä»¶
app.mount("/static", StaticFiles(directory="static"), name="static")

security_bearer = HTTPBearer()


class Message(BaseModel):
    role: str
    content: Union[str, List[Dict[str, Any]]]


class ChatRequest(BaseModel):
    model: str = "gemini-auto"
    messages: List[Message]
    stream: bool = True
    temperature: Optional[float] = 0.7
    top_p: Optional[float] = 1.0


def create_chunk(
    id: str, created: int, model: str, delta: dict, finish_reason: Optional[str]
) -> str:
    chunk = {
        "id": id,
        "object": "chat.completion.chunk",
        "created": created,
        "model": model,
        "choices": [
            {
                "index": 0,
                "delta": delta,
                "finish_reason": finish_reason,
            }
        ],
    }
    return json.dumps(chunk, ensure_ascii=False)


@app.get("/v1/models")
async def list_models():
    data = []
    now = int(time.time())
    for m in MODEL_MAPPING.keys():
        data.append(
            {
                "id": m,
                "object": "model",
                "created": now,
                "owned_by": "google",
                "permission": [],
            }
        )
    return {"object": "list", "data": data}


@app.get("/health")
async def health():
    return {"status": "ok", "time": get_beijing_time().isoformat()}


@app.get("/")
async def root():
    """é‡å®šå‘åˆ°ç™»å½•é¡µé¢"""
    return RedirectResponse(url="/static/index.html")


@app.websocket("/ws/admin/events")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    try:
        while True:
            await websocket.receive_text()
    except WebSocketDisconnect:
        manager.disconnect(websocket)


# ---------- ç®¡ç†å‘˜è®¤è¯æ¥å£ ----------
class LoginRequest(BaseModel):
    username: str
    password: str


class LoginResponse(BaseModel):
    access_token: str
    token_type: str = "bearer"


class ChangePasswordRequest(BaseModel):
    old_password: str
    new_password: str


class ChangeUsernameRequest(BaseModel):
    new_username: str
    password: str  # éœ€è¦éªŒè¯å¯†ç æ‰èƒ½ä¿®æ”¹ç”¨æˆ·å


@app.post("/admin/login", response_model=LoginResponse)
async def admin_login(req: LoginRequest, db: Session = Depends(get_db)):
    """ç®¡ç†å‘˜ç™»å½•"""
    admin = db.query(Admin).filter(Admin.username == req.username).first()
    
    if not admin or not verify_password(req.password, admin.hashed_password):
        raise HTTPException(
            status_code=401,
            detail="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯"
        )
    
    access_token = create_access_token({"sub": admin.username})
    return LoginResponse(access_token=access_token)


@app.put("/admin/change-password")
async def change_password(
    req: ChangePasswordRequest,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """ä¿®æ”¹ç®¡ç†å‘˜å¯†ç """
    # éªŒè¯æ—§å¯†ç 
    if not verify_password(req.old_password, admin.hashed_password):
        raise HTTPException(
            status_code=400,
            detail="æ—§å¯†ç é”™è¯¯"
        )
    
    # éªŒè¯æ–°å¯†ç é•¿åº¦
    if len(req.new_password) < 6:
        raise HTTPException(
            status_code=400,
            detail="æ–°å¯†ç é•¿åº¦è‡³å°‘ä¸º 6 ä½"
        )
    
    # æ›´æ–°å¯†ç 
    admin.hashed_password = hash_password(req.new_password)
    db.commit()
    
    logger.info(f"âœ… ç®¡ç†å‘˜ {admin.username} ä¿®æ”¹äº†å¯†ç ")
    
    return {"message": "å¯†ç ä¿®æ”¹æˆåŠŸ"}


@app.put("/admin/change-username")
async def change_username(
    req: ChangeUsernameRequest,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """ä¿®æ”¹ç®¡ç†å‘˜ç”¨æˆ·å"""
    # éªŒè¯å¯†ç 
    if not verify_password(req.password, admin.hashed_password):
        raise HTTPException(
            status_code=400,
            detail="å¯†ç é”™è¯¯"
        )
    
    # éªŒè¯æ–°ç”¨æˆ·å
    if not req.new_username or len(req.new_username.strip()) == 0:
        raise HTTPException(
            status_code=400,
            detail="ç”¨æˆ·åä¸èƒ½ä¸ºç©º"
        )
    
    if len(req.new_username) > 50:
        raise HTTPException(
            status_code=400,
            detail="ç”¨æˆ·åé•¿åº¦ä¸èƒ½è¶…è¿‡ 50 ä¸ªå­—ç¬¦"
        )
    
    # æ£€æŸ¥æ–°ç”¨æˆ·åæ˜¯å¦å·²å­˜åœ¨
    existing_admin = db.query(Admin).filter(Admin.username == req.new_username.strip()).first()
    if existing_admin and existing_admin.id != admin.id:
        raise HTTPException(
            status_code=400,
            detail="ç”¨æˆ·åå·²å­˜åœ¨"
        )
    
    old_username = admin.username
    # æ›´æ–°ç”¨æˆ·å
    admin.username = req.new_username.strip()
    db.commit()
    
    logger.info(f"âœ… ç®¡ç†å‘˜ {old_username} å°†ç”¨æˆ·åä¿®æ”¹ä¸º {admin.username}")
    
    return {"message": "ç”¨æˆ·åä¿®æ”¹æˆåŠŸ", "new_username": admin.username}


# ---------- API å¯†é’¥ç®¡ç†æ¥å£ ----------
class GenerateKeysRequest(BaseModel):
    count: int = 1
    expires_days: int = 30
    name_prefix: str = "API Key"


class APIKeyResponse(BaseModel):
    id: int
    key: Optional[str] = None  # ä»…åœ¨ç”Ÿæˆæ—¶è¿”å›æ˜æ–‡
    name: str
    created_at: datetime
    expires_at: datetime
    is_active: bool
    usage_count: int
    last_used_at: Optional[datetime]


@app.post("/admin/api-keys", response_model=List[APIKeyResponse])
async def generate_api_keys(
    req: GenerateKeysRequest,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """æ‰¹é‡ç”Ÿæˆ API å¯†é’¥"""
    if req.count < 1 or req.count > 100:
        raise HTTPException(status_code=400, detail="æ•°é‡å¿…é¡»åœ¨ 1-100 ä¹‹é—´")
    
    if req.expires_days < 1 or req.expires_days > 3650:
        raise HTTPException(status_code=400, detail="æœ‰æ•ˆæœŸå¿…é¡»åœ¨ 1-3650 å¤©ä¹‹é—´")
    
    keys = []
    # å­˜å‚¨æ—¶ä½¿ç”¨ naive datetimeï¼ˆæ•°æ®åº“å…¼å®¹ï¼‰
    expires_at = ensure_naive(get_beijing_time() + timedelta(days=req.expires_days))
    
    for i in range(req.count):
        # ç”Ÿæˆ UUID æ ¼å¼å¯†é’¥
        plain_key = generate_api_key()
        key_hash = hash_api_key(plain_key)
        encrypted = encrypt_api_key(plain_key)  # åŠ å¯†å­˜å‚¨
        
        name = f"{req.name_prefix} #{i+1}" if req.count > 1 else req.name_prefix
        
        api_key = APIKey(
            key_hash=key_hash,
            encrypted_key=encrypted,  # å­˜å‚¨åŠ å¯†åçš„å¯†é’¥
            name=name,
            expires_at=expires_at,
            is_active=True
        )
        db.add(api_key)
        db.commit()
        db.refresh(api_key)
        
        keys.append(APIKeyResponse(
            id=api_key.id,
            key=plain_key,  # ä»…åœ¨ç”Ÿæˆæ—¶è¿”å›æ˜æ–‡
            name=api_key.name,
            created_at=api_key.created_at,
            expires_at=api_key.expires_at,
            is_active=api_key.is_active,
            usage_count=api_key.usage_count,
            last_used_at=api_key.last_used_at
        ))
    
    return keys


@app.get("/admin/api-keys", response_model=List[APIKeyResponse])
async def list_api_keys(
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """åˆ—å‡ºæ‰€æœ‰ API å¯†é’¥ï¼ˆä»…æ˜¾ç¤ºæ´»è·ƒçš„ï¼‰"""
    # æŒ‰åˆ›å»ºæ—¶é—´å‡åºæ’åˆ—ï¼ˆæœ€è€çš„åœ¨å‰ï¼‰
    keys = db.query(APIKey).filter(APIKey.is_active == True).order_by(APIKey.created_at.asc()).all()
    return [
        APIKeyResponse(
            id=k.id,
            name=k.name,
            created_at=k.created_at,
            expires_at=k.expires_at,
            is_active=k.is_active,
            usage_count=k.usage_count,
            last_used_at=k.last_used_at
        )
        for k in keys
    ]


@app.delete("/admin/api-keys/{key_id}")
async def revoke_api_key(
    key_id: int,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """æ’¤é”€ API å¯†é’¥"""
    api_key = db.query(APIKey).filter(APIKey.id == key_id).first()
    if not api_key:
        raise HTTPException(status_code=404, detail="å¯†é’¥ä¸å­˜åœ¨")
    
    api_key.is_active = False
    db.commit()
    return {"message": "å¯†é’¥å·²æ’¤é”€"}


@app.get("/admin/api-keys/{key_id}/view")
async def view_api_key(
    key_id: int,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """æŸ¥çœ‹ API å¯†é’¥æ˜æ–‡"""
    api_key = db.query(APIKey).filter(APIKey.id == key_id).first()
    if not api_key:
        raise HTTPException(status_code=404, detail="å¯†é’¥ä¸å­˜åœ¨")
    
    try:
        decrypted_key = decrypt_api_key(api_key.encrypted_key)
        return {"key": decrypted_key}
    except Exception as e:
        logger.error(f"Failed to decrypt key: {e}")
        raise HTTPException(status_code=500, detail="è§£å¯†å¤±è´¥")


@app.get("/admin/stats")
async def get_stats(
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """è·å–ç»Ÿè®¡ä¿¡æ¯"""
    from sqlalchemy import func
    
    total_keys = db.query(APIKey).count()
    # è·å–å½“å‰åŒ—äº¬æ—¶é—´ï¼ˆnaive æ ¼å¼ç”¨äºæ•°æ®åº“æ¯”è¾ƒï¼‰
    now_naive = get_beijing_time().replace(tzinfo=None)
    active_keys = db.query(APIKey).filter(
        APIKey.is_active == True,
        APIKey.expires_at > now_naive
    ).count()
    total_usage = db.query(func.sum(APIKey.usage_count)).filter(
        APIKey.is_active == True
    ).scalar() or 0
    
    return {
        "total_keys": total_keys,
        "active_keys": active_keys,
        "total_usage": total_usage
    }


@app.get("/admin/api-keys/{key_id}/logs")
async def get_api_key_logs(
    key_id: int,
    page: int = 1,
    page_size: int = 50,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """è·å–æŒ‡å®š API å¯†é’¥çš„è°ƒç”¨æ—¥å¿—"""
    # éªŒè¯å¯†é’¥æ˜¯å¦å­˜åœ¨
    api_key = db.query(APIKey).filter(APIKey.id == key_id).first()
    if not api_key:
        raise HTTPException(status_code=404, detail="å¯†é’¥ä¸å­˜åœ¨")
    
    # æŸ¥è¯¢æ—¥å¿—
    offset = (page - 1) * page_size
    logs = db.query(APICallLog).filter(
        APICallLog.api_key_id == key_id
    ).order_by(
        APICallLog.timestamp.desc()
    ).offset(offset).limit(page_size).all()
    
    # è·å–æ€»æ•°
    total = db.query(APICallLog).filter(APICallLog.api_key_id == key_id).count()
    
    return {
        "key_id": key_id,
        "key_name": api_key.name,
        "total": total,
        "page": page,
        "page_size": page_size,
        "logs": [
            {
                "id": log.id,
                "timestamp": log.timestamp.isoformat(),
                "model": log.model,
                "status": log.status,
                "error_message": log.error_message,
                "ip_address": log.ip_address,
                "endpoint": log.endpoint,
                "response_time": log.response_time
            }
            for log in logs
        ]
    }


@app.get("/admin/api-keys/{key_id}/stats")
async def get_api_key_stats(
    key_id: int,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """è·å–æŒ‡å®š API å¯†é’¥çš„ç»Ÿè®¡ä¿¡æ¯"""
    from sqlalchemy import func
    
    # éªŒè¯å¯†é’¥æ˜¯å¦å­˜åœ¨
    api_key = db.query(APIKey).filter(APIKey.id == key_id).first()
    if not api_key:
        raise HTTPException(status_code=404, detail="å¯†é’¥ä¸å­˜åœ¨")
    
    # æ€»è°ƒç”¨æ¬¡æ•°
    total_calls = db.query(APICallLog).filter(APICallLog.api_key_id == key_id).count()
    
    # æˆåŠŸ/å¤±è´¥ç»Ÿè®¡
    success_calls = db.query(APICallLog).filter(
        APICallLog.api_key_id == key_id,
        APICallLog.status == "success"
    ).count()
    
    error_calls = db.query(APICallLog).filter(
        APICallLog.api_key_id == key_id,
        APICallLog.status == "error"
    ).count()
    
    # æŒ‰æ¨¡å‹ç»Ÿè®¡
    model_stats = db.query(
        APICallLog.model,
        func.count(APICallLog.id).label("count")
    ).filter(
        APICallLog.api_key_id == key_id
    ).group_by(APICallLog.model).all()
    
    # å¹³å‡å“åº”æ—¶é—´
    avg_response_time = db.query(
        func.avg(APICallLog.response_time)
    ).filter(
        APICallLog.api_key_id == key_id,
        APICallLog.response_time.isnot(None)
    ).scalar() or 0
    
    # æœ€è¿‘ 7 å¤©çš„è°ƒç”¨è¶‹åŠ¿ï¼ˆä½¿ç”¨ naive datetime ç”¨äºæ•°æ®åº“æŸ¥è¯¢ï¼‰
    seven_days_ago = ensure_naive(get_beijing_time() - timedelta(days=7))
    
    daily_stats = db.query(
        func.date(APICallLog.timestamp).label("date"),
        func.count(APICallLog.id).label("count")
    ).filter(
        APICallLog.api_key_id == key_id,
        APICallLog.timestamp >= seven_days_ago
    ).group_by(
        func.date(APICallLog.timestamp)
    ).order_by(
        func.date(APICallLog.timestamp)
    ).all()
    
    return {
        "key_id": key_id,
        "key_name": api_key.name,
        "total_calls": total_calls,
        "success_calls": success_calls,
        "error_calls": error_calls,
        "success_rate": round(success_calls / total_calls * 100, 2) if total_calls > 0 else 0,
        "avg_response_time": round(avg_response_time, 2),
        "model_stats": [
            {"model": m[0], "count": m[1]}
            for m in model_stats
        ],
        "daily_stats": [
            {"date": str(d[0]), "count": d[1]}
            for d in daily_stats
        ]
    }


# ---------- è´¦å·ç®¡ç†æ¥å£ ----------
def read_env_file() -> List[Dict[str, str]]:
    """è¯»å– .env æ–‡ä»¶ï¼Œè¿”å›æ‰€æœ‰è¡Œï¼ˆåŒ…æ‹¬æ³¨é‡Šå’Œç©ºè¡Œï¼‰"""
    env_path = ".env"
    if not os.path.exists(env_path):
        return []
    
    lines = []
    try:
        with open(env_path, "r", encoding="utf-8") as f:
            for line in f:
                lines.append({"raw": line.rstrip("\n\r"), "type": "line"})
    except Exception as e:
        logger.error(f"è¯»å– .env æ–‡ä»¶å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è¯»å– .env æ–‡ä»¶å¤±è´¥: {e}")
    
    return lines


def write_env_file(lines: List[Dict[str, str]]) -> None:
    """å†™å…¥ .env æ–‡ä»¶"""
    env_path = ".env"
    try:
        with open(env_path, "w", encoding="utf-8") as f:
            for line_data in lines:
                f.write(line_data["raw"] + "\n")
    except Exception as e:
        logger.error(f"å†™å…¥ .env æ–‡ä»¶å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å†™å…¥ .env æ–‡ä»¶å¤±è´¥: {e}")


def parse_accounts_from_env_lines(lines: List[Dict[str, str]]) -> List[Dict[str, Any]]:
    """ä» .env æ–‡ä»¶è¡Œä¸­è§£æè´¦å·é…ç½®"""
    accounts = []
    account_vars = {}  # {index: {vars}}
    
    # è§£ææ‰€æœ‰è´¦å·ç›¸å…³çš„ç¯å¢ƒå˜é‡
    for line_data in lines:
        line = line_data["raw"].strip()
        if not line or line.startswith("#") or "=" not in line:
            continue
        
        key, value = line.split("=", 1)
        key = key.strip()
        value = value.strip().strip('"').strip("'")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è´¦å·é…ç½®
        if key.startswith("ACCOUNT") and key.endswith("_SECURE_C_SES"):
            idx_str = key[len("ACCOUNT") : -len("_SECURE_C_SES")]
            try:
                idx = int(idx_str)
                if idx not in account_vars:
                    account_vars[idx] = {}
                account_vars[idx]["SECURE_C_SES"] = value
                account_vars[idx]["index"] = idx
            except ValueError:
                continue
        elif key.startswith("ACCOUNT") and "_" in key:
            parts = key.split("_", 1)
            if len(parts) == 2 and parts[0].startswith("ACCOUNT"):
                idx_str = parts[0][len("ACCOUNT"):]
                try:
                    idx = int(idx_str)
                    var_name = parts[1]
                    if idx not in account_vars:
                        account_vars[idx] = {}
                    account_vars[idx][var_name] = value
                    account_vars[idx]["index"] = idx
                except ValueError:
                    continue
    
    # æ£€æŸ¥æ—§çš„å•è´¦å·é…ç½®
    old_account = {}
    for line_data in lines:
        line = line_data["raw"].strip()
        if not line or line.startswith("#") or "=" not in line:
            continue
        key, value = line.split("=", 1)
        key = key.strip()
        value = value.strip().strip('"').strip("'")
        if key in ["SECURE_C_SES", "CSESIDX", "CONFIG_ID", "HOST_C_OSES"]:
            old_account[key] = value
    
    # å¤„ç†å¤šè´¦å·é…ç½®
    for idx in sorted(account_vars.keys()):
        vars_dict = account_vars[idx]
        if vars_dict.get("SECURE_C_SES") and vars_dict.get("CSESIDX") and vars_dict.get("CONFIG_ID"):
            accounts.append({
                "index": idx,
                "name": vars_dict.get("NAME") or f"account-{idx}",
                "secure_c_ses": vars_dict.get("SECURE_C_SES"),
                "csesidx": vars_dict.get("CSESIDX"),
                "config_id": vars_dict.get("CONFIG_ID"),
                "host_c_oses": vars_dict.get("HOST_C_OSES", ""),
            })
    
    # å¤„ç†æ—§çš„å•è´¦å·é…ç½®
    if not accounts and old_account.get("SECURE_C_SES") and old_account.get("CSESIDX") and old_account.get("CONFIG_ID"):
        accounts.append({
            "index": 0,  # 0 è¡¨ç¤ºæ—§æ ¼å¼
            "name": "default",
            "secure_c_ses": old_account.get("SECURE_C_SES"),
            "csesidx": old_account.get("CSESIDX"),
            "config_id": old_account.get("CONFIG_ID"),
            "host_c_oses": old_account.get("HOST_C_OSES", ""),
        })
    
    return accounts


class AccountRequest(BaseModel):
    name: str
    secure_c_ses: str
    csesidx: str
    config_id: str
    host_c_oses: Optional[str] = ""


class AccountResponse(BaseModel):
    index: int
    name: str
    secure_c_ses: str
    csesidx: str
    config_id: str
    host_c_oses: str
    status: Optional[str] = None  # æµ‹è¯•çŠ¶æ€


@app.get("/admin/accounts", response_model=List[AccountResponse])
async def list_accounts(
    admin: Admin = Depends(get_current_admin)
):
    """åˆ—å‡ºæ‰€æœ‰è´¦å·é…ç½®"""
    lines = read_env_file()
    accounts = parse_accounts_from_env_lines(lines)
    
    # è·å–å½“å‰è¿è¡Œæ—¶çš„è´¦å·çŠ¶æ€
    account_status = {}
    if ACCOUNT_POOL:
        for acc in ACCOUNT_POOL.accounts:
            account_status[acc.name] = "available" if acc.is_available() else "unavailable"
    
    result = []
    for acc in accounts:
        status = account_status.get(acc["name"], "unknown")
        result.append(AccountResponse(
            index=acc["index"],
            name=acc["name"],
            secure_c_ses=acc["secure_c_ses"],
            csesidx=acc["csesidx"],
            config_id=acc["config_id"],
            host_c_oses=acc.get("host_c_oses", ""),
            status=status
        ))
    
    return result


@app.post("/admin/accounts", response_model=AccountResponse)
async def create_account(
    req: AccountRequest,
    admin: Admin = Depends(get_current_admin)
):
    """åˆ›å»ºæ–°è´¦å·ï¼ˆåŸºäºé‚®ç®±å»é‡ï¼‰"""
    lines = read_env_file()
    accounts = parse_accounts_from_env_lines(lines)
    
    # æå–å½“å‰è´¦å·çš„é‚®ç®±
    account_data = {
        "name": req.name,
        "secure_c_ses": req.secure_c_ses,
        "csesidx": req.csesidx,
        "config_id": req.config_id,
        "host_c_oses": req.host_c_oses or ""
    }
    new_email = extract_email_from_account(account_data)
    
    # é‚®ç®±å»é‡æ£€æŸ¥
    if new_email:
        for acc in accounts:
            existing_account_data = {
                "name": acc.get("name", ""),
                "secure_c_ses": acc.get("secure_c_ses", ""),
                "csesidx": acc.get("csesidx", ""),
                "config_id": acc.get("config_id", ""),
                "host_c_oses": acc.get("host_c_oses", "")
            }
            existing_email = extract_email_from_account(existing_account_data)
            if existing_email and existing_email == new_email:
                raise HTTPException(
                    status_code=400,
                    detail=f"é‚®ç®± {new_email} å·²å­˜åœ¨ï¼Œä¸èƒ½é‡å¤æ·»åŠ "
                )
    
    # æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨çš„ç´¢å¼•
    existing_indices = {acc["index"] for acc in accounts if acc["index"] > 0}
    next_index = 1
    while next_index in existing_indices:
        next_index += 1
    
    # æ·»åŠ æ–°è´¦å·é…ç½®åˆ°æ–‡ä»¶æœ«å°¾
    new_lines = [
        {"raw": f"# Account {next_index}: {req.name}@{next_index}", "type": "comment"},
        {"raw": f'ACCOUNT{next_index}_NAME="{req.name}"', "type": "line"},
        {"raw": f'ACCOUNT{next_index}_SECURE_C_SES="{req.secure_c_ses}"', "type": "line"},
        {"raw": f'ACCOUNT{next_index}_CSESIDX="{req.csesidx}"', "type": "line"},
        {"raw": f'ACCOUNT{next_index}_CONFIG_ID="{req.config_id}"', "type": "line"},
    ]
    if req.host_c_oses:
        new_lines.append({"raw": f'ACCOUNT{next_index}_HOST_C_OSES="{req.host_c_oses}"', "type": "line"})
    new_lines.append({"raw": "", "type": "line"})  # ç©ºè¡Œåˆ†éš”
    
    lines.extend(new_lines)
    write_env_file(lines)
    
    # åŠ¨æ€é‡æ–°åŠ è½½è´¦å·é…ç½®
    reload_accounts_from_env_file()
    
    logger.info(f"âœ… ç®¡ç†å‘˜ {admin.username} åˆ›å»ºäº†æ–°è´¦å·: {req.name} (ç´¢å¼•: {next_index})")
    
    return AccountResponse(
        index=next_index,
        name=req.name,
        secure_c_ses=req.secure_c_ses,
        csesidx=req.csesidx,
        config_id=req.config_id,
        host_c_oses=req.host_c_oses or "",
        status="unknown"
    )


class BulkAccountRequest(BaseModel):
    """æ‰¹é‡æ·»åŠ è´¦å·è¯·æ±‚"""
    text: str  # åŸå§‹æ–‡æœ¬ï¼Œä»ä¸­æå–è´¦å·ä¿¡æ¯


def extract_email_from_account(account_data: Dict[str, str]) -> Optional[str]:
    """
    ä»è´¦å·ä¿¡æ¯ä¸­æå–é‚®ç®±
    ä¼˜å…ˆä» EMAIL å­—æ®µæå–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä» NAME å­—æ®µä¸­æå–ï¼ˆå¦‚æœ NAME æ˜¯é‚®ç®±æ ¼å¼ï¼‰
    """
    # å…ˆå°è¯•ä» EMAIL å­—æ®µæå–
    email = account_data.get('email') or account_data.get('EMAIL')
    if email:
        return email.strip().lower()
    
    # å¦‚æœ NAME å­—æ®µçœ‹èµ·æ¥åƒé‚®ç®±ï¼Œä½¿ç”¨å®ƒ
    name = account_data.get('name') or account_data.get('NAME')
    if name:
        name = name.strip()
        # ç®€å•çš„é‚®ç®±æ ¼å¼æ£€æŸ¥ï¼šåŒ…å« @ ç¬¦å·
        if '@' in name and '.' in name.split('@')[-1]:
            return name.lower()
    
    return None


def extract_accounts_from_text(text: str) -> List[Dict[str, str]]:
    """
    ä»æ–‡æœ¬ä¸­æ¨¡ç³ŠåŒ¹é…æå–è´¦å·ä¿¡æ¯
    æŸ¥æ‰¾ NAMEã€EMAILã€SECURE_C_SESã€CSESIDXã€CONFIG_IDã€HOST_C_OSES å­—æ®µ
    """
    accounts = []
    lines = text.split('\n')
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å„ç§å¯èƒ½çš„æ ¼å¼
    # æ”¯æŒæ ¼å¼ï¼šKEY=value, KEY="value", KEY='value', KEY: value ç­‰
    # åŒ¹é…å¸¦å¼•å·çš„å€¼ï¼š["']([^"']+)["'] æˆ– ä¸å¸¦å¼•å·çš„å€¼ï¼š([^\s=:]+)
    def extract_value(line: str, key_pattern: str) -> Optional[str]:
        # å…ˆå°è¯•åŒ¹é…å¸¦å¼•å·çš„æ ¼å¼
        quoted_pattern = re.compile(
            rf'{key_pattern}\s*[=:]\s*["\']([^"\']+)["\']',
            re.IGNORECASE
        )
        match = quoted_pattern.search(line)
        if match:
            return match.group(1).strip()
        
        # å†å°è¯•åŒ¹é…ä¸å¸¦å¼•å·çš„æ ¼å¼
        unquoted_pattern = re.compile(
            rf'{key_pattern}\s*[=:]\s*([^\s=:]+)',
            re.IGNORECASE
        )
        match = unquoted_pattern.search(line)
        if match:
            return match.group(1).strip()
        
        return None
    
    current_account = {}
    
    for line in lines:
        line = line.strip()
        if not line or line.startswith('#'):
            # é‡åˆ°ç©ºè¡Œæˆ–æ³¨é‡Šï¼Œå¦‚æœå½“å‰è´¦å·æœ‰å¿…éœ€å­—æ®µï¼Œä¿å­˜å®ƒ
            if current_account.get('secure_c_ses') and current_account.get('csesidx') and current_account.get('config_id'):
                accounts.append(current_account.copy())
                current_account = {}
            continue
        
        # å°è¯•åŒ¹é…å„ä¸ªå­—æ®µ
        # EMAILï¼ˆä¼˜å…ˆï¼‰
        value = extract_value(line, r'(?:EMAIL|email)')
        if value:
            current_account['email'] = value
            continue
        
        # NAME
        value = extract_value(line, r'(?:NAME|name)')
        if value:
            current_account['name'] = value
            continue
        
        # SECURE_C_SES
        value = extract_value(line, r'(?:SECURE_C_SES|secure_c_ses|SECURE_CSES|secure_cses)')
        if value:
            current_account['secure_c_ses'] = value
            continue
        
        # CSESIDX
        value = extract_value(line, r'(?:CSESIDX|csesidx|CSES_IDX|cses_idx)')
        if value:
            current_account['csesidx'] = value
            continue
        
        # CONFIG_ID
        value = extract_value(line, r'(?:CONFIG_ID|config_id|CONFIGID|configid)')
        if value:
            current_account['config_id'] = value
            continue
        
        # HOST_C_OSES
        value = extract_value(line, r'(?:HOST_C_OSES|host_c_oses|HOST_COSES|host_coses)')
        if value:
            current_account['host_c_oses'] = value
            continue
        
        # ä¹Ÿæ”¯æŒ ACCOUNT1_NAME="value" è¿™ç§æ ¼å¼
        account_match = re.match(
            r'ACCOUNT\d+_(NAME|EMAIL|SECURE_C_SES|CSESIDX|CONFIG_ID|HOST_C_OSES)\s*=\s*["\']?([^"\']+)["\']?',
            line,
            re.IGNORECASE
        )
        if account_match:
            key = account_match.group(1).lower()
            value = account_match.group(2).strip()
            if key == 'name':
                current_account['name'] = value
            elif key == 'email':
                current_account['email'] = value
            elif key == 'secure_c_ses':
                current_account['secure_c_ses'] = value
            elif key == 'csesidx':
                current_account['csesidx'] = value
            elif key == 'config_id':
                current_account['config_id'] = value
            elif key == 'host_c_oses':
                current_account['host_c_oses'] = value
    
    # ä¿å­˜æœ€åä¸€ä¸ªè´¦å·
    if current_account.get('secure_c_ses') and current_account.get('csesidx') and current_account.get('config_id'):
        accounts.append(current_account)
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•è´¦å·ï¼Œå°è¯•æŒ‰ç©ºè¡Œæˆ–æ˜æ˜¾åˆ†éš”ç¬¦åˆ†å‰²æ–‡æœ¬å—
    if not accounts:
        # å°è¯•æŒ‰å¤šä¸ªç©ºè¡Œæˆ–æ˜æ˜¾åˆ†éš”ç¬¦åˆ†å‰²
        blocks = re.split(r'\n\s*\n+', text)
        for block in blocks:
            account = {}
            # EMAIL
            value = extract_value(block, r'(?:EMAIL|email)')
            if value:
                account['email'] = value
            # NAME
            value = extract_value(block, r'(?:NAME|name)')
            if value:
                account['name'] = value
            # SECURE_C_SES
            value = extract_value(block, r'(?:SECURE_C_SES|secure_c_ses|SECURE_CSES|secure_cses)')
            if value:
                account['secure_c_ses'] = value
            # CSESIDX
            value = extract_value(block, r'(?:CSESIDX|csesidx|CSES_IDX|cses_idx)')
            if value:
                account['csesidx'] = value
            # CONFIG_ID
            value = extract_value(block, r'(?:CONFIG_ID|config_id|CONFIGID|configid)')
            if value:
                account['config_id'] = value
            # HOST_C_OSES
            value = extract_value(block, r'(?:HOST_C_OSES|host_c_oses|HOST_COSES|host_coses)')
            if value:
                account['host_c_oses'] = value
            
            if account.get('secure_c_ses') and account.get('csesidx') and account.get('config_id'):
                accounts.append(account)
    
    return accounts


@app.post("/admin/accounts/bulk")
async def create_accounts_bulk(
    req: BulkAccountRequest,
    admin: Admin = Depends(get_current_admin)
):
    """æ‰¹é‡åˆ›å»ºè´¦å·ï¼ˆå¸¦å»é‡åŠŸèƒ½ï¼Œä»æ–‡æœ¬ä¸­æ¨¡ç³ŠåŒ¹é…æå–ï¼‰"""
    if not req.text or not req.text.strip():
        raise HTTPException(status_code=400, detail="æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º")
    
    # ä»æ–‡æœ¬ä¸­æå–è´¦å·ä¿¡æ¯
    extracted_accounts = extract_accounts_from_text(req.text)
    if not extracted_accounts:
        raise HTTPException(status_code=400, detail="æœªèƒ½ä»æ–‡æœ¬ä¸­æå–åˆ°æœ‰æ•ˆçš„è´¦å·ä¿¡æ¯ï¼Œè¯·ç¡®ä¿åŒ…å« NAMEã€SECURE_C_SESã€CSESIDXã€CONFIG_ID å­—æ®µ")
    
    lines = read_env_file()
    accounts = parse_accounts_from_env_lines(lines)
    
    # è·å–å·²å­˜åœ¨è´¦å·çš„é‚®ç®±é›†åˆï¼ˆç”¨äºå»é‡ï¼‰
    existing_emails = set()
    for acc in accounts:
        account_data = {
            "name": acc.get("name", ""),
            "secure_c_ses": acc.get("secure_c_ses", ""),
            "csesidx": acc.get("csesidx", ""),
            "config_id": acc.get("config_id", ""),
            "host_c_oses": acc.get("host_c_oses", "")
        }
        email = extract_email_from_account(account_data)
        if email:
            existing_emails.add(email)
    
    # æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨çš„ç´¢å¼•
    existing_indices = {acc["index"] for acc in accounts if acc["index"] > 0}
    next_index = 1
    while next_index in existing_indices:
        next_index += 1
    
    created_accounts = []
    skipped_accounts = []
    seen_emails_in_batch = set()  # ç”¨äºæ‰¹é‡æ·»åŠ å†…éƒ¨çš„é‚®ç®±å»é‡
    
    new_lines = []
    
    for acc_data in extracted_accounts:
        # è·å–å­—æ®µå€¼ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨ç©ºå­—ç¬¦ä¸²
        name = acc_data.get('name', '').strip() or f'account-{next_index}'
        secure_c_ses = acc_data.get('secure_c_ses', '').strip()
        csesidx = acc_data.get('csesidx', '').strip()
        config_id = acc_data.get('config_id', '').strip()
        host_c_oses = acc_data.get('host_c_oses', '').strip()
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        if not secure_c_ses or not csesidx or not config_id:
            skipped_accounts.append({
                "name": name,
                "reason": "ç¼ºå°‘å¿…éœ€å­—æ®µï¼ˆSECURE_C_SESã€CSESIDXã€CONFIG_IDï¼‰"
            })
            continue
        
        # æå–é‚®ç®±
        current_account_data = {
            "name": name,
            "email": acc_data.get('email', '').strip(),
            "secure_c_ses": secure_c_ses,
            "csesidx": csesidx,
            "config_id": config_id,
            "host_c_oses": host_c_oses
        }
        email = extract_email_from_account(current_account_data)
        
        # å¦‚æœæ²¡æœ‰é‚®ç®±ï¼Œè·³è¿‡å»é‡æ£€æŸ¥ï¼ˆå…è®¸æ·»åŠ ï¼‰
        if not email:
            # æ²¡æœ‰é‚®ç®±ï¼Œç›´æ¥æ·»åŠ 
            pass
        else:
            # å»é‡æ£€æŸ¥1ï¼šæ£€æŸ¥æ˜¯å¦ä¸å·²å­˜åœ¨çš„è´¦å·é‚®ç®±é‡å¤
            if email in existing_emails:
                skipped_accounts.append({
                    "name": name,
                    "reason": f"é‚®ç®± {email} å·²å­˜åœ¨"
                })
                continue
            
            # å»é‡æ£€æŸ¥2ï¼šæ£€æŸ¥æ‰¹é‡æ·»åŠ çš„è´¦å·ä¹‹é—´é‚®ç®±æ˜¯å¦é‡å¤
            if email in seen_emails_in_batch:
                skipped_accounts.append({
                    "name": name,
                    "reason": f"æ‰¹é‡æ·»åŠ ä¸­é‚®ç®± {email} é‡å¤"
                })
                continue
            
            # æ·»åŠ åˆ°å·²è§é‚®ç®±é›†åˆ
            seen_emails_in_batch.add(email)
            existing_emails.add(email)  # æ›´æ–°å·²å­˜åœ¨é‚®ç®±é›†åˆï¼Œé¿å…åç»­é‡å¤
        
        # æ·»åŠ æ–°è´¦å·é…ç½®
        new_lines.append({"raw": f"# Account {next_index}: {name}@{next_index}", "type": "comment"})
        new_lines.append({"raw": f'ACCOUNT{next_index}_NAME="{name}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{next_index}_SECURE_C_SES="{secure_c_ses}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{next_index}_CSESIDX="{csesidx}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{next_index}_CONFIG_ID="{config_id}"', "type": "line"})
        if host_c_oses:
            new_lines.append({"raw": f'ACCOUNT{next_index}_HOST_C_OSES="{host_c_oses}"', "type": "line"})
        new_lines.append({"raw": "", "type": "line"})  # ç©ºè¡Œåˆ†éš”
        
        created_accounts.append({
            "index": next_index,
            "name": name
        })
        
        next_index += 1
        # ç¡®ä¿ç´¢å¼•ä¸å†²çª
        while next_index in existing_indices:
            next_index += 1
    
    if new_lines:
        lines.extend(new_lines)
        write_env_file(lines)
        # åŠ¨æ€é‡æ–°åŠ è½½è´¦å·é…ç½®
        reload_accounts_from_env_file()
        logger.info(f"âœ… ç®¡ç†å‘˜ {admin.username} æ‰¹é‡åˆ›å»ºäº† {len(created_accounts)} ä¸ªè´¦å·ï¼Œè·³è¿‡äº† {len(skipped_accounts)} ä¸ªé‡å¤è´¦å·")
    
    return {
        "message": f"æˆåŠŸåˆ›å»º {len(created_accounts)} ä¸ªè´¦å·",
        "created": created_accounts,
        "skipped": skipped_accounts,
        "total": len(extracted_accounts),
        "created_count": len(created_accounts),
        "skipped_count": len(skipped_accounts)
    }


@app.put("/admin/accounts/{account_index}", response_model=AccountResponse)
async def update_account(
    account_index: int,
    req: AccountRequest,
    admin: Admin = Depends(get_current_admin)
):
    """æ›´æ–°è´¦å·é…ç½®"""
    lines = read_env_file()
    accounts = parse_accounts_from_env_lines(lines)
    
    # æ£€æŸ¥è´¦å·æ˜¯å¦å­˜åœ¨
    account_exists = any(acc["index"] == account_index for acc in accounts)
    if not account_exists:
        raise HTTPException(status_code=404, detail="è´¦å·ä¸å­˜åœ¨")
    
    # å¤„ç†æ—§æ ¼å¼è´¦å·ï¼ˆindex=0ï¼‰ï¼Œè½¬æ¢ä¸ºæ–°æ ¼å¼
    if account_index == 0:
        # åˆ é™¤æ—§æ ¼å¼çš„é…ç½®è¡Œ
        old_keys = ["SECURE_C_SES", "CSESIDX", "CONFIG_ID", "HOST_C_OSES"]
        new_lines = []
        for line_data in lines:
            line = line_data["raw"].strip()
            if "=" in line:
                key = line.split("=", 1)[0].strip()
                if key not in old_keys:
                    new_lines.append(line_data)
            else:
                new_lines.append(line_data)
        
        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨çš„ç´¢å¼•
        existing_indices = {acc["index"] for acc in accounts if acc["index"] > 0}
        next_index = 1
        while next_index in existing_indices:
            next_index += 1
        
        # æ·»åŠ æ–°æ ¼å¼çš„è´¦å·é…ç½®
        new_lines.append({"raw": f"# Account {next_index}: {req.name}@{next_index}", "type": "comment"})
        new_lines.append({"raw": f'ACCOUNT{next_index}_NAME="{req.name}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{next_index}_SECURE_C_SES="{req.secure_c_ses}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{next_index}_CSESIDX="{req.csesidx}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{next_index}_CONFIG_ID="{req.config_id}"', "type": "line"})
        if req.host_c_oses:
            new_lines.append({"raw": f'ACCOUNT{next_index}_HOST_C_OSES="{req.host_c_oses}"', "type": "line"})
        new_lines.append({"raw": "", "type": "line"})
        
        write_env_file(new_lines)
        
        # åŠ¨æ€é‡æ–°åŠ è½½è´¦å·é…ç½®
        reload_accounts_from_env_file()
        
        logger.info(f"âœ… ç®¡ç†å‘˜ {admin.username} æ›´æ–°äº†è´¦å·: {req.name} (ä»æ—§æ ¼å¼è½¬æ¢ä¸ºç´¢å¼•: {next_index})")
        
        return AccountResponse(
            index=next_index,
            name=req.name,
            secure_c_ses=req.secure_c_ses,
            csesidx=req.csesidx,
            config_id=req.config_id,
            host_c_oses=req.host_c_oses or "",
            status="unknown"
        )
    
    # æ›´æ–°æ–°æ ¼å¼è´¦å·é…ç½®
    new_lines = []
    i = 0
    in_account_section = False
    account_start = -1
    account_end = -1
    
    while i < len(lines):
        line = lines[i]["raw"]
        
        # æ£€æŸ¥æ˜¯å¦è¿›å…¥ç›®æ ‡è´¦å·åŒºåŸŸ
        if f"ACCOUNT{account_index}_" in line:
            if not in_account_section:
                in_account_section = True
                account_start = i
                # æ£€æŸ¥å‰é¢æ˜¯å¦æœ‰æ³¨é‡Š
                if i > 0 and lines[i-1]["raw"].strip().startswith("#"):
                    account_start = i - 1
        elif in_account_section:
            # æ£€æŸ¥æ˜¯å¦ç¦»å¼€è´¦å·åŒºåŸŸï¼ˆé‡åˆ°ä¸‹ä¸€ä¸ªè´¦å·æˆ–ç©ºè¡Œåçš„éè´¦å·è¡Œï¼‰
            if line.strip() and not line.startswith("#") and "ACCOUNT" not in line:
                # å¯èƒ½æ˜¯å…¶ä»–é…ç½®ï¼Œç»“æŸå½“å‰è´¦å·åŒºåŸŸ
                account_end = i
                break
            elif line.strip() == "" and i > account_start:
                # ç©ºè¡Œï¼Œå¯èƒ½æ˜¯è´¦å·åŒºåŸŸç»“æŸ
                account_end = i
                break
        
        i += 1
    
    if in_account_section and account_end == -1:
        account_end = len(lines)
    
    # é‡å»ºæ–‡ä»¶å†…å®¹
    if account_start >= 0:
        # ä¿ç•™è´¦å·åŒºåŸŸä¹‹å‰çš„å†…å®¹
        new_lines.extend(lines[:account_start])
        
        # æ·»åŠ æ›´æ–°åçš„è´¦å·é…ç½®
        account_name_line = f"# Account {account_index}: {req.name}@{account_index}"
        if account_start > 0 and lines[account_start-1]["raw"].strip().startswith("#"):
            # å¦‚æœå‰é¢æœ‰æ³¨é‡Šï¼Œæ›¿æ¢å®ƒ
            new_lines[-1] = {"raw": account_name_line, "type": "comment"}
        else:
            new_lines.append({"raw": account_name_line, "type": "comment"})
        
        new_lines.append({"raw": f'ACCOUNT{account_index}_NAME="{req.name}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{account_index}_SECURE_C_SES="{req.secure_c_ses}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{account_index}_CSESIDX="{req.csesidx}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{account_index}_CONFIG_ID="{req.config_id}"', "type": "line"})
        if req.host_c_oses:
            new_lines.append({"raw": f'ACCOUNT{account_index}_HOST_C_OSES="{req.host_c_oses}"', "type": "line"})
        new_lines.append({"raw": "", "type": "line"})  # ç©ºè¡Œåˆ†éš”
        
        # ä¿ç•™è´¦å·åŒºåŸŸä¹‹åçš„å†…å®¹
        new_lines.extend(lines[account_end:])
    else:
        # å¦‚æœæ‰¾ä¸åˆ°è´¦å·åŒºåŸŸï¼Œè¿½åŠ åˆ°æ–‡ä»¶æœ«å°¾
        new_lines = lines
        new_lines.append({"raw": f"# Account {account_index}: {req.name}@{account_index}", "type": "comment"})
        new_lines.append({"raw": f'ACCOUNT{account_index}_NAME="{req.name}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{account_index}_SECURE_C_SES="{req.secure_c_ses}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{account_index}_CSESIDX="{req.csesidx}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{account_index}_CONFIG_ID="{req.config_id}"', "type": "line"})
        if req.host_c_oses:
            new_lines.append({"raw": f'ACCOUNT{account_index}_HOST_C_OSES="{req.host_c_oses}"', "type": "line"})
        new_lines.append({"raw": "", "type": "line"})
    
    write_env_file(new_lines)
    
    # åŠ¨æ€é‡æ–°åŠ è½½è´¦å·é…ç½®
    reload_accounts_from_env_file()
    
    logger.info(f"âœ… ç®¡ç†å‘˜ {admin.username} æ›´æ–°äº†è´¦å·: {req.name} (ç´¢å¼•: {account_index})")
    
    return AccountResponse(
        index=account_index,
        name=req.name,
        secure_c_ses=req.secure_c_ses,
        csesidx=req.csesidx,
        config_id=req.config_id,
        host_c_oses=req.host_c_oses or "",
        status="unknown"
    )


@app.delete("/admin/accounts/{account_index}")
async def delete_account(
    account_index: int,
    admin: Admin = Depends(get_current_admin)
):
    """åˆ é™¤è´¦å·é…ç½®"""
    lines = read_env_file()
    accounts = parse_accounts_from_env_lines(lines)
    
    # æ£€æŸ¥è´¦å·æ˜¯å¦å­˜åœ¨
    account_exists = any(acc["index"] == account_index for acc in accounts)
    if not account_exists:
        raise HTTPException(status_code=404, detail="è´¦å·ä¸å­˜åœ¨")
    
    # å¤„ç†æ—§æ ¼å¼è´¦å·ï¼ˆindex=0ï¼‰
    if account_index == 0:
        # åˆ é™¤æ—§æ ¼å¼çš„é…ç½®è¡Œ
        old_keys = ["SECURE_C_SES", "CSESIDX", "CONFIG_ID", "HOST_C_OSES"]
        new_lines = []
        for line_data in lines:
            line = line_data["raw"].strip()
            if "=" in line:
                key = line.split("=", 1)[0].strip()
                if key not in old_keys:
                    new_lines.append(line_data)
            else:
                new_lines.append(line_data)
        
        write_env_file(new_lines)
        # åŠ¨æ€é‡æ–°åŠ è½½è´¦å·é…ç½®
        reload_accounts_from_env_file()
        logger.info(f"âœ… ç®¡ç†å‘˜ {admin.username} åˆ é™¤äº†æ—§æ ¼å¼è´¦å·")
        return {"message": "è´¦å·å·²åˆ é™¤"}
    
    # åˆ é™¤æ–°æ ¼å¼è´¦å·é…ç½®
    new_lines = []
    i = 0
    in_account_section = False
    account_start = -1
    account_end = -1
    
    while i < len(lines):
        line = lines[i]["raw"]
        
        # æ£€æŸ¥æ˜¯å¦è¿›å…¥ç›®æ ‡è´¦å·åŒºåŸŸ
        if f"ACCOUNT{account_index}_" in line:
            if not in_account_section:
                in_account_section = True
                account_start = i
                # æ£€æŸ¥å‰é¢æ˜¯å¦æœ‰æ³¨é‡Š
                if i > 0 and lines[i-1]["raw"].strip().startswith("#"):
                    account_start = i - 1
        elif in_account_section:
            # æ£€æŸ¥æ˜¯å¦ç¦»å¼€è´¦å·åŒºåŸŸ
            if line.strip() and not line.startswith("#") and "ACCOUNT" not in line:
                account_end = i
                break
            elif line.strip() == "" and i > account_start:
                account_end = i
                break
        
        i += 1
    
    if in_account_section and account_end == -1:
        account_end = len(lines)
    
    # é‡å»ºæ–‡ä»¶å†…å®¹ï¼ˆè·³è¿‡è´¦å·åŒºåŸŸï¼‰
    if account_start >= 0:
        new_lines.extend(lines[:account_start])
        new_lines.extend(lines[account_end:])
    else:
        new_lines = lines
    
    write_env_file(new_lines)
    
    # åŠ¨æ€é‡æ–°åŠ è½½è´¦å·é…ç½®
    reload_accounts_from_env_file()
    
    logger.info(f"âœ… ç®¡ç†å‘˜ {admin.username} åˆ é™¤äº†è´¦å· (ç´¢å¼•: {account_index})")
    
    return {"message": "è´¦å·å·²åˆ é™¤"}


class BulkDeleteAccountRequest(BaseModel):
    """æ‰¹é‡åˆ é™¤è´¦å·è¯·æ±‚"""
    indices: List[int]  # è¦åˆ é™¤çš„è´¦å·ç´¢å¼•åˆ—è¡¨


@app.post("/admin/accounts/bulk-delete")
async def bulk_delete_accounts(
    req: BulkDeleteAccountRequest,
    admin: Admin = Depends(get_current_admin)
):
    """æ‰¹é‡åˆ é™¤è´¦å·"""
    if not req.indices:
        raise HTTPException(status_code=400, detail="è¯·é€‰æ‹©è¦åˆ é™¤çš„è´¦å·")
    
    lines = read_env_file()
    accounts = parse_accounts_from_env_lines(lines)
    
    # éªŒè¯è¦åˆ é™¤çš„è´¦å·æ˜¯å¦å­˜åœ¨
    existing_indices = {acc["index"] for acc in accounts}
    invalid_indices = [idx for idx in req.indices if idx not in existing_indices]
    if invalid_indices:
        raise HTTPException(status_code=404, detail=f"ä»¥ä¸‹è´¦å·ä¸å­˜åœ¨: {invalid_indices}")
    
    # ä¸å…è®¸åˆ é™¤é»˜è®¤è´¦å·ï¼ˆindex=0ï¼‰
    if 0 in req.indices:
        raise HTTPException(status_code=400, detail="ä¸èƒ½åˆ é™¤é»˜è®¤è´¦å·")
    
    # æŒ‰ç´¢å¼•ä»å¤§åˆ°å°æ’åºï¼Œä»åå¾€å‰åˆ é™¤ï¼Œé¿å…ç´¢å¼•å˜åŒ–å½±å“
    sorted_indices = sorted(req.indices, reverse=True)
    
    deleted_count = 0
    for account_index in sorted_indices:
        # åˆ é™¤è´¦å·é…ç½®
        new_lines = []
        i = 0
        in_account_section = False
        account_start = -1
        account_end = -1
        
        while i < len(lines):
            line = lines[i]["raw"]
            
            # æ£€æŸ¥æ˜¯å¦è¿›å…¥ç›®æ ‡è´¦å·åŒºåŸŸ
            if f"ACCOUNT{account_index}_" in line:
                if not in_account_section:
                    in_account_section = True
                    account_start = i
                    # æ£€æŸ¥å‰é¢æ˜¯å¦æœ‰æ³¨é‡Š
                    if account_start > 0 and lines[account_start - 1]["raw"].strip().startswith("#"):
                        account_start -= 1
            elif in_account_section:
                # æ£€æŸ¥æ˜¯å¦ç¦»å¼€è´¦å·åŒºåŸŸï¼ˆé‡åˆ°ç©ºè¡Œæˆ–ä¸‹ä¸€ä¸ªè´¦å·ï¼‰
                if not line.strip() or (line.strip().startswith("#") and "Account" in line and f"Account {account_index}" not in line):
                    account_end = i
                    break
                # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸‹ä¸€ä¸ªè´¦å·çš„é…ç½®
                if "ACCOUNT" in line and f"ACCOUNT{account_index}_" not in line:
                    account_end = i
                    break
            
            i += 1
        
        # å¦‚æœæ‰¾åˆ°äº†è´¦å·åŒºåŸŸï¼Œåˆ é™¤å®ƒ
        if account_start >= 0:
            if account_end == -1:
                account_end = len(lines)
            new_lines = lines[:account_start] + lines[account_end:]
            lines = new_lines
            deleted_count += 1
    
    if deleted_count > 0:
        write_env_file(lines)
        # åŠ¨æ€é‡æ–°åŠ è½½è´¦å·é…ç½®
        reload_accounts_from_env_file()
        logger.info(f"âœ… ç®¡ç†å‘˜ {admin.username} æ‰¹é‡åˆ é™¤äº† {deleted_count} ä¸ªè´¦å· (ç´¢å¼•: {req.indices})")
    
    return {
        "message": f"æˆåŠŸåˆ é™¤ {deleted_count} ä¸ªè´¦å·",
        "deleted_count": deleted_count
    }


@app.post("/admin/accounts/{account_index}/test")
async def test_account(
    account_index: int,
    admin: Admin = Depends(get_current_admin)
):
    """æµ‹è¯•è´¦å·æ˜¯å¦å¯ç”¨"""
    lines = read_env_file()
    accounts = parse_accounts_from_env_lines(lines)
    
    # æ‰¾åˆ°ç›®æ ‡è´¦å·
    target_account = None
    for acc in accounts:
        if acc["index"] == account_index:
            target_account = acc
            break
    
    if not target_account:
        raise HTTPException(status_code=404, detail="è´¦å·ä¸å­˜åœ¨")
    
    # åˆ›å»ºä¸´æ—¶è´¦å·å¯¹è±¡è¿›è¡Œæµ‹è¯•
    test_acc = Account(
        name=target_account["name"],
        secure_c_ses=target_account["secure_c_ses"],
        csesidx=target_account["csesidx"],
        config_id=target_account["config_id"],
        host_c_oses=target_account.get("host_c_oses", ""),
    )
    
    try:
        # å°è¯•è·å– JWT
        jwt_token = await test_acc.jwt_mgr.get()
        if jwt_token:
            return {"status": "success", "message": "è´¦å·æµ‹è¯•æˆåŠŸï¼ŒJWT è·å–æ­£å¸¸"}
        else:
            return {"status": "error", "message": "æ— æ³•è·å– JWT"}
    except Exception as e:
        logger.error(f"è´¦å·æµ‹è¯•å¤±è´¥: {e}")
        return {"status": "error", "message": f"è´¦å·æµ‹è¯•å¤±è´¥: {str(e)}"}


# ---------- API å¯†é’¥éªŒè¯ä¸­é—´ä»¶ ----------
async def verify_api_key_middleware(request: Request, call_next):
    """éªŒè¯ API å¯†é’¥"""
    from fastapi.responses import JSONResponse
    import time as time_module
    
    # åªå¯¹ /v1/ å¼€å¤´çš„è·¯å¾„è¿›è¡ŒéªŒè¯
    if request.url.path.startswith("/v1/"):
        auth_header = request.headers.get("Authorization")
        start_time = time_module.time()
        
        if not auth_header or not auth_header.startswith("Bearer "):
            return JSONResponse(
                status_code=401,
                content={"detail": "ç¼ºå°‘ API å¯†é’¥"}
            )
        
        api_key = auth_header.replace("Bearer ", "")
        key_hash = hash_api_key(api_key)
        
        # è·å–æ•°æ®åº“ä¼šè¯
        db = next(get_db())
        db_key = None
        client_ip = request.client.host if request.client else "unknown"
        
        try:
            db_key = db.query(APIKey).filter(APIKey.key_hash == key_hash).first()
            
            if not db_key:
                return JSONResponse(
                    status_code=401,
                    content={"detail": "æ— æ•ˆçš„ API å¯†é’¥"}
                )
            
            if not db_key.is_active:
                return JSONResponse(
                    status_code=401,
                    content={"detail": "API å¯†é’¥å·²è¢«æ’¤é”€"}
                )
            
            # ç¡®ä¿ expires_at æ˜¯ aware datetime ä»¥ä¾¿æ¯”è¾ƒ
            expires_at = ensure_aware(db_key.expires_at)
            if expires_at < get_beijing_time():
                return JSONResponse(
                    status_code=401,
                    content={"detail": "API å¯†é’¥å·²è¿‡æœŸ"}
                )
            
            # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡ï¼ˆå­˜å‚¨æ—¶ä½¿ç”¨ naive datetimeï¼‰
            db_key.usage_count += 1
            db_key.last_used_at = ensure_naive(get_beijing_time())
            db.commit()
            
            # å­˜å‚¨åˆ°è¯·æ±‚çŠ¶æ€ï¼Œç”¨äºåç»­è®°å½•
            request.state.api_key_id = db_key.id
            request.state.start_time = start_time
            request.state.client_ip = client_ip
            
        except Exception as e:
            logger.error(f"API key validation error: {e}")
            return JSONResponse(
                status_code=500,
                content={"detail": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}
            )
        finally:
            db.close()
    
    # æ‰§è¡Œå®é™…è¯·æ±‚
    response = await call_next(request)
    
    # è®°å½•è°ƒç”¨æ—¥å¿—
    if request.url.path.startswith("/v1/") and hasattr(request.state, "api_key_id"):
        db = next(get_db())
        try:
            # å°è¯•ä»è¯·æ±‚ä½“è·å–æ¨¡å‹ä¿¡æ¯
            model = "unknown"
            if hasattr(request.state, "model"):
                model = request.state.model
            
            response_time = int((time_module.time() - request.state.start_time) * 1000)
            
            log_entry = APICallLog(
                api_key_id=request.state.api_key_id,
                timestamp=ensure_naive(get_beijing_time()),
                model=model,
                status="success" if response.status_code < 400 else "error",
                error_message=None if response.status_code < 400 else f"HTTP {response.status_code}",
                ip_address=request.state.client_ip,
                endpoint=request.url.path,
                response_time=response_time
            )
            db.add(log_entry)
            db.commit()
            
            # å¹¿æ’­æ›´æ–°æ¶ˆæ¯
            await manager.broadcast("update")
        except Exception as e:
            logger.error(f"Failed to log API call: {e}")
        finally:
            db.close()
    
    return response

app.middleware("http")(verify_api_key_middleware)


@app.post("/admin/chat/completions")
async def admin_chat(
    req: ChatRequest,
    admin: Admin = Depends(get_current_admin)
):
    """ç®¡ç†å‘˜ä¸“ç”¨çš„èŠå¤©æ¥å£ï¼Œæ— éœ€ API å¯†é’¥"""
    # å¤ç”¨ç°æœ‰çš„èŠå¤©é€»è¾‘ï¼Œä½†ä¸è®°å½•åˆ° API è°ƒç”¨æ—¥å¿—
    request = Request({"type": "http", "method": "POST", "path": "/admin/chat/completions"})
    request.state.model = req.model
    
    # 1. æ¨¡å‹æ ¡éªŒ
    if req.model not in MODEL_MAPPING:
        raise HTTPException(
            status_code=404, detail=f"Model '{req.model}' not found."
        )

    if ACCOUNT_POOL is None:
        raise HTTPException(
            status_code=500,
            detail="No Gemini business accounts configured",
        )

    # 2. è§£æè¯·æ±‚å†…å®¹
    last_text, current_images = parse_last_message(req.messages)

    # 3. é”šå®šå¯¹è¯ & è´¦å·
    conv_key = get_conversation_key([m.dict() for m in req.messages])
    account = ACCOUNT_POOL.get_for_conversation(conv_key)
    cached = SESSION_CACHE.get(conv_key)

    if cached:
        google_session = cached["session_id"]
        text_to_send = last_text
        logger.info(
            f"â™»ï¸ ç®¡ç†å‘˜å¯¹è¯å»¶ç»­æ—§å¯¹è¯[{req.model}] è´¦å·={account.name} session={google_session[-12:]}"
        )
        cached["updated_at"] = time.time()
        is_retry_mode = False
    else:
        logger.info(f"ğŸ†• ç®¡ç†å‘˜å¼€å¯æ–°å¯¹è¯ [{req.model}] ä½¿ç”¨è´¦å· {account.name}")

        google_session: Optional[str] = None
        first_error: Optional[Exception] = None
        tried_accounts = set()

        while True:
            tried_accounts.add(account.name)
            try:
                google_session = await create_google_session(account)
                break
            except HTTPException as e:
                if e.status_code in (401, 403, 429):
                    account.mark_quota_error(e.status_code, str(e.detail))
                    alt = ACCOUNT_POOL.get_alternative(account.name)
                    if not alt or alt.name in tried_accounts:
                        if first_error:
                            raise first_error
                        raise e
                    first_error = e
                    account = alt
                    continue
                raise

        SESSION_CACHE[conv_key] = {
            "session_id": google_session,
            "updated_at": time.time(),
            "account": account.name,
        }
        text_to_send = build_full_context_text(req.messages)
        is_retry_mode = True

    chat_id = f"chatcmpl-admin-{uuid.uuid4().hex[:8]}"
    created_time = int(time.time())

    # 4. å°è£…ç”Ÿæˆé€»è¾‘
    async def response_wrapper():
        nonlocal account

        retry_count = 0
        max_retries = 2

        current_text = text_to_send
        current_retry_mode = is_retry_mode
        current_file_ids: List[str] = []

        while retry_count <= max_retries:
            try:
                cached_session = SESSION_CACHE.get(conv_key)
                if not cached_session:
                    new_sess = await create_google_session(account)
                    SESSION_CACHE[conv_key] = {
                        "session_id": new_sess,
                        "updated_at": time.time(),
                        "account": account.name,
                    }
                    cached_session = SESSION_CACHE[conv_key]

                current_session = cached_session["session_id"]

                # A. å¦‚æœæœ‰å›¾ç‰‡ä¸”è¿˜æ²¡ä¸Šä¼ åˆ°å½“å‰ Sessionï¼Œå…ˆä¸Šä¼ 
                if current_images and not current_file_ids:
                    for img in current_images:
                        fid = await upload_context_file(
                            account, current_session, img["mime"], img["data"]
                        )
                        current_file_ids.append(fid)

                # B. å‡†å¤‡æ–‡æœ¬ (é‡è¯•æ¨¡å¼ä¸‹å‘å…¨æ–‡)
                if current_retry_mode:
                    current_text = build_full_context_text(req.messages)

                # C. å‘èµ·å¯¹è¯
                async for chunk in stream_chat_generator(
                    account,
                    current_session,
                    current_text,
                    current_file_ids,
                    req.model,
                    chat_id,
                    created_time,
                    req.stream,
                ):
                    yield chunk
                break

            except (httpx.ConnectError, httpx.ReadTimeout, ssl.SSLError,
                    asyncio.TimeoutError) as e:
                retry_count += 1
                if retry_count > max_retries:
                    logger.error(f"ç½‘ç»œé”™è¯¯é‡è¯•å¤±è´¥ [{account.name}]: {e}")
                    raise HTTPException(status_code=503, detail="Service Unavailable")
                logger.warning(f"ç½‘ç»œé”™è¯¯ï¼Œé‡è¯• {retry_count}/{max_retries} [{account.name}]")
                await asyncio.sleep(1)
                continue

            except HTTPException as e:
                if e.status_code in (401, 403, 429):
                    account.mark_quota_error(e.status_code, str(e.detail))
                    alt = ACCOUNT_POOL.get_alternative(account.name)
                    if alt and alt.name != account.name:
                        logger.info(f"åˆ‡æ¢åˆ°å¤‡ç”¨è´¦å·: {alt.name}")
                        account = alt
                        retry_count = 0
                        continue
                raise

    if req.stream:
        return StreamingResponse(
            response_wrapper(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            },
        )

    # éæµå¼å“åº”
    full_content = ""
    async for chunk_str in response_wrapper():
        if chunk_str.startswith("data: [DONE]"):
            break
        if chunk_str.startswith("data: "):
            try:
                data = json.loads(chunk_str[6:])
                delta = data["choices"][0]["delta"]
                if "content" in delta:
                    full_content += delta["content"]
            except Exception:
                pass

    response_data = {
        "id": chat_id,
        "object": "chat.completion",
        "created": created_time,
        "model": req.model,
        "choices": [
            {
                "index": 0,
                "message": {"role": "assistant", "content": full_content},
                "finish_reason": "stop",
            }
        ],
        "usage": {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0,
        },
    }

    return response_data


@app.post("/v1/chat/completions")
async def chat(req: ChatRequest, request: Request):
    # è®°å½•æ¨¡å‹åˆ°è¯·æ±‚çŠ¶æ€
    request.state.model = req.model
    
    # 1. æ¨¡å‹æ ¡éªŒ
    if req.model not in MODEL_MAPPING:
        raise HTTPException(
            status_code=404, detail=f"Model '{req.model}' not found."
        )

    if ACCOUNT_POOL is None:
        raise HTTPException(
            status_code=500,
            detail="No Gemini business accounts configured",
        )

    # 2. è§£æè¯·æ±‚å†…å®¹
    last_text, current_images = parse_last_message(req.messages)

    # 3. é”šå®šå¯¹è¯ & è´¦å·
    conv_key = get_conversation_key([m.dict() for m in req.messages])
    account = ACCOUNT_POOL.get_for_conversation(conv_key)
    cached = SESSION_CACHE.get(conv_key)

    if cached:
        google_session = cached["session_id"]
        text_to_send = last_text
        logger.info(
            f"â™»ï¸ å»¶ç»­æ—§å¯¹è¯[{req.model}] è´¦å·={account.name} session={google_session[-12:]}"
        )
        cached["updated_at"] = time.time()
        is_retry_mode = False
    else:
        logger.info(f"ğŸ†• å¼€å¯æ–°å¯¹è¯ [{req.model}] ä½¿ç”¨è´¦å· {account.name}")

        google_session: Optional[str] = None
        first_error: Optional[Exception] = None
        tried_accounts = set()

        while True:
            tried_accounts.add(account.name)
            try:
                google_session = await create_google_session(account)
                break
            except HTTPException as e:
                if e.status_code in (401, 403, 429):
                    account.mark_quota_error(e.status_code, str(e.detail))
                    alt = ACCOUNT_POOL.get_alternative(account.name)
                    if not alt or alt.name in tried_accounts:
                        first_error = e
                        break
                    logger.info(
                        f"createSession é…é¢å—é™ï¼Œåˆ‡æ¢è´¦å· {account.name} -> {alt.name}"
                    )
                    account = alt
                    continue
                first_error = e
                break
            except Exception as e:
                first_error = e
                break

        if not google_session:
            if isinstance(first_error, HTTPException):
                raise first_error
            raise HTTPException(status_code=500, detail="No available account")

        text_to_send = build_full_context_text(req.messages)
        SESSION_CACHE[conv_key] = {
            "session_id": google_session,
            "updated_at": time.time(),
            "account": account.name,
        }
        is_retry_mode = True

    chat_id = f"chatcmpl-{uuid.uuid4()}"
    created_time = int(time.time())

    # 4. å°è£…ç”Ÿæˆé€»è¾‘ï¼ˆå«å›¾ç‰‡ä¸Šä¼ ã€é‡è¯•å’Œè´¦å·åˆ‡æ¢ï¼‰
    async def response_wrapper():
        nonlocal account

        retry_count = 0
        max_retries = 2

        current_text = text_to_send
        current_retry_mode = is_retry_mode
        current_file_ids: List[str] = []

        while retry_count <= max_retries:
            try:
                cached_session = SESSION_CACHE.get(conv_key)
                if not cached_session:
                    new_sess = await create_google_session(account)
                    SESSION_CACHE[conv_key] = {
                        "session_id": new_sess,
                        "updated_at": time.time(),
                        "account": account.name,
                    }
                    cached_session = SESSION_CACHE[conv_key]

                current_session = cached_session["session_id"]

                # A. å¦‚æœæœ‰å›¾ç‰‡ä¸”è¿˜æ²¡ä¸Šä¼ åˆ°å½“å‰ Sessionï¼Œå…ˆä¸Šä¼ 
                if current_images and not current_file_ids:
                    for img in current_images:
                        fid = await upload_context_file(
                            account, current_session, img["mime"], img["data"]
                        )
                        current_file_ids.append(fid)

                # B. å‡†å¤‡æ–‡æœ¬ (é‡è¯•æ¨¡å¼ä¸‹å‘å…¨æ–‡)
                if current_retry_mode:
                    current_text = build_full_context_text(req.messages)

                # C. å‘èµ·å¯¹è¯
                async for chunk in stream_chat_generator(
                    account,
                    current_session,
                    current_text,
                    current_file_ids,
                    req.model,
                    chat_id,
                    created_time,
                    req.stream,
                ):
                    yield chunk
                break

            except (httpx.ConnectError, httpx.ReadTimeout, ssl.SSLError, HTTPException) as e:
                retry_count += 1
                logger.warning(
                    f"âš ï¸ è¯·æ±‚å¼‚å¸¸ (é‡è¯• {retry_count}/{max_retries}) è´¦å·={account.name}: {e}"
                )

                status_code = getattr(e, "status_code", None)

                # å…ˆåˆ¤å®šé…é¢/æƒé™ç±»é”™è¯¯ï¼Œå°è¯•åˆ‡æ¢è´¦å·
                if isinstance(e, HTTPException) and status_code in (401, 403, 429):
                    account.mark_quota_error(status_code, str(e.detail))
                    alt = ACCOUNT_POOL.get_alternative(account.name)
                    if alt:
                        logger.info(f"ğŸ” åˆ‡æ¢åˆ°å¤‡ç”¨è´¦å· {alt.name}")
                        account = alt
                        try:
                            new_sess = await create_google_session(account)
                            SESSION_CACHE[conv_key] = {
                                "session_id": new_sess,
                                "updated_at": time.time(),
                                "account": account.name,
                            }
                            current_retry_mode = True
                            current_file_ids = []
                            continue
                        except Exception as create_err:
                            logger.error(
                                f"å¤‡ç”¨è´¦å·åˆ›å»º Session å¤±è´¥: {create_err}"
                            )
                            if req.stream:
                                yield "data: " + json.dumps(
                                    {
                                        "error": {
                                            "message": "All accounts exhausted"
                                        }
                                    }
                                ) + "\n\n"
                                return
                            raise

                # éé…é¢é”™è¯¯æˆ–åˆ‡æ¢å¤±è´¥ï¼Œå°è¯•å½“å‰è´¦å·é‡å»º session
                if retry_count <= max_retries:
                    logger.info("ğŸ”„ å°è¯•é‡å»º Session...")
                    try:
                        new_sess = await create_google_session(account)
                        SESSION_CACHE[conv_key] = {
                            "session_id": new_sess,
                            "updated_at": time.time(),
                            "account": account.name,
                        }
                        current_retry_mode = True
                        current_file_ids = []
                    except Exception as create_err:
                        logger.error(f"Session é‡å»ºå¤±è´¥: {create_err}")
                        if req.stream:
                            yield "data: " + json.dumps(
                                {
                                    "error": {
                                        "message": "Session Recovery Failed"
                                    }
                                }
                            ) + "\n\n"
                            return
                        raise
                else:
                    if req.stream:
                        yield "data: " + json.dumps(
                            {"error": {"message": f"Final Error: {e}"}}
                        ) + "\n\n"
                        return
                    raise

    if req.stream:
        return StreamingResponse(
            response_wrapper(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            },
        )

    full_content = ""
    async for chunk_str in response_wrapper():
        if chunk_str.startswith("data: [DONE]"):
            break
        if chunk_str.startswith("data: "):
            try:
                data = json.loads(chunk_str[6:])
                delta = data["choices"][0]["delta"]
                if "content" in delta:
                    full_content += delta["content"]
            except Exception:
                pass

    response_data = {
        "id": chat_id,
        "object": "chat.completion",
        "created": created_time,
        "model": req.model,
        "choices": [
            {
                "index": 0,
                "message": {"role": "assistant", "content": full_content},
                "finish_reason": "stop",
            }
        ],
        "usage": {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0,
        },
    }

    return response_data


async def stream_chat_generator(
    account: Account,
    session: str,
    text_content: str,
    file_ids: List[str],
    model_name: str,
    chat_id: str,
    created_time: int,
    is_stream: bool = True,
):
    jwt = await account.jwt_mgr.get()
    headers = get_common_headers(jwt)

    body: Dict[str, Any] = {
        "configId": account.config_id,
        "additionalParams": {"token": "-"},
        "streamAssistRequest": {
            "session": session,
            "query": {"parts": [{"text": text_content}]},
            "filter": "",
            "fileIds": file_ids,
            "answerGenerationMode": "NORMAL",
            "toolsSpec": {
                "webGroundingSpec": {},
                "toolRegistry": "default_tool_registry",
                "imageGenerationSpec": {},
                "videoGenerationSpec": {},
            },
            "languageCode": "zh-CN",
            "userMetadata": {"timeZone": "Asia/Shanghai"},
            "assistSkippingMode": "REQUEST_ASSIST",
        },
    }

    target_model_id = MODEL_MAPPING.get(model_name)
    if target_model_id:
        body["streamAssistRequest"]["assistGenerationConfig"] = {
            "modelId": target_model_id
        }

    if is_stream:
        chunk = create_chunk(
            chat_id, created_time, model_name, {"role": "assistant"}, None
        )
        yield f"data: {chunk}\n\n"

    r = await http_client.post(
        "https://biz-discoveryengine.googleapis.com/v1alpha/locations/global/widgetStreamAssist",
        headers=headers,
        json=body,
    )

    if r.status_code != 200:
        logger.error(
            f"widgetStreamAssist å¤±è´¥ [{account.name}]: {r.status_code} {r.text}"
        )
        if r.status_code in (401, 403, 429):
            account.mark_quota_error(r.status_code, r.text)
        raise HTTPException(status_code=r.status_code, detail=f"Upstream Error {r.text}")

    try:
        data_list = r.json()
    except Exception as e:  # noqa: BLE001
        logger.error(f"JSON è§£æå¤±è´¥ [{account.name}]: {e}")
        raise HTTPException(status_code=502, detail="Invalid JSON response")

    # ========== ç¬¬ä¸€æ­¥ï¼šæ”¶é›†æ–‡æœ¬å†…å®¹å’Œæ€è€ƒè¿‡ç¨‹ ==========
    full_content = ""
    generated_images: List[ChatImage] = []
    thinking_parts = []

    for data in data_list:
        for reply in (
            data.get("streamAssistResponse", {})
            .get("answer", {})
            .get("replies", [])
        ):
            # æå– API è¿”å›çš„ thought å­—æ®µ
            thought = reply.get("thought", "")
            if thought:
                thinking_parts.append(thought)
            
            # æå–æ­£æ–‡å†…å®¹
            text = (
                reply.get("groundedContent", {})
                .get("content", {})
                .get("text", "")
            )
            if text and not thought:
                full_content += text

    # ========== ç¬¬äºŒæ­¥ï¼šä»æ­£æ–‡ä¸­æå– **æ ‡é¢˜** æ ¼å¼çš„æ€è€ƒæ ‡é¢˜ ==========
    lines = full_content.splitlines()
    filtered_lines = []
    thinking_titles = []
    
    for line in lines:
        # åŒ¹é…å•ç‹¬æˆè¡Œçš„ **æ ‡é¢˜** æ ¼å¼
        m = re.match(r'^\s*\*\*([^*]+)\*\*\s*$', line)
        if m:
            title_text = m.group(1).strip()
            # åˆ¤æ–­æ˜¯å¦æ˜¯æ€è€ƒæ ‡é¢˜ï¼šè‹±æ–‡çŸ­è¯­ï¼Œé•¿åº¦é€‚ä¸­ï¼Œä¸è¶…è¿‡6ä¸ªå•è¯
            if (re.match(r'^[A-Za-z\s\'\-\(\)]+$', title_text) and 
                len(title_text) < 100 and 
                len(title_text.split()) <= 6):
                thinking_titles.append(title_text)
                continue  # è·³è¿‡æ€è€ƒæ ‡é¢˜è¡Œ
        filtered_lines.append(line)
    
    if thinking_titles:
        thinking_parts.extend(thinking_titles)
    
    # æ›´æ–°æ­£æ–‡å†…å®¹ï¼ˆå·²ç§»é™¤æ€è€ƒæ ‡é¢˜ï¼‰
    full_content = "\n".join(filtered_lines).strip()

    # ========== ç¬¬ä¸‰æ­¥ï¼šå¤„ç†å¹¶å‘é€æ€è€ƒè¿‡ç¨‹ ==========
    if thinking_parts:
        thinking_content = "\n\n".join(thinking_parts)
        thinking_html = f"<details><summary>æ˜¾ç¤ºæ€è·¯</summary>\n\n{thinking_content}\n\n</details>\n\n"
        full_content = thinking_html + full_content
        
        if is_stream:
            # å‘é€ thinking å­—æ®µï¼ˆå…¼å®¹æ”¯æŒè¯¥å­—æ®µçš„å‰ç«¯ï¼‰
            thinking_chunk = create_chunk(
                chat_id, created_time, model_name, {"thinking": thinking_content}, None
            )
            yield f"data: {thinking_chunk}\n\n"
        logger.info(f"ğŸ“ æå–åˆ° {len(thinking_parts)} ä¸ªæ€è€ƒæ­¥éª¤ [{account.name}]")

    # ========== ç¬¬å››æ­¥ï¼šæµå¼å‘é€æ­£æ–‡å†…å®¹ï¼ˆé€å­—è¾“å‡ºï¼‰ ==========
    if full_content:
        if is_stream:
            # æµå¼è¾“å‡ºï¼šå°†å†…å®¹åˆ†å—å‘é€ï¼Œæ¨¡æ‹Ÿé€å­—è¾“å‡º
            # ä½¿ç”¨è¾ƒå°çš„åˆ†å—å’Œé€‚å½“çš„å»¶è¿Ÿï¼Œå®ç°å¹³æ»‘çš„æµå¼æ•ˆæœ
            chunk_size = 4  # æ¯æ¬¡å‘é€4ä¸ªå­—ç¬¦ï¼Œå¹³è¡¡æµç•…åº¦å’Œæ€§èƒ½
            sent_length = 0
            total_chunks = 0
            
            while sent_length < len(full_content):
                # è®¡ç®—æœ¬æ¬¡è¦å‘é€çš„å†…å®¹
                end_pos = min(sent_length + chunk_size, len(full_content))
                delta_content = full_content[sent_length:end_pos]
                
                if delta_content:
                    chunk = create_chunk(
                        chat_id, created_time, model_name, {"content": delta_content}, None
                    )
                    yield f"data: {chunk}\n\n"
                    sent_length = end_pos
                    total_chunks += 1
                    # æ·»åŠ å»¶è¿Ÿï¼Œæ¨¡æ‹ŸçœŸå®æµå¼è¾“å‡ºï¼ˆ30msï¼Œçº¦æ¯ç§’33ä¸ªå­—ç¬¦ï¼‰
                    # è¿™ä¸ªé€Ÿåº¦æ—¢ä¸ä¼šå¤ªå¿«ä¹Ÿä¸ä¼šå¤ªæ…¢ï¼Œé€‚åˆå¤§å¤šæ•°å®¢æˆ·ç«¯
                    await asyncio.sleep(0.03)
            
            logger.debug(f"ğŸ“¤ æµå¼å‘é€å®Œæˆ: {total_chunks} ä¸ªæ•°æ®å—, æ€»é•¿åº¦ {len(full_content)} å­—ç¬¦")
        else:
            # éæµå¼ï¼šä¸€æ¬¡æ€§å‘é€å®Œæ•´å†…å®¹
            chunk = create_chunk(
                chat_id, created_time, model_name, {"content": full_content}, None
            )
            yield f"data: {chunk}\n\n"

    # ========== ç¬¬äº”æ­¥ï¼šè§£æå¹¶ä¸‹è½½ç”Ÿæˆçš„å›¾ç‰‡ ==========
    image_file_ids, response_session = parse_images_from_response(data_list)
    
    if response_session and response_session != session:
        logger.info(f"ğŸ”„ æ£€æµ‹åˆ°æ–° Session [{account.name}]: ...{response_session[-15:]}")

    if image_file_ids:
        logger.info(f"ğŸ–¼ï¸  æ£€æµ‹åˆ° {len(image_file_ids)} ä¸ªç”Ÿæˆå›¾ç‰‡ [{account.name}]")
        session_for_download = response_session or session

        try:
            file_metadata = await get_session_file_metadata(account, session_for_download)
            existing_image_count = 0

            for idx, finfo in enumerate(image_file_ids):
                fid = finfo["fileId"]
                mime = finfo["mimeType"]
                meta = file_metadata.get(fid, {})
                file_name = meta.get("name")
                session_path = meta.get("session") or session_for_download

                image_index = existing_image_count + idx + 1
                img = await save_generated_image(account, session_path, fid, file_name, mime, chat_id, image_index)
                generated_images.append(img)

        except Exception as e:
            logger.error(f"âŒ å¤„ç†ç”Ÿæˆå›¾ç‰‡å¤±è´¥ [{account.name}]: {e}", exc_info=True)

    # ========== ç¬¬å…­æ­¥ï¼šå°†å›¾ç‰‡é“¾æ¥æ·»åŠ åˆ°æ–‡æœ¬å†…å®¹ä¸­ ==========
    if generated_images:
        image_markdown = "\n\n"
        for img in generated_images:
            if img.base64_data:
                image_markdown += f"![ç”Ÿæˆçš„å›¾ç‰‡](data:{img.mime_type};base64,{img.base64_data})\n\n"
        
        if image_markdown.strip():
            full_content += image_markdown
            if is_stream:
                chunk = create_chunk(
                    chat_id, created_time, model_name, {"content": image_markdown}, None
                )
                yield f"data: {chunk}\n\n"
            logger.info(f"âœ… å·²å°† {len(generated_images)} å¼ å›¾ç‰‡æ·»åŠ åˆ°å›å¤ä¸­ [{account.name}]")

    if is_stream:
        final_chunk = create_chunk(
            chat_id, created_time, model_name, {}, "stop"
        )
        yield f"data: {final_chunk}\n\n"
        yield "data: [DONE]\n\n"


@app.on_event("startup")
async def _startup_event() -> None:
    """å¯åŠ¨æ—¶åˆå§‹åŒ–æ•°æ®åº“å’Œç®¡ç†å‘˜è´¦å·"""
    init_db()
    db = next(get_db())
    try:
        init_admin(db)
    finally:
        db.close()


@app.on_event("shutdown")
async def _shutdown_event() -> None:
    try:
        await http_client.aclose()
    except Exception:  # noqa: BLE001
        pass


if __name__ == "__main__":
    # è‡³å°‘éœ€è¦æœ‰ä¸€ä¸ªè´¦å·é…ç½®
    if not ACCOUNTS:
        logger.error("No Gemini business accounts configured.")
        logger.error(
            "Set SECURE_C_SES/CSESIDX/CONFIG_ID or ACCOUNT1_* env variables first."
        )
        raise SystemExit(1)

    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=5000)
