import json
import time
import hmac
import hashlib
import base64
import os
import asyncio
import uuid
import ssl
import re
from datetime import datetime, timedelta, timezone
from typing import List, Optional, Union, Dict, Any
from dataclasses import dataclass, field
from pathlib import Path
import logging

import httpx
from fastapi import FastAPI, HTTPException, Request, Depends, WebSocket, WebSocketDisconnect  # noqa: F401
from contextlib import asynccontextmanager
from fastapi.responses import StreamingResponse, RedirectResponse
from fastapi.staticfiles import StaticFiles
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sqlalchemy.orm import Session
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger
import subprocess
import sys
import signal

from database import init_db, get_db, Admin, APIKey, APICallLog, KeepAliveTask, KeepAliveLog, KeepAliveAccountLog, AccountCookieStatus
from auth import (
    hash_password, verify_password, create_access_token, 
    generate_api_key, hash_api_key, get_current_admin, init_admin,
    encrypt_api_key, decrypt_api_key
)


# ---------- æœ¬åœ° .env åŠ è½½ï¼ˆä¾¿äºç›´æ¥ python main.py è¿è¡Œï¼‰ ----------
def _load_env_file(path: str = ".env") -> None:
    if not os.path.exists(path):
        return
    try:
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith("#"):
                    continue
                if "=" not in line:
                    continue
                key, value = line.split("=", 1)
                key = key.strip()
                value = value.strip()
                # å»é™¤å¼•å·ï¼ˆæ”¯æŒå•å¼•å·å’ŒåŒå¼•å·ï¼‰
                if value.startswith('"') and value.endswith('"'):
                    value = value[1:-1]
                elif value.startswith("'") and value.endswith("'"):
                    value = value[1:-1]
                if key and key not in os.environ:
                    os.environ[key] = value
    except Exception:
        # æœ¬åœ°åŠ è½½å¤±è´¥ç›´æ¥å¿½ç•¥ï¼Œä¿æŒä¸åŸç¯å¢ƒä¸€è‡´
        pass


_load_env_file()


# ---------- æ—¥å¿—é…ç½® ----------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger("gemini")

# ---------- æ—¶åŒºé…ç½® ----------
# åŒ—äº¬æ—¶é—´ UTC+8
BEIJING_TZ = timezone(timedelta(hours=8))

def get_beijing_time():
    """è·å–å½“å‰åŒ—äº¬æ—¶é—´"""
    return datetime.now(BEIJING_TZ)

def ensure_aware(dt: datetime) -> datetime:
    """ç¡®ä¿ datetime æ˜¯ awareï¼ˆæœ‰æ—¶åŒºä¿¡æ¯ï¼‰"""
    if dt is None:
        return None
    if dt.tzinfo is None:
        # å¦‚æœæ˜¯ naive datetimeï¼Œå‡è®¾å®ƒæ˜¯åŒ—äº¬æ—¶é—´å¹¶æ·»åŠ æ—¶åŒºä¿¡æ¯
        return dt.replace(tzinfo=BEIJING_TZ)
    return dt

def ensure_naive(dt: datetime) -> datetime:
    """ç¡®ä¿ datetime æ˜¯ naiveï¼ˆæ— æ—¶åŒºä¿¡æ¯ï¼‰ï¼Œè½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´åç§»é™¤æ—¶åŒº"""
    if dt is None:
        return None
    if dt.tzinfo is not None:
        # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´åç§»é™¤æ—¶åŒºä¿¡æ¯
        return dt.astimezone(BEIJING_TZ).replace(tzinfo=None)
    return dt

# ---------- é…ç½® ----------
SECURE_C_SES = os.getenv("SECURE_C_SES")
HOST_C_OSES = os.getenv("HOST_C_OSES")
CSESIDX = os.getenv("CSESIDX")
CONFIG_ID = os.getenv("CONFIG_ID")
PROXY_RAW = os.getenv("PROXY") or None
# å»é™¤ä»£ç†é…ç½®ä¸­å¯èƒ½å­˜åœ¨çš„å¼•å·
if PROXY_RAW:
    PROXY_RAW = PROXY_RAW.strip().strip('"').strip("'")
    PROXY = PROXY_RAW if PROXY_RAW else None
else:
    PROXY = None
TIMEOUT_SECONDS = int(os.getenv("TIMEOUT_SECONDS", "600"))

# ---------- å›¾ç‰‡ç”Ÿæˆç›¸å…³å¸¸é‡ ----------
BASE_DIR = Path(__file__).resolve().parent
IMAGE_SAVE_DIR = BASE_DIR / "generated_images"
LIST_FILE_METADATA_URL = "https://biz-discoveryengine.googleapis.com/v1alpha/locations/global/widgetListSessionFileMetadata"

# ---------- å›¾ç‰‡æ•°æ®ç±» ----------
@dataclass
class ChatImage:
    """è¡¨ç¤ºç”Ÿæˆçš„å›¾ç‰‡"""
    file_id: Optional[str] = None
    file_name: Optional[str] = None
    base64_data: Optional[str] = None
    url: Optional[str] = None
    local_path: Optional[str] = None
    mime_type: str = "image/png"

    def save_to_file(self, directory: Optional[Path] = None) -> str:
        """ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œè¿”å›æ–‡ä»¶è·¯å¾„"""
        if self.local_path and os.path.exists(self.local_path):
            return self.local_path

        save_dir = directory or IMAGE_SAVE_DIR
        os.makedirs(save_dir, exist_ok=True)

        ext = ".png"
        if self.mime_type:
            ext_map = {
                "image/png": ".png",
                "image/jpeg": ".jpg",
                "image/gif": ".gif",
                "image/webp": ".webp",
            }
            ext = ext_map.get(self.mime_type, ".png")

        if self.file_name:
            filename = self.file_name
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"gemini_{timestamp}_{uuid.uuid4().hex[:8]}{ext}"

        filepath = os.path.join(save_dir, filename)

        if self.base64_data:
            image_data = base64.b64decode(self.base64_data)
            with open(filepath, "wb") as f:
                f.write(image_data)
            self.local_path = filepath

        return filepath

# ---------- æ¨¡å‹æ˜ å°„é…ç½® ----------
MODEL_MAPPING: Dict[str, Optional[str]] = {
    "gemini-auto": None,
    "gemini-2.5-flash": "gemini-2.5-flash",
    "gemini-2.5-pro": "gemini-2.5-pro",
    "gemini-3-pro-preview": "gemini-3-pro-preview"
}

# ---------- å…¨å±€ Session ç¼“å­˜ ----------
# key: conversation_key -> {"session_id": str, "updated_at": float, "account": str}
SESSION_CACHE: Dict[str, Dict[str, Any]] = {}

# ---------- WebSocket ç®¡ç† ----------
class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            try:
                await connection.send_text(message)
            except Exception:
                pass

manager = ConnectionManager()

# ---------- HTTP å®¢æˆ·ç«¯ ----------
# è®°å½•ä»£ç†é…ç½®ä¿¡æ¯
if PROXY:
    logger.info(f"ğŸŒ ä»£ç†é…ç½®: {PROXY}")
else:
    logger.info("ğŸŒ æœªé…ç½®ä»£ç†ï¼Œä½¿ç”¨ç›´è¿")
http_client = httpx.AsyncClient(
    proxy=PROXY,
    verify=False,
    http2=False,
    timeout=httpx.Timeout(TIMEOUT_SECONDS, connect=60.0),
    limits=httpx.Limits(max_keepalive_connections=20, max_connections=50),
)


# ---------- é€šç”¨å·¥å…·å‡½æ•° ----------
def get_common_headers(jwt: str) -> dict:
    return {
        "accept": "*/*",
        "accept-encoding": "gzip, deflate, br, zstd",
        "accept-language": "zh-CN,zh;q=0.9,en;q=0.8",
        "authorization": f"Bearer {jwt}",
        "content-type": "application/json",
        "origin": "https://business.gemini.google",
        "referer": "https://business.gemini.google/",
        "user-agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/140.0.0.0 Safari/537.36"
        ),
        "x-server-timeout": "1800",
        "sec-ch-ua": '"Chromium";v="124", "Google Chrome";v="124", "Not-A.Brand";v="99"',
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": '"Windows"',
        "sec-fetch-dest": "empty",
        "sec-fetch-mode": "cors",
        "sec-fetch-site": "cross-site",
    }


def urlsafe_b64encode(data: bytes) -> str:
    return base64.urlsafe_b64encode(data).decode().rstrip("=")


def kq_encode(s: str) -> str:
    b = bytearray()
    for ch in s:
        v = ord(ch)
        if v > 255:
            b.append(v & 255)
            b.append(v >> 8)
        else:
            b.append(v)
    return urlsafe_b64encode(bytes(b))


def create_jwt(key_bytes: bytes, key_id: str, csesidx: str) -> str:
    now = int(time.time())
    header = {"alg": "HS256", "typ": "JWT", "kid": key_id}
    payload = {
        "iss": "https://business.gemini.google",
        "aud": "https://biz-discoveryengine.googleapis.com",
        "sub": f"csesidx/{csesidx}",
        "iat": now,
        "exp": now + 300,
        "nbf": now,
    }
    header_b64 = kq_encode(json.dumps(header, separators=(",", ":")))
    payload_b64 = kq_encode(json.dumps(payload, separators=(",", ":")))
    message = f"{header_b64}.{payload_b64}"
    sig = hmac.new(key_bytes, message.encode(), hashlib.sha256).digest()
    return f"{message}.{urlsafe_b64encode(sig)}"


# ---------- JWT ä¸è´¦å·ç®¡ç† ----------
class JWTManager:
    def __init__(self, account: "Account") -> None:
        self.account = account
        self.jwt: str = ""
        self.expires: float = 0
        self._lock = asyncio.Lock()

    async def get(self) -> str:
        async with self._lock:
            if time.time() > self.expires:
                await self._refresh()
            return self.jwt

    async def _refresh(self) -> None:
        cookie = f"__Secure-C_SES={self.account.secure_c_ses}"
        if self.account.host_c_oses:
            cookie += f"; __Host-C_OSES={self.account.host_c_oses}"

        logger.debug(f"ğŸ”‘ æ­£åœ¨åˆ·æ–° JWT... è´¦å·={self.account.name}")
        r = await http_client.get(
            "https://business.gemini.google/auth/getoxsrf",
            params={"csesidx": self.account.csesidx},
            headers={
                "cookie": cookie,
                "user-agent": (
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 (KHTML, like Gecko) "
                    "Chrome/140.0.0.0 Safari/537.36"
                ),
                "referer": "https://business.gemini.google/",
            },
        )
        if r.status_code != 200:
            logger.error(
                f"getoxsrf å¤±è´¥ [{self.account.name}]: {r.status_code} {r.text}"
            )
            if r.status_code in (401, 403, 429):
                self.account.mark_quota_error(r.status_code, r.text)
            raise HTTPException(r.status_code, "getoxsrf failed")

        # å°è¯•ä»å“åº”å¤´ä¸­è§£æ Cookie è¿‡æœŸæ—¶é—´
        cookie_expires_at = None
        try:
            # æ£€æŸ¥å“åº”å¤´ä¸­æ˜¯å¦æœ‰ Set-Cookie
            logger.debug(f"æ£€æŸ¥å“åº”å¤´ä¸­çš„ Set-Cookie...")
            logger.debug(f"æ‰€æœ‰å“åº”å¤´: {dict(r.headers)}")
            
            # httpx ä½¿ç”¨ get_list æˆ– getall è·å–æ‰€æœ‰åŒåå¤´éƒ¨
            set_cookie_headers = []
            if hasattr(r.headers, 'get_list'):
                set_cookie_headers = r.headers.get_list("set-cookie", [])
            elif hasattr(r.headers, 'getall'):
                set_cookie_headers = r.headers.getall("set-cookie", [])
            else:
                # å¦‚æœæ²¡æœ‰è¿™äº›æ–¹æ³•ï¼Œå°è¯•ç›´æ¥è·å–
                set_cookie_header = r.headers.get("set-cookie")
                if set_cookie_header:
                    set_cookie_headers = [set_cookie_header]
            
            logger.debug(f"æ‰¾åˆ° {len(set_cookie_headers)} ä¸ª Set-Cookie å¤´")
            
            if set_cookie_headers:
                from http.cookies import SimpleCookie
                from database import get_beijing_time
                for set_cookie in set_cookie_headers:
                    try:
                        # è§£æ Set-Cookie å¤´
                        cookie_obj = SimpleCookie()
                        cookie_obj.load(set_cookie)
                        for cookie_name, cookie_attrs in cookie_obj.items():
                            if cookie_name in ("__Secure-C_SES", "__Host-C_OSES"):
                                # æ£€æŸ¥ Expires å±æ€§
                                if "expires" in cookie_attrs:
                                    expires_str = cookie_attrs["expires"]
                                    try:
                                        # è§£æ RFC 1123 æ ¼å¼çš„æ—¥æœŸï¼ˆGMT/UTCï¼‰
                                        # æ³¨æ„ï¼šéœ€è¦å¤„ç†æ—¶åŒºï¼Œè½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´ï¼ˆnaiveï¼‰
                                        from email.utils import parsedate_to_datetime
                                        expires_dt = parsedate_to_datetime(expires_str)
                                        # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´ï¼ˆnaiveï¼‰
                                        if expires_dt.tzinfo:
                                            expires_dt = expires_dt.astimezone(timezone(timedelta(hours=8)))
                                            cookie_expires_at = expires_dt.replace(tzinfo=None)
                                        else:
                                            cookie_expires_at = expires_dt
                                        logger.debug(f"ä» Set-Cookie è§£æåˆ°è¿‡æœŸæ—¶é—´: {cookie_expires_at}")
                                        break
                                    except (ValueError, TypeError) as e:
                                        logger.debug(f"è§£æ Expires å¤±è´¥: {e}")
                                # æ£€æŸ¥ Max-Age å±æ€§
                                elif "max-age" in cookie_attrs:
                                    try:
                                        max_age = int(cookie_attrs["max-age"])
                                        # ä½¿ç”¨åŒ—äº¬æ—¶é—´
                                        cookie_expires_at = get_beijing_time() + timedelta(seconds=max_age)
                                        logger.debug(f"ä» Max-Age è®¡ç®—è¿‡æœŸæ—¶é—´: {cookie_expires_at}")
                                        break
                                    except (ValueError, TypeError) as e:
                                        logger.debug(f"è§£æ Max-Age å¤±è´¥: {e}")
                    except Exception as e:
                        logger.debug(f"è§£æ Set-Cookie å¤±è´¥: {e}")
            else:
                logger.debug(f"å“åº”å¤´ä¸­æ²¡æœ‰ Set-Cookieï¼ŒGoogle API å¯èƒ½ä¸ä¼šåœ¨æ¯æ¬¡è¯·æ±‚æ—¶è¿”å› Cookie è¿‡æœŸä¿¡æ¯")
        except Exception as e:
            logger.debug(f"è·å– Set-Cookie å“åº”å¤´å¤±è´¥: {e}")
        
        # å¦‚æœæ— æ³•ä»å“åº”å¤´è·å–ï¼Œä¿å­˜åˆ° account å¯¹è±¡ä¾›åç»­ä½¿ç”¨
        if cookie_expires_at:
            self.account._cookie_expires_at = cookie_expires_at
            logger.info(f"âœ… æˆåŠŸè·å– Cookie è¿‡æœŸæ—¶é—´ [{self.account.name}]: {cookie_expires_at}")
        else:
            logger.debug(f"âš ï¸ æ— æ³•ä»å“åº”å¤´è·å– Cookie è¿‡æœŸæ—¶é—´ [{self.account.name}]")

        txt = r.text[4:] if r.text.startswith(")]}'") else r.text
        data = json.loads(txt)

        key_bytes = base64.urlsafe_b64decode(data["xsrfToken"] + "==")
        self.jwt = create_jwt(key_bytes, data["keyId"], self.account.csesidx)
        self.expires = time.time() + 270
        logger.info(f"JWT åˆ·æ–°æˆåŠŸ [{self.account.name}]")


class Account:
    def __init__(
        self,
        name: str,
        secure_c_ses: str,
        csesidx: str,
        config_id: str,
        host_c_oses: Optional[str] = None,
    ) -> None:
        self.name = name
        self.secure_c_ses = secure_c_ses
        self.host_c_oses = host_c_oses
        self.csesidx = csesidx
        self.config_id = config_id
        self.jwt_mgr = JWTManager(self)
        self._cookie_expires_at = None  # Cookie è¿‡æœŸæ—¶é—´ï¼ˆå¦‚æœå¯è·å–ï¼‰
        self.disabled_until: float = 0.0

    def is_available(self) -> bool:
        return time.time() >= self.disabled_until

    def mark_quota_error(self, status_code: int, detail: str = "") -> None:
        cooldown_seconds = 300  # æš‚åœ 5 åˆ†é’Ÿ
        self.disabled_until = max(self.disabled_until, time.time() + cooldown_seconds)
        logger.warning(f"è´¦å·[{self.name}] æš‚æ—¶æ ‡è®°ä¸ºä¸å¯ç”¨ (status={status_code})")
        if detail:
            logger.debug(f"è´¦å·[{self.name}] é”™è¯¯è¯¦æƒ…: {detail[:200]}")


class AccountPool:
    def __init__(self, accounts: List[Account]) -> None:
        if not accounts:
            raise RuntimeError("No Gemini business accounts configured")
        self.accounts = accounts
        self._rr_index = 0

    def _next_round_robin(self) -> Account:
        n = len(self.accounts)
        for _ in range(n):
            acc = self.accounts[self._rr_index % n]
            self._rr_index = (self._rr_index + 1) % n
            if acc.is_available():
                return acc
        # å¦‚æœéƒ½è¢«æ ‡è®°ä¸ºä¸å¯ç”¨ï¼Œä»ç„¶è¿”å›ä¸€ä¸ªè´¦å·é¿å…å®Œå…¨ç˜«ç—ª
        return self.accounts[0]

    def get_for_conversation(self, conv_key: str) -> Account:
        cached = SESSION_CACHE.get(conv_key)
        if cached:
            acc_name = cached.get("account")
            for acc in self.accounts:
                if acc.name == acc_name and acc.is_available():
                    return acc
        # æ²¡æœ‰ç¼“å­˜æˆ–è´¦å·ä¸å¯ç”¨ï¼Œèµ°è½®è¯¢
        return self._next_round_robin()

    def get_alternative(self, exclude_name: str) -> Optional[Account]:
        for acc in self.accounts:
            if acc.name != exclude_name and acc.is_available():
                return acc
        return None


def load_accounts_from_env() -> List[Account]:
    accounts: List[Account] = []

    # æ”¯æŒ ACCOUNT1_*, ACCOUNT2_*... å¤šè´¦å·é…ç½®
    account_indices = set()
    for key in os.environ.keys():
        if key.startswith("ACCOUNT") and key.endswith("_SECURE_C_SES"):
            idx_str = key[len("ACCOUNT") : -len("_SECURE_C_SES")]
            try:
                idx = int(idx_str)
            except ValueError:
                continue
            account_indices.add(idx)

    for idx in sorted(account_indices):
        prefix = f"ACCOUNT{idx}_"
        secure = os.getenv(prefix + "SECURE_C_SES")
        csesidx = os.getenv(prefix + "CSESIDX")
        config_id = os.getenv(prefix + "CONFIG_ID")
        host = os.getenv(prefix + "HOST_C_OSES")
        if not (secure and csesidx and config_id):
            logger.warning(f"è´¦å·ç´¢å¼• {idx} é…ç½®ä¸å®Œæ•´ï¼Œå·²è·³è¿‡")
            continue
        # å»é™¤å¯èƒ½å­˜åœ¨çš„å¼•å·ï¼ˆåŒé‡ä¿é™©ï¼‰
        secure = secure.strip().strip('"').strip("'") if secure else None
        csesidx = csesidx.strip().strip('"').strip("'") if csesidx else None
        config_id = config_id.strip().strip('"').strip("'") if config_id else None
        # å»é™¤ config_id ä¸­å¯èƒ½å­˜åœ¨çš„ ?csesidx åç¼€
        if config_id and '?csesidx' in config_id:
            config_id = config_id.split('?csesidx')[0]
        host = host.strip().strip('"').strip("'") if host else None
        name = os.getenv(prefix + "NAME") or f"account-{idx}"
        if name:
            name = name.strip().strip('"').strip("'")
        accounts.append(
            Account(
                name=name,
                secure_c_ses=secure,
                csesidx=csesidx,
                config_id=config_id,
                host_c_oses=host,
            )
        )

    # å…¼å®¹æ—§çš„å•è´¦å·ç¯å¢ƒå˜é‡
    if not accounts and SECURE_C_SES and CSESIDX and CONFIG_ID:
        # å»é™¤å¯èƒ½å­˜åœ¨çš„å¼•å·
        secure_c_ses = SECURE_C_SES.strip().strip('"').strip("'") if SECURE_C_SES else None
        csesidx = CSESIDX.strip().strip('"').strip("'") if CSESIDX else None
        config_id = CONFIG_ID.strip().strip('"').strip("'") if CONFIG_ID else None
        # å»é™¤ config_id ä¸­å¯èƒ½å­˜åœ¨çš„ ?csesidx åç¼€
        if config_id and '?csesidx' in config_id:
            config_id = config_id.split('?csesidx')[0]
        host_c_oses = HOST_C_OSES.strip().strip('"').strip("'") if HOST_C_OSES else None
        accounts.append(
            Account(
                name="default",
                secure_c_ses=secure_c_ses,
                csesidx=csesidx,
                config_id=config_id,
                host_c_oses=host_c_oses,
            )
        )

    return accounts


ACCOUNTS: List[Account] = load_accounts_from_env()
ACCOUNT_POOL: Optional["AccountPool"]
if ACCOUNTS:
    ACCOUNT_POOL = AccountPool(ACCOUNTS)
else:
    ACCOUNT_POOL = None


def reload_accounts_from_env_file() -> None:
    """ä» .env æ–‡ä»¶é‡æ–°åŠ è½½è´¦å·é…ç½®ï¼ˆåŠ¨æ€é‡è½½ï¼Œæ— éœ€é‡å¯ï¼‰"""
    global ACCOUNTS, ACCOUNT_POOL, PROXY
    
    # é‡æ–°è¯»å– .env æ–‡ä»¶å¹¶æ›´æ–°ç¯å¢ƒå˜é‡
    lines = read_env_file()
    for line_data in lines:
        line = line_data["raw"].strip()
        if not line or line.startswith("#") or "=" not in line:
            continue
        key, value = line.split("=", 1)
        key = key.strip()
        # å»æ‰é¦–å°¾çš„å¼•å·ï¼ˆæ”¯æŒå•å¼•å·å’ŒåŒå¼•å·ï¼‰
        value = value.strip()
        if (value.startswith('"') and value.endswith('"')) or (value.startswith("'") and value.endswith("'")):
            value = value[1:-1]
        # å»é™¤ config_id ä¸­å¯èƒ½å­˜åœ¨çš„ ?csesidx åç¼€
        if key.endswith("_CONFIG_ID") or key == "CONFIG_ID":
            if '?csesidx' in value:
                value = value.split('?csesidx')[0]
        # æ›´æ–°ç¯å¢ƒå˜é‡
        os.environ[key] = value
        # å¦‚æœæ›´æ–°äº† PROXYï¼ŒåŒæ­¥æ›´æ–°å…¨å±€å˜é‡
        if key == "PROXY":
            PROXY_RAW = value.strip().strip('"').strip("'") if value else None
            PROXY = PROXY_RAW if PROXY_RAW else None
            if PROXY:
                logger.info(f"ğŸ”„ ä»£ç†é…ç½®å·²æ›´æ–°: {PROXY}")
            else:
                logger.info("ğŸ”„ ä»£ç†é…ç½®å·²æ¸…é™¤")
    
    # é‡æ–°åŠ è½½è´¦å·
    ACCOUNTS = load_accounts_from_env()
    
    # é‡æ–°åˆ›å»ºè´¦å·æ± 
    if ACCOUNTS:
        ACCOUNT_POOL = AccountPool(ACCOUNTS)
        logger.info(f"ğŸ”„ è´¦å·é…ç½®å·²é‡æ–°åŠ è½½ï¼Œå…± {len(ACCOUNTS)} ä¸ªè´¦å·")
    else:
        ACCOUNT_POOL = None
        logger.warning("âš ï¸ é‡æ–°åŠ è½½åæ²¡æœ‰å¯ç”¨è´¦å·")


# ---------- Session & File ç®¡ç† ----------
async def create_google_session(account: Account) -> str:
    jwt = await account.jwt_mgr.get()
    headers = get_common_headers(jwt)
    body = {
        "configId": account.config_id,
        "additionalParams": {"token": "-"},
        "createSessionRequest": {"session": {"name": "", "displayName": ""}},
    }

    logger.info(f"ğŸŒ ç”³è¯· Session... è´¦å·={account.name}, configId={account.config_id}")
    r = await http_client.post(
        "https://biz-discoveryengine.googleapis.com/v1alpha/locations/global/widgetCreateSession",
        headers=headers,
        json=body,
    )
    if r.status_code != 200:
        logger.error(
            f"createSession å¤±è´¥ [{account.name}]: {r.status_code}, configId={account.config_id}, å“åº”={r.text}"
        )
        if r.status_code in (401, 403, 429):
            account.mark_quota_error(r.status_code, r.text)
        raise HTTPException(r.status_code, "createSession failed")
    sess_name = r.json()["session"]["name"]
    return sess_name


async def upload_context_file(
    account: Account, session_name: str, mime_type: str, base64_content: str
) -> str:
    """ä¸Šä¼ æ–‡ä»¶åˆ°æŒ‡å®š Sessionï¼Œè¿”å› fileId"""
    jwt = await account.jwt_mgr.get()
    headers = get_common_headers(jwt)

    ext = mime_type.split("/")[-1] if "/" in mime_type else "bin"
    file_name = f"upload_{int(time.time())}_{uuid.uuid4().hex[:6]}.{ext}"

    body = {
        "configId": account.config_id,
        "additionalParams": {"token": "-"},
        "addContextFileRequest": {
            "name": session_name,
            "fileName": file_name,
            "mimeType": mime_type,
            "fileContents": base64_content,
        },
    }

    logger.info(f"ğŸ“¤ ä¸Šä¼ å›¾ç‰‡ [{mime_type}] åˆ° Sessionï¼Œè´¦å·={account.name}")
    r = await http_client.post(
        "https://biz-discoveryengine.googleapis.com/v1alpha/locations/global/widgetAddContextFile",
        headers=headers,
        json=body,
    )

    if r.status_code != 200:
        logger.error(
            f"ä¸Šä¼ æ–‡ä»¶å¤±è´¥ [{account.name}]: {r.status_code} {r.text}"
        )
        if r.status_code in (401, 403, 429):
            account.mark_quota_error(r.status_code, r.text)
        raise HTTPException(r.status_code, f"Upload failed: {r.text}")

    data = r.json()
    file_id = data.get("addContextFileResponse", {}).get("fileId")
    logger.info(f"å›¾ç‰‡ä¸Šä¼ æˆåŠŸ, ID: {file_id}, è´¦å·={account.name}")
    return file_id


# ---------- æ¶ˆæ¯å¤„ç†é€»è¾‘ ----------
def get_conversation_key(messages: List[dict]) -> str:
    if not messages:
        return "empty"
    first_msg = messages[0].copy()
    if isinstance(first_msg.get("content"), list):
        text_part = "".join(
            [x.get("text", "") for x in first_msg["content"] if x.get("type") == "text"]
        )
        first_msg["content"] = text_part

    key_str = json.dumps(first_msg, sort_keys=True, ensure_ascii=False)
    return hashlib.md5(key_str.encode("utf-8")).hexdigest()


def parse_last_message(messages: List["Message"]):
    """è§£ææœ€åä¸€æ¡æ¶ˆæ¯ï¼Œåˆ†ç¦»æ–‡æœ¬å’Œå›¾ç‰‡"""
    if not messages:
        return "", []

    last_msg = messages[-1]
    content = last_msg.content

    text_content = ""
    images = []  # List of {"mime": str, "data": str_base64}

    if isinstance(content, str):
        text_content = content
    elif isinstance(content, list):
        for part in content:
            if part.get("type") == "text":
                text_content += part.get("text", "")
            elif part.get("type") == "image_url":
                url = part.get("image_url", {}).get("url", "")
                match = re.match(r"data:(image/[^;]+);base64,(.+)", url)
                if match:
                    images.append(
                        {"mime": match.group(1), "data": match.group(2)}
                    )
                else:
                    logger.warning(
                        f"æš‚ä¸æ”¯æŒé Base64 å›¾ç‰‡é“¾æ¥: {url[:30]}..."
                    )

    return text_content, images


def build_full_context_text(messages: List["Message"]) -> str:
    """ä»…æ‹¼æ¥å†å²æ–‡æœ¬ï¼Œå›¾ç‰‡åªå¤„ç†å½“æ¬¡è¯·æ±‚çš„"""
    prompt = ""
    for msg in messages:
        role = "User" if msg.role in ["user", "system"] else "Assistant"
        content_str = ""
        if isinstance(msg.content, str):
            content_str = msg.content
        elif isinstance(msg.content, list):
            for part in msg.content:
                if part.get("type") == "text":
                    content_str += part.get("text", "")
                elif part.get("type") == "image_url":
                    content_str += "[å›¾ç‰‡]"

        prompt += f"{role}: {content_str}\n\n"
    return prompt


# ---------- å›¾ç‰‡ç”Ÿæˆå¤„ç†æ–¹æ³• ----------
async def get_session_file_metadata(account: Account, session_name: str) -> dict:
    """è·å– session ä¸­çš„æ–‡ä»¶å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬ä¸‹è½½é“¾æ¥"""
    jwt = await account.jwt_mgr.get()
    headers = get_common_headers(jwt)
    body = {
        "configId": account.config_id,
        "additionalParams": {"token": "-"},
        "listSessionFileMetadataRequest": {
            "name": session_name,
            "filter": "file_origin_type = AI_GENERATED"
        }
    }

    async with httpx.AsyncClient(proxy=PROXY, verify=False, timeout=30) as cli:
        resp = await cli.post(LIST_FILE_METADATA_URL, headers=headers, json=body)

        if resp.status_code == 401:
            # JWT è¿‡æœŸï¼Œåˆ·æ–°åé‡è¯•
            jwt = await account.jwt_mgr.get()
            headers = get_common_headers(jwt)
            resp = await cli.post(LIST_FILE_METADATA_URL, headers=headers, json=body)

        if resp.status_code != 200:
            logger.warning(f"è·å–æ–‡ä»¶å…ƒæ•°æ®å¤±è´¥ [{account.name}]: {resp.status_code}")
            return {}

        data = resp.json()
        result = {}
        file_metadata_list = data.get("listSessionFileMetadataResponse", {}).get("fileMetadata", [])
        for fm in file_metadata_list:
            fid = fm.get("fileId")
            if fid:
                result[fid] = fm

        return result


def build_image_download_url(session_name: str, file_id: str) -> str:
    """æ„é€ æ­£ç¡®çš„å›¾ç‰‡ä¸‹è½½ URL"""
    return f"https://biz-discoveryengine.googleapis.com/v1alpha/{session_name}:downloadFile?fileId={file_id}&alt=media"


async def download_image_with_jwt(account: Account, session_name: str, file_id: str) -> bytes:
    """ä½¿ç”¨ JWT è®¤è¯ä¸‹è½½å›¾ç‰‡"""
    url = build_image_download_url(session_name, file_id)
    jwt = await account.jwt_mgr.get()
    headers = get_common_headers(jwt)

    async with httpx.AsyncClient(proxy=PROXY, verify=False, timeout=120) as cli:
        resp = await cli.get(url, headers=headers, follow_redirects=True)

        if resp.status_code == 401:
            # JWT è¿‡æœŸï¼Œåˆ·æ–°åé‡è¯•
            jwt = await account.jwt_mgr.get()
            headers = get_common_headers(jwt)
            resp = await cli.get(url, headers=headers, follow_redirects=True)

        resp.raise_for_status()
        content = resp.content

        # æ£€æµ‹æ˜¯å¦ä¸º base64 ç¼–ç çš„å†…å®¹
        try:
            text_content = content.decode("utf-8", errors="ignore").strip()
            if text_content.startswith("iVBORw0KGgo") or text_content.startswith("/9j/"):
                # æ˜¯ base64 ç¼–ç ï¼Œéœ€è¦è§£ç 
                return base64.b64decode(text_content)
        except Exception:
            pass

        return content


async def save_generated_image(account: Account, session_name: str, file_id: str, file_name: Optional[str], mime_type: str, chat_id: str, image_index: int = 1) -> ChatImage:
    """ä¸‹è½½å¹¶ä¿å­˜ç”Ÿæˆçš„å›¾ç‰‡ï¼ŒæŒ‰ chat_id å‘½å"""
    img = ChatImage(
        file_id=file_id,
        file_name=file_name,
        mime_type=mime_type,
    )

    try:
        image_data = await download_image_with_jwt(account, session_name, file_id)
        os.makedirs(IMAGE_SAVE_DIR, exist_ok=True)

        ext = ".png"
        ext_map = {"image/png": ".png", "image/jpeg": ".jpg", "image/gif": ".gif", "image/webp": ".webp"}
        ext = ext_map.get(mime_type, ".png")

        # æŒ‰ {chat_id}_{åºå·}.png å‘½å
        filename = f"{chat_id}_{image_index}{ext}"
        filepath = IMAGE_SAVE_DIR / filename

        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³é¿å…è¦†ç›–
        if filepath.exists():
            timestamp = datetime.now().strftime("%H%M%S")
            filename = f"{chat_id}_{image_index}_{timestamp}{ext}"
            filepath = IMAGE_SAVE_DIR / filename

        with open(filepath, "wb") as f:
            f.write(image_data)

        img.local_path = str(filepath)
        img.file_name = filename
        img.base64_data = base64.b64encode(image_data).decode("utf-8")
        logger.info(f"å›¾ç‰‡å·²ä¿å­˜ [{account.name}]: {filepath}")
    except Exception as e:
        logger.error(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥ [{account.name}]: {e}")

    return img


def parse_images_from_response(data_list: list) -> tuple[list, Optional[str]]:
    """
    ä» API å“åº”ä¸­è§£æå›¾ç‰‡æ–‡ä»¶å¼•ç”¨
    è¿”å›: (file_ids_list, current_session)
    file_ids_list: [{"fileId": str, "mimeType": str}, ...]
    """
    file_ids = []
    current_session = None

    for data in data_list:
        sar = data.get("streamAssistResponse")
        if not sar:
            continue

        # è·å– session ä¿¡æ¯
        session_info = sar.get("sessionInfo", {})
        if session_info.get("session"):
            current_session = session_info["session"]

        answer = sar.get("answer") or {}
        replies = answer.get("replies") or []

        for reply in replies:
            gc = reply.get("groundedContent", {})
            content = gc.get("content", {})

            # æ£€æŸ¥ file å­—æ®µï¼ˆå›¾ç‰‡ç”Ÿæˆçš„å…³é”®ï¼‰
            file_info = content.get("file")
            if file_info and file_info.get("fileId"):
                file_ids.append({
                    "fileId": file_info["fileId"],
                    "mimeType": file_info.get("mimeType", "image/png")
                })

    return file_ids, current_session


# ---------- åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç† ----------
@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶æ‰§è¡Œ
    init_db()
    db = next(get_db())
    try:
        init_admin(db)
        
        # æ¸…ç†é—ç•™çš„"running"çŠ¶æ€ï¼ˆå¯èƒ½æ˜¯ä¸Šæ¬¡å¼‚å¸¸é€€å‡ºå¯¼è‡´çš„ï¼‰
        running_logs = db.query(KeepAliveLog).filter(
            KeepAliveLog.status == "running"
        ).all()
        for log in running_logs:
            log.status = "error"
            log.finished_at = get_beijing_time()
            log.message = "æœåŠ¡é‡å¯ï¼Œè¿›ç¨‹å·²ç»ˆæ­¢"
            
            # æ›´æ–°æ‰€æœ‰è¿è¡Œä¸­çš„è´¦å·æ—¥å¿—
            running_account_logs = db.query(KeepAliveAccountLog).filter(
                KeepAliveAccountLog.task_log_id == log.id,
                KeepAliveAccountLog.status == "running"
            ).all()
            for acc_log in running_account_logs:
                acc_log.status = "error"
                acc_log.finished_at = get_beijing_time()
                acc_log.message = "æœåŠ¡é‡å¯ï¼Œè¿›ç¨‹å·²ç»ˆæ­¢"
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task = db.query(KeepAliveTask).first()
        if task and task.last_status == "running":
            task.last_status = "error"
            task.last_message = "æœåŠ¡é‡å¯ï¼Œè¿›ç¨‹å·²ç»ˆæ­¢"
        
        db.commit()
    finally:
        db.close()
    
    # å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
    scheduler.start()
    setup_keep_alive_scheduler()
    
    yield  # åº”ç”¨è¿è¡ŒæœŸé—´
    
    # å…³é—­æ—¶æ‰§è¡Œ
    try:
        logger.info("ğŸ›‘ æ­£åœ¨å…³é—­æœåŠ¡...")
        
        # å…ˆå…³é—­è°ƒåº¦å™¨ï¼ˆè®¾ç½®è¶…æ—¶ï¼Œé¿å…é˜»å¡ï¼‰
        try:
            scheduler.shutdown(wait=False)  # ä¸ç­‰å¾…ä»»åŠ¡å®Œæˆ
        except Exception as e:
            logger.warning(f"âš ï¸ å…³é—­è°ƒåº¦å™¨æ—¶å‡ºé”™: {e}")
        
        # å…³é—­ HTTP å®¢æˆ·ç«¯ï¼ˆè®¾ç½®è¶…æ—¶ï¼‰
        try:
            await asyncio.wait_for(http_client.aclose(), timeout=2.0)
        except asyncio.TimeoutError:
            logger.warning("âš ï¸ å…³é—­ HTTP å®¢æˆ·ç«¯è¶…æ—¶ï¼Œå¼ºåˆ¶å…³é—­")
        except Exception as e:
            logger.warning(f"âš ï¸ å…³é—­ HTTP å®¢æˆ·ç«¯æ—¶å‡ºé”™: {e}")
        
        # ç¡®ä¿ä¿æ´»è¿›ç¨‹è¢«ç»ˆæ­¢
        async with keep_alive_process_lock:
            if current_keep_alive_process is not None:
                try:
                    logger.info("ğŸ›‘ æ­£åœ¨ç»ˆæ­¢ä¿æ´»è¿›ç¨‹...")
                    current_keep_alive_process.terminate()
                    # ä½¿ç”¨ asyncio.wait_for æ¥è®¾ç½®è¶…æ—¶
                    try:
                        await asyncio.wait_for(
                            asyncio.to_thread(current_keep_alive_process.wait),
                            timeout=3.0
                        )
                    except asyncio.TimeoutError:
                        logger.warning("âš ï¸ ä¿æ´»è¿›ç¨‹æœªåœ¨ 3 ç§’å†…é€€å‡ºï¼Œå¼ºåˆ¶ç»ˆæ­¢")
                        current_keep_alive_process.kill()
                        # å†ç­‰å¾…ä¸€ä¸‹ç¡®ä¿è¿›ç¨‹è¢«æ€æ­»
                        try:
                            await asyncio.wait_for(
                                asyncio.to_thread(current_keep_alive_process.wait),
                                timeout=2.0
                            )
                        except asyncio.TimeoutError:
                            pass
                except Exception as e:
                    logger.warning(f"âš ï¸ ç»ˆæ­¢ä¿æ´»è¿›ç¨‹æ—¶å‡ºé”™: {e}")
        
        logger.info("âœ… æœåŠ¡å·²å…³é—­")
    except Exception as e:  # noqa: BLE001
        logger.error(f"âŒ å…³é—­æœåŠ¡æ—¶å‡ºé”™: {e}")


# ---------- OpenAI å…¼å®¹æ¥å£ ----------
app = FastAPI(title="Gemini-Business OpenAI Gateway", lifespan=lifespan)

# ---------- CORS é…ç½®ï¼ˆå‰åç«¯åˆ†ç¦»ï¼‰ ----------
# å…è®¸çš„å‰ç«¯åŸŸå
CORS_ORIGINS = os.getenv("CORS_ORIGINS", "http://localhost:5000,http://localhost:3000").split(",")
app.add_middleware(
    CORSMiddleware,
    allow_origins=CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é™æ€æ–‡ä»¶æœåŠ¡ï¼ˆå¯é€‰ï¼Œä»…ç”¨äºå…¼å®¹æ—§éƒ¨ç½²æ–¹å¼ï¼‰
# å‰åç«¯åˆ†ç¦»éƒ¨ç½²æ—¶å¯ä»¥æ³¨é‡Šæ‰è¿™è¡Œ
# app.mount("/static", StaticFiles(directory="static"), name="static")

security_bearer = HTTPBearer()


class Message(BaseModel):
    role: str
    content: Union[str, List[Dict[str, Any]]]


class ChatRequest(BaseModel):
    model: str = "gemini-auto"
    messages: List[Message]
    stream: bool = True
    temperature: Optional[float] = 0.7
    top_p: Optional[float] = 1.0


def create_chunk(
    id: str, created: int, model: str, delta: dict, finish_reason: Optional[str]
) -> str:
    chunk = {
        "id": id,
        "object": "chat.completion.chunk",
        "created": created,
        "model": model,
        "choices": [
            {
                "index": 0,
                "delta": delta,
                "finish_reason": finish_reason,
            }
        ],
    }
    return json.dumps(chunk, ensure_ascii=False)


@app.get("/v1/models")
async def list_models():
    data = []
    now = int(time.time())
    for m in MODEL_MAPPING.keys():
        data.append(
            {
                "id": m,
                "object": "model",
                "created": now,
                "owned_by": "google",
                "permission": [],
            }
        )
    return {"object": "list", "data": data}


@app.get("/admin/models")
async def list_models_admin(admin: Admin = Depends(get_current_admin)):
    """ç®¡ç†å‘˜è·å–æ¨¡å‹åˆ—è¡¨ï¼ˆä½¿ç”¨ admin token è®¤è¯ï¼‰"""
    data = []
    now = int(time.time())
    for m in MODEL_MAPPING.keys():
        data.append(
            {
                "id": m,
                "object": "model",
                "created": now,
                "owned_by": "google",
                "permission": [],
            }
        )
    return {"object": "list", "data": data}


@app.get("/health")
async def health():
    return {"status": "ok", "time": get_beijing_time().isoformat()}


@app.get("/")
async def root():
    """API æ ¹è·¯ç”±"""
    return {
        "name": "Gemini-Business API",
        "version": "1.0.0",
        "docs": "/docs",
        "health": "/health"
    }


@app.websocket("/ws/admin/events")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    try:
        while True:
            await websocket.receive_text()
    except WebSocketDisconnect:
        manager.disconnect(websocket)


# ---------- ç®¡ç†å‘˜è®¤è¯æ¥å£ ----------
class LoginRequest(BaseModel):
    username: str
    password: str


class LoginResponse(BaseModel):
    access_token: str
    token_type: str = "bearer"


class ChangePasswordRequest(BaseModel):
    old_password: str
    new_password: str


class ChangeUsernameRequest(BaseModel):
    new_username: str
    password: str  # éœ€è¦éªŒè¯å¯†ç æ‰èƒ½ä¿®æ”¹ç”¨æˆ·å


@app.post("/admin/login", response_model=LoginResponse)
async def admin_login(req: LoginRequest, db: Session = Depends(get_db)):
    """ç®¡ç†å‘˜ç™»å½•"""
    admin = db.query(Admin).filter(Admin.username == req.username).first()
    
    if not admin or not verify_password(req.password, admin.hashed_password):
        raise HTTPException(
            status_code=401,
            detail="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯"
        )
    
    access_token = create_access_token({"sub": admin.username})
    return LoginResponse(access_token=access_token)


@app.put("/admin/change-password")
async def change_password(
    req: ChangePasswordRequest,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """ä¿®æ”¹ç®¡ç†å‘˜å¯†ç """
    # éªŒè¯æ—§å¯†ç 
    if not verify_password(req.old_password, admin.hashed_password):
        raise HTTPException(
            status_code=400,
            detail="æ—§å¯†ç é”™è¯¯"
        )
    
    # éªŒè¯æ–°å¯†ç é•¿åº¦
    if len(req.new_password) < 6:
        raise HTTPException(
            status_code=400,
            detail="æ–°å¯†ç é•¿åº¦è‡³å°‘ä¸º 6 ä½"
        )
    
    # æ›´æ–°å¯†ç 
    admin.hashed_password = hash_password(req.new_password)
    db.commit()
    
    logger.info(f"âœ… ç®¡ç†å‘˜ {admin.username} ä¿®æ”¹äº†å¯†ç ")
    
    return {"message": "å¯†ç ä¿®æ”¹æˆåŠŸ"}


@app.put("/admin/change-username")
async def change_username(
    req: ChangeUsernameRequest,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """ä¿®æ”¹ç®¡ç†å‘˜ç”¨æˆ·å"""
    # éªŒè¯å¯†ç 
    if not verify_password(req.password, admin.hashed_password):
        raise HTTPException(
            status_code=400,
            detail="å¯†ç é”™è¯¯"
        )
    
    # éªŒè¯æ–°ç”¨æˆ·å
    if not req.new_username or len(req.new_username.strip()) == 0:
        raise HTTPException(
            status_code=400,
            detail="ç”¨æˆ·åä¸èƒ½ä¸ºç©º"
        )
    
    if len(req.new_username) > 50:
        raise HTTPException(
            status_code=400,
            detail="ç”¨æˆ·åé•¿åº¦ä¸èƒ½è¶…è¿‡ 50 ä¸ªå­—ç¬¦"
        )
    
    # æ£€æŸ¥æ–°ç”¨æˆ·åæ˜¯å¦å·²å­˜åœ¨
    existing_admin = db.query(Admin).filter(Admin.username == req.new_username.strip()).first()
    if existing_admin and existing_admin.id != admin.id:
        raise HTTPException(
            status_code=400,
            detail="ç”¨æˆ·åå·²å­˜åœ¨"
        )
    
    old_username = admin.username
    # æ›´æ–°ç”¨æˆ·å
    admin.username = req.new_username.strip()
    db.commit()
    
    logger.info(f"âœ… ç®¡ç†å‘˜ {old_username} å°†ç”¨æˆ·åä¿®æ”¹ä¸º {admin.username}")
    
    return {"message": "ç”¨æˆ·åä¿®æ”¹æˆåŠŸ", "new_username": admin.username}


# ---------- API å¯†é’¥ç®¡ç†æ¥å£ ----------
class GenerateKeysRequest(BaseModel):
    count: int = 1
    expires_days: int = 30
    name_prefix: str = "API Key"


class APIKeyResponse(BaseModel):
    id: int
    key: Optional[str] = None  # ä»…åœ¨ç”Ÿæˆæ—¶è¿”å›æ˜æ–‡
    name: str
    created_at: datetime
    expires_at: datetime
    is_active: bool
    usage_count: int
    last_used_at: Optional[datetime]


@app.post("/admin/api-keys", response_model=List[APIKeyResponse])
async def generate_api_keys(
    req: GenerateKeysRequest,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """æ‰¹é‡ç”Ÿæˆ API å¯†é’¥"""
    if req.count < 1 or req.count > 100:
        raise HTTPException(status_code=400, detail="æ•°é‡å¿…é¡»åœ¨ 1-100 ä¹‹é—´")
    
    if req.expires_days < 1 or req.expires_days > 3650:
        raise HTTPException(status_code=400, detail="æœ‰æ•ˆæœŸå¿…é¡»åœ¨ 1-3650 å¤©ä¹‹é—´")
    
    keys = []
    # å­˜å‚¨æ—¶ä½¿ç”¨ naive datetimeï¼ˆæ•°æ®åº“å…¼å®¹ï¼‰
    expires_at = ensure_naive(get_beijing_time() + timedelta(days=req.expires_days))
    
    for i in range(req.count):
        # ç”Ÿæˆ UUID æ ¼å¼å¯†é’¥
        plain_key = generate_api_key()
        key_hash = hash_api_key(plain_key)
        encrypted = encrypt_api_key(plain_key)  # åŠ å¯†å­˜å‚¨
        
        name = f"{req.name_prefix} #{i+1}" if req.count > 1 else req.name_prefix
        
        api_key = APIKey(
            key_hash=key_hash,
            encrypted_key=encrypted,  # å­˜å‚¨åŠ å¯†åçš„å¯†é’¥
            name=name,
            expires_at=expires_at,
            is_active=True
        )
        db.add(api_key)
        db.commit()
        db.refresh(api_key)
        
        keys.append(APIKeyResponse(
            id=api_key.id,
            key=plain_key,  # ä»…åœ¨ç”Ÿæˆæ—¶è¿”å›æ˜æ–‡
            name=api_key.name,
            created_at=api_key.created_at,
            expires_at=api_key.expires_at,
            is_active=api_key.is_active,
            usage_count=api_key.usage_count,
            last_used_at=api_key.last_used_at
        ))
    
    return keys


@app.get("/admin/api-keys", response_model=List[APIKeyResponse])
async def list_api_keys(
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """åˆ—å‡ºæ‰€æœ‰ API å¯†é’¥ï¼ˆä»…æ˜¾ç¤ºæ´»è·ƒçš„ï¼‰"""
    # æŒ‰åˆ›å»ºæ—¶é—´å‡åºæ’åˆ—ï¼ˆæœ€è€çš„åœ¨å‰ï¼‰
    keys = db.query(APIKey).filter(APIKey.is_active == True).order_by(APIKey.created_at.asc()).all()
    return [
        APIKeyResponse(
            id=k.id,
            name=k.name,
            created_at=k.created_at,
            expires_at=k.expires_at,
            is_active=k.is_active,
            usage_count=k.usage_count,
            last_used_at=k.last_used_at
        )
        for k in keys
    ]


@app.delete("/admin/api-keys/{key_id}")
async def revoke_api_key(
    key_id: int,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """æ’¤é”€ API å¯†é’¥"""
    api_key = db.query(APIKey).filter(APIKey.id == key_id).first()
    if not api_key:
        raise HTTPException(status_code=404, detail="å¯†é’¥ä¸å­˜åœ¨")
    
    api_key.is_active = False
    db.commit()
    return {"message": "å¯†é’¥å·²æ’¤é”€"}


@app.get("/admin/api-keys/{key_id}/view")
async def view_api_key(
    key_id: int,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """æŸ¥çœ‹ API å¯†é’¥æ˜æ–‡"""
    api_key = db.query(APIKey).filter(APIKey.id == key_id).first()
    if not api_key:
        raise HTTPException(status_code=404, detail="å¯†é’¥ä¸å­˜åœ¨")
    
    try:
        decrypted_key = decrypt_api_key(api_key.encrypted_key)
        return {"key": decrypted_key}
    except Exception as e:
        logger.error(f"Failed to decrypt key: {e}")
        raise HTTPException(status_code=500, detail="è§£å¯†å¤±è´¥")


@app.get("/admin/stats")
async def get_stats(
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """è·å–ç»Ÿè®¡ä¿¡æ¯"""
    from sqlalchemy import func
    
    total_keys = db.query(APIKey).count()
    # è·å–å½“å‰åŒ—äº¬æ—¶é—´ï¼ˆnaive æ ¼å¼ç”¨äºæ•°æ®åº“æ¯”è¾ƒï¼‰
    now_naive = get_beijing_time().replace(tzinfo=None)
    active_keys = db.query(APIKey).filter(
        APIKey.is_active == True,
        APIKey.expires_at > now_naive
    ).count()
    total_usage = db.query(func.sum(APIKey.usage_count)).filter(
        APIKey.is_active == True
    ).scalar() or 0
    
    return {
        "total_keys": total_keys,
        "active_keys": active_keys,
        "total_usage": total_usage
    }


@app.get("/admin/api-keys/{key_id}/logs")
async def get_api_key_logs(
    key_id: int,
    page: int = 1,
    page_size: int = 50,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """è·å–æŒ‡å®š API å¯†é’¥çš„è°ƒç”¨æ—¥å¿—"""
    # éªŒè¯å¯†é’¥æ˜¯å¦å­˜åœ¨
    api_key = db.query(APIKey).filter(APIKey.id == key_id).first()
    if not api_key:
        raise HTTPException(status_code=404, detail="å¯†é’¥ä¸å­˜åœ¨")
    
    # æŸ¥è¯¢æ—¥å¿—
    offset = (page - 1) * page_size
    logs = db.query(APICallLog).filter(
        APICallLog.api_key_id == key_id
    ).order_by(
        APICallLog.timestamp.desc()
    ).offset(offset).limit(page_size).all()
    
    # è·å–æ€»æ•°
    total = db.query(APICallLog).filter(APICallLog.api_key_id == key_id).count()
    
    return {
        "key_id": key_id,
        "key_name": api_key.name,
        "total": total,
        "page": page,
        "page_size": page_size,
        "logs": [
            {
                "id": log.id,
                "timestamp": log.timestamp.isoformat(),
                "model": log.model,
                "status": log.status,
                "error_message": log.error_message,
                "ip_address": log.ip_address,
                "endpoint": log.endpoint,
                "response_time": log.response_time
            }
            for log in logs
        ]
    }


@app.get("/admin/api-keys/{key_id}/stats")
async def get_api_key_stats(
    key_id: int,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """è·å–æŒ‡å®š API å¯†é’¥çš„ç»Ÿè®¡ä¿¡æ¯"""
    from sqlalchemy import func
    
    # éªŒè¯å¯†é’¥æ˜¯å¦å­˜åœ¨
    api_key = db.query(APIKey).filter(APIKey.id == key_id).first()
    if not api_key:
        raise HTTPException(status_code=404, detail="å¯†é’¥ä¸å­˜åœ¨")
    
    # æ€»è°ƒç”¨æ¬¡æ•°
    total_calls = db.query(APICallLog).filter(APICallLog.api_key_id == key_id).count()
    
    # æˆåŠŸ/å¤±è´¥ç»Ÿè®¡
    success_calls = db.query(APICallLog).filter(
        APICallLog.api_key_id == key_id,
        APICallLog.status == "success"
    ).count()
    
    error_calls = db.query(APICallLog).filter(
        APICallLog.api_key_id == key_id,
        APICallLog.status == "error"
    ).count()
    
    # æŒ‰æ¨¡å‹ç»Ÿè®¡
    model_stats = db.query(
        APICallLog.model,
        func.count(APICallLog.id).label("count")
    ).filter(
        APICallLog.api_key_id == key_id
    ).group_by(APICallLog.model).all()
    
    # å¹³å‡å“åº”æ—¶é—´
    avg_response_time = db.query(
        func.avg(APICallLog.response_time)
    ).filter(
        APICallLog.api_key_id == key_id,
        APICallLog.response_time.isnot(None)
    ).scalar() or 0
    
    # æœ€è¿‘ 7 å¤©çš„è°ƒç”¨è¶‹åŠ¿ï¼ˆä½¿ç”¨ naive datetime ç”¨äºæ•°æ®åº“æŸ¥è¯¢ï¼‰
    seven_days_ago = ensure_naive(get_beijing_time() - timedelta(days=7))
    
    daily_stats = db.query(
        func.date(APICallLog.timestamp).label("date"),
        func.count(APICallLog.id).label("count")
    ).filter(
        APICallLog.api_key_id == key_id,
        APICallLog.timestamp >= seven_days_ago
    ).group_by(
        func.date(APICallLog.timestamp)
    ).order_by(
        func.date(APICallLog.timestamp)
    ).all()
    
    return {
        "key_id": key_id,
        "key_name": api_key.name,
        "total_calls": total_calls,
        "success_calls": success_calls,
        "error_calls": error_calls,
        "success_rate": round(success_calls / total_calls * 100, 2) if total_calls > 0 else 0,
        "avg_response_time": round(avg_response_time, 2),
        "model_stats": [
            {"model": m[0], "count": m[1]}
            for m in model_stats
        ],
        "daily_stats": [
            {"date": str(d[0]), "count": d[1]}
            for d in daily_stats
        ]
    }


# ---------- è´¦å·ç®¡ç†æ¥å£ ----------
def extract_email_from_name(name: str) -> Optional[str]:
    """ä»è´¦å·åç§°ä¸­æå–é‚®ç®±åœ°å€"""
    if not name:
        return None
    
    # é‚®ç®±æ­£åˆ™è¡¨è¾¾å¼
    email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    match = re.search(email_pattern, name)
    if match:
        return match.group(0).lower()  # è½¬æ¢ä¸ºå°å†™ä»¥ä¾¿æ¯”è¾ƒ
    return None


def read_env_file() -> List[Dict[str, str]]:
    """è¯»å– .env æ–‡ä»¶ï¼Œè¿”å›æ‰€æœ‰è¡Œï¼ˆåŒ…æ‹¬æ³¨é‡Šå’Œç©ºè¡Œï¼‰"""
    env_path = ".env"
    if not os.path.exists(env_path):
        return []
    
    lines = []
    try:
        with open(env_path, "r", encoding="utf-8") as f:
            for line in f:
                lines.append({"raw": line.rstrip("\n\r"), "type": "line"})
    except Exception as e:
        logger.error(f"è¯»å– .env æ–‡ä»¶å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è¯»å– .env æ–‡ä»¶å¤±è´¥: {e}")
    
    return lines


def write_env_file(lines: List[Dict[str, str]]) -> None:
    """å†™å…¥ .env æ–‡ä»¶"""
    env_path = ".env"
    try:
        with open(env_path, "w", encoding="utf-8") as f:
            for line_data in lines:
                f.write(line_data["raw"] + "\n")
    except Exception as e:
        logger.error(f"å†™å…¥ .env æ–‡ä»¶å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å†™å…¥ .env æ–‡ä»¶å¤±è´¥: {e}")


def reindex_accounts_in_file(lines: List[Dict[str, str]]) -> List[Dict[str, str]]:
    """é‡æ–°åˆ†é…è´¦å·ç´¢å¼•ï¼Œä½¿ç´¢å¼•ä»1å¼€å§‹è¿ç»­"""
    # è§£æç°æœ‰è´¦å·
    accounts = parse_accounts_from_env_lines(lines)
    
    # è¿‡æ»¤æ‰æ—§æ ¼å¼è´¦å·ï¼ˆindex=0ï¼‰ï¼Œåªä¿ç•™æœ‰æ•ˆçš„è´¦å·
    valid_accounts = [acc for acc in accounts if acc["index"] > 0]
    
    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆè´¦å·ï¼Œç›´æ¥è¿”å›
    if not valid_accounts:
        return lines
    
    # æŒ‰ç´¢å¼•æ’åº
    valid_accounts.sort(key=lambda x: x["index"])
    
    # åˆ›å»ºç´¢å¼•æ˜ å°„ï¼šæ—§ç´¢å¼• -> æ–°ç´¢å¼•ï¼ˆä»1å¼€å§‹è¿ç»­ç¼–å·ï¼‰
    index_mapping = {}
    for new_idx, acc in enumerate(valid_accounts, start=1):
        old_idx = acc["index"]
        index_mapping[old_idx] = new_idx
    
    # é‡æ–°æ„å»ºæ–‡ä»¶å†…å®¹
    new_lines = []
    i = 0
    
    while i < len(lines):
        line_data = lines[i]
        line = line_data["raw"]
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è´¦å·ç›¸å…³çš„è¡Œ
        if "ACCOUNT" in line and "_" in line:
            # å°è¯•åŒ¹é… ACCOUNT{æ•°å­—}_ æ ¼å¼
            match = re.match(r'ACCOUNT(\d+)_', line)
            if match:
                old_idx = int(match.group(1))
                if old_idx in index_mapping:
                    new_idx = index_mapping[old_idx]
                    # æ›¿æ¢ç´¢å¼•
                    new_line = line.replace(f"ACCOUNT{old_idx}_", f"ACCOUNT{new_idx}_")
                    new_lines.append({"raw": new_line, "type": "line"})
                    i += 1
                    continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è´¦å·æ³¨é‡Šè¡Œ
        if line.strip().startswith("#") and "Account" in line:
            # å°è¯•åŒ¹é… # Account {æ•°å­—}: æ ¼å¼
            match = re.match(r'#\s*Account\s+(\d+):', line, re.IGNORECASE)
            if match:
                old_idx = int(match.group(1))
                if old_idx in index_mapping:
                    new_idx = index_mapping[old_idx]
                    # è·å–è´¦å·åç§°
                    name_match = re.search(r':\s*([^@]+)', line)
                    name = name_match.group(1).strip() if name_match else f"account-{new_idx}"
                    # æ›¿æ¢æ³¨é‡Š
                    new_line = f"# Account {new_idx}: {name}@{new_idx}"
                    new_lines.append({"raw": new_line, "type": "comment"})
                    i += 1
                    continue
        
        # å…¶ä»–è¡Œä¿æŒä¸å˜
        new_lines.append(line_data)
        i += 1
    
    return new_lines


def parse_accounts_from_env_lines(lines: List[Dict[str, str]]) -> List[Dict[str, Any]]:
    """ä» .env æ–‡ä»¶è¡Œä¸­è§£æè´¦å·é…ç½®"""
    accounts = []
    account_vars = {}  # {index: {vars}}
    
    # è§£ææ‰€æœ‰è´¦å·ç›¸å…³çš„ç¯å¢ƒå˜é‡
    for line_data in lines:
        line = line_data["raw"].strip()
        if not line or line.startswith("#") or "=" not in line:
            continue
        
        key, value = line.split("=", 1)
        key = key.strip()
        value = value.strip().strip('"').strip("'")
        # å»é™¤ config_id ä¸­å¯èƒ½å­˜åœ¨çš„ ?csesidx åç¼€
        if key.endswith("_CONFIG_ID") and '?csesidx' in value:
            value = value.split('?csesidx')[0]
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è´¦å·é…ç½®
        if key.startswith("ACCOUNT") and key.endswith("_SECURE_C_SES"):
            idx_str = key[len("ACCOUNT") : -len("_SECURE_C_SES")]
            try:
                idx = int(idx_str)
                if idx not in account_vars:
                    account_vars[idx] = {}
                account_vars[idx]["SECURE_C_SES"] = value
                account_vars[idx]["index"] = idx
            except ValueError:
                continue
        elif key.startswith("ACCOUNT") and "_" in key:
            parts = key.split("_", 1)
            if len(parts) == 2 and parts[0].startswith("ACCOUNT"):
                idx_str = parts[0][len("ACCOUNT"):]
                try:
                    idx = int(idx_str)
                    var_name = parts[1]
                    if idx not in account_vars:
                        account_vars[idx] = {}
                    account_vars[idx][var_name] = value
                    account_vars[idx]["index"] = idx
                except ValueError:
                    continue
    
    # æ£€æŸ¥æ—§çš„å•è´¦å·é…ç½®
    old_account = {}
    for line_data in lines:
        line = line_data["raw"].strip()
        if not line or line.startswith("#") or "=" not in line:
            continue
        key, value = line.split("=", 1)
        key = key.strip()
        value = value.strip().strip('"').strip("'")
        # å»é™¤ config_id ä¸­å¯èƒ½å­˜åœ¨çš„ ?csesidx åç¼€
        if key == "CONFIG_ID" and '?csesidx' in value:
            value = value.split('?csesidx')[0]
        if key in ["SECURE_C_SES", "CSESIDX", "CONFIG_ID", "HOST_C_OSES"]:
            old_account[key] = value
    
    # å¤„ç†å¤šè´¦å·é…ç½®
    for idx in sorted(account_vars.keys()):
        vars_dict = account_vars[idx]
        if vars_dict.get("SECURE_C_SES") and vars_dict.get("CSESIDX") and vars_dict.get("CONFIG_ID"):
            accounts.append({
                "index": idx,
                "name": vars_dict.get("NAME") or f"account-{idx}",
                "secure_c_ses": vars_dict.get("SECURE_C_SES"),
                "csesidx": vars_dict.get("CSESIDX"),
                "config_id": vars_dict.get("CONFIG_ID"),
                "host_c_oses": vars_dict.get("HOST_C_OSES", ""),
            })
    
    # å¤„ç†æ—§çš„å•è´¦å·é…ç½®
    if not accounts and old_account.get("SECURE_C_SES") and old_account.get("CSESIDX") and old_account.get("CONFIG_ID"):
        accounts.append({
            "index": 0,  # 0 è¡¨ç¤ºæ—§æ ¼å¼
            "name": "default",
            "secure_c_ses": old_account.get("SECURE_C_SES"),
            "csesidx": old_account.get("CSESIDX"),
            "config_id": old_account.get("CONFIG_ID"),
            "host_c_oses": old_account.get("HOST_C_OSES", ""),
        })
    
    return accounts


class AccountRequest(BaseModel):
    name: str
    secure_c_ses: str
    csesidx: str
    config_id: str
    host_c_oses: Optional[str] = ""


class AccountResponse(BaseModel):
    index: int
    name: str
    secure_c_ses: str
    csesidx: str
    config_id: str
    host_c_oses: str
    status: Optional[str] = None  # æµ‹è¯•çŠ¶æ€
    cookie_status: Optional[str] = None  # Cookie çŠ¶æ€: valid, expired, unknown
    last_check_at: Optional[datetime] = None  # æœ€åæ£€æŸ¥æ—¶é—´
    expires_at: Optional[datetime] = None  # é¢„ä¼°åˆ°æœŸæ—¶é—´ï¼ˆå¦‚æœå¯è·å–ï¼‰
    error_message: Optional[str] = None  # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœè¿‡æœŸï¼‰


@app.get("/admin/accounts", response_model=List[AccountResponse])
async def list_accounts(
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """åˆ—å‡ºæ‰€æœ‰è´¦å·é…ç½®"""
    from database import AccountCookieStatus
    
    lines = read_env_file()
    accounts = parse_accounts_from_env_lines(lines)
    
    # è·å–å½“å‰è¿è¡Œæ—¶çš„è´¦å·çŠ¶æ€
    account_status = {}
    if ACCOUNT_POOL:
        for acc in ACCOUNT_POOL.accounts:
            account_status[acc.name] = "available" if acc.is_available() else "unavailable"
    
    # ä»æ•°æ®åº“è·å– Cookie çŠ¶æ€
    cookie_status_map = {}
    cookie_statuses = db.query(AccountCookieStatus).all()
    logger.debug(f"ä»æ•°æ®åº“è¯»å–åˆ° {len(cookie_statuses)} æ¡ Cookie çŠ¶æ€è®°å½•")
    for cs in cookie_statuses:
        cookie_status_map[cs.account_name] = {
            "cookie_status": cs.cookie_status,
            "last_check_at": cs.last_check_at,
            "expires_at": cs.expires_at,
            "error_message": cs.error_message
        }
        if cs.last_check_at:
            logger.debug(f"è´¦å· {cs.account_name} çš„æœ€åæ£€æŸ¥æ—¶é—´: {cs.last_check_at}")
    
    result = []
    for acc in accounts:
        status = account_status.get(acc["name"], "unknown")
        cookie_info = cookie_status_map.get(acc["name"], {})
        
        result.append(AccountResponse(
            index=acc["index"],
            name=acc["name"],
            secure_c_ses=acc["secure_c_ses"],
            csesidx=acc["csesidx"],
            config_id=acc["config_id"],
            host_c_oses=acc.get("host_c_oses", ""),
            status=status,
            cookie_status=cookie_info.get("cookie_status"),
            last_check_at=cookie_info.get("last_check_at"),
            expires_at=cookie_info.get("expires_at"),
            error_message=cookie_info.get("error_message")
        ))
    
    return result


@app.post("/admin/accounts", response_model=AccountResponse)
async def create_account(
    req: AccountRequest,
    admin: Admin = Depends(get_current_admin)
):
    """åˆ›å»ºæ–°è´¦å·"""
    lines = read_env_file()
    accounts = parse_accounts_from_env_lines(lines)
    
    # é‚®ç®±å»é‡æ£€æŸ¥
    new_email = extract_email_from_name(req.name)
    if new_email:
        for acc in accounts:
            existing_email = extract_email_from_name(acc["name"])
            if existing_email and existing_email == new_email:
                raise HTTPException(
                    status_code=400,
                    detail=f"é‚®ç®± {new_email} å·²å­˜åœ¨äºè´¦å· {acc['name']} ä¸­"
                )
    
    # æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨çš„ç´¢å¼•
    existing_indices = {acc["index"] for acc in accounts if acc["index"] > 0}
    next_index = 1
    while next_index in existing_indices:
        next_index += 1
    
    # æ·»åŠ æ–°è´¦å·é…ç½®åˆ°æ–‡ä»¶æœ«å°¾
    new_lines = [
        {"raw": f"# Account {next_index}: {req.name}@{next_index}", "type": "comment"},
        {"raw": f'ACCOUNT{next_index}_NAME="{req.name}"', "type": "line"},
        {"raw": f'ACCOUNT{next_index}_SECURE_C_SES="{req.secure_c_ses}"', "type": "line"},
        {"raw": f'ACCOUNT{next_index}_CSESIDX="{req.csesidx}"', "type": "line"},
        {"raw": f'ACCOUNT{next_index}_CONFIG_ID="{req.config_id}"', "type": "line"},
    ]
    if req.host_c_oses:
        new_lines.append({"raw": f'ACCOUNT{next_index}_HOST_C_OSES="{req.host_c_oses}"', "type": "line"})
    new_lines.append({"raw": "", "type": "line"})  # ç©ºè¡Œåˆ†éš”
    
    lines.extend(new_lines)
    write_env_file(lines)
    
    # åŠ¨æ€é‡æ–°åŠ è½½è´¦å·é…ç½®
    reload_accounts_from_env_file()
    
    logger.info(f"âœ… ç®¡ç†å‘˜ {admin.username} åˆ›å»ºäº†æ–°è´¦å·: {req.name} (ç´¢å¼•: {next_index})")
    
    return AccountResponse(
        index=next_index,
        name=req.name,
        secure_c_ses=req.secure_c_ses,
        csesidx=req.csesidx,
        config_id=req.config_id,
        host_c_oses=req.host_c_oses or "",
        status="unknown"
    )


class BulkAccountRequest(BaseModel):
    """æ‰¹é‡æ·»åŠ è´¦å·è¯·æ±‚"""
    text: str  # åŸå§‹æ–‡æœ¬ï¼Œä»ä¸­æå–è´¦å·ä¿¡æ¯


def extract_accounts_from_text(text: str) -> List[Dict[str, str]]:
    """
    ä»æ–‡æœ¬ä¸­æ¨¡ç³ŠåŒ¹é…æå–è´¦å·ä¿¡æ¯
    æŸ¥æ‰¾ NAMEã€SECURE_C_SESã€CSESIDXã€CONFIG_IDã€HOST_C_OSES å­—æ®µ
    """
    accounts = []
    lines = text.split('\n')
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å„ç§å¯èƒ½çš„æ ¼å¼
    # æ”¯æŒæ ¼å¼ï¼šKEY=value, KEY="value", KEY='value', KEY: value ç­‰
    # åŒ¹é…å¸¦å¼•å·çš„å€¼ï¼š["']([^"']+)["'] æˆ– ä¸å¸¦å¼•å·çš„å€¼ï¼š([^\s=:]+)
    def extract_value(line: str, key_pattern: str) -> Optional[str]:
        # å…ˆå°è¯•åŒ¹é…å¸¦å¼•å·çš„æ ¼å¼
        quoted_pattern = re.compile(
            rf'{key_pattern}\s*[=:]\s*["\']([^"\']+)["\']',
            re.IGNORECASE
        )
        match = quoted_pattern.search(line)
        if match:
            return match.group(1).strip()
        
        # å†å°è¯•åŒ¹é…ä¸å¸¦å¼•å·çš„æ ¼å¼
        unquoted_pattern = re.compile(
            rf'{key_pattern}\s*[=:]\s*([^\s=:]+)',
            re.IGNORECASE
        )
        match = unquoted_pattern.search(line)
        if match:
            return match.group(1).strip()
        
        return None
    
    current_account = {}
    
    for line in lines:
        line = line.strip()
        if not line or line.startswith('#'):
            # é‡åˆ°ç©ºè¡Œæˆ–æ³¨é‡Šï¼Œå¦‚æœå½“å‰è´¦å·æœ‰å¿…éœ€å­—æ®µï¼Œä¿å­˜å®ƒ
            if current_account.get('secure_c_ses') and current_account.get('csesidx') and current_account.get('config_id'):
                accounts.append(current_account.copy())
                current_account = {}
            continue
        
        # å°è¯•åŒ¹é…å„ä¸ªå­—æ®µ
        # NAME
        value = extract_value(line, r'(?:NAME|name)')
        if value:
            current_account['name'] = value
            continue
        
        # SECURE_C_SES
        value = extract_value(line, r'(?:SECURE_C_SES|secure_c_ses|SECURE_CSES|secure_cses)')
        if value:
            current_account['secure_c_ses'] = value
            continue
        
        # CSESIDX
        value = extract_value(line, r'(?:CSESIDX|csesidx|CSES_IDX|cses_idx)')
        if value:
            current_account['csesidx'] = value
            continue
        
        # CONFIG_ID
        value = extract_value(line, r'(?:CONFIG_ID|config_id|CONFIGID|configid)')
        if value:
            current_account['config_id'] = value
            continue
        
        # HOST_C_OSES
        value = extract_value(line, r'(?:HOST_C_OSES|host_c_oses|HOST_COSES|host_coses)')
        if value:
            current_account['host_c_oses'] = value
            continue
        
        # ä¹Ÿæ”¯æŒ ACCOUNT1_NAME="value" è¿™ç§æ ¼å¼
        account_match = re.match(
            r'ACCOUNT\d+_(NAME|SECURE_C_SES|CSESIDX|CONFIG_ID|HOST_C_OSES)\s*=\s*["\']?([^"\']+)["\']?',
            line,
            re.IGNORECASE
        )
        if account_match:
            key = account_match.group(1).lower()
            value = account_match.group(2).strip()
            if key == 'name':
                current_account['name'] = value
            elif key == 'secure_c_ses':
                current_account['secure_c_ses'] = value
            elif key == 'csesidx':
                current_account['csesidx'] = value
            elif key == 'config_id':
                current_account['config_id'] = value
            elif key == 'host_c_oses':
                current_account['host_c_oses'] = value
    
    # ä¿å­˜æœ€åä¸€ä¸ªè´¦å·
    if current_account.get('secure_c_ses') and current_account.get('csesidx') and current_account.get('config_id'):
        accounts.append(current_account)
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•è´¦å·ï¼Œå°è¯•æŒ‰ç©ºè¡Œæˆ–æ˜æ˜¾åˆ†éš”ç¬¦åˆ†å‰²æ–‡æœ¬å—
    if not accounts:
        # å°è¯•æŒ‰å¤šä¸ªç©ºè¡Œæˆ–æ˜æ˜¾åˆ†éš”ç¬¦åˆ†å‰²
        blocks = re.split(r'\n\s*\n+', text)
        for block in blocks:
            account = {}
            # NAME
            value = extract_value(block, r'(?:NAME|name)')
            if value:
                account['name'] = value
            # SECURE_C_SES
            value = extract_value(block, r'(?:SECURE_C_SES|secure_c_ses|SECURE_CSES|secure_cses)')
            if value:
                account['secure_c_ses'] = value
            # CSESIDX
            value = extract_value(block, r'(?:CSESIDX|csesidx|CSES_IDX|cses_idx)')
            if value:
                account['csesidx'] = value
            # CONFIG_ID
            value = extract_value(block, r'(?:CONFIG_ID|config_id|CONFIGID|configid)')
            if value:
                account['config_id'] = value
            # HOST_C_OSES
            value = extract_value(block, r'(?:HOST_C_OSES|host_c_oses|HOST_COSES|host_coses)')
            if value:
                account['host_c_oses'] = value
            
            if account.get('secure_c_ses') and account.get('csesidx') and account.get('config_id'):
                accounts.append(account)
    
    return accounts


@app.post("/admin/accounts/bulk")
async def create_accounts_bulk(
    req: BulkAccountRequest,
    admin: Admin = Depends(get_current_admin)
):
    """æ‰¹é‡åˆ›å»ºè´¦å·ï¼ˆå¸¦å»é‡åŠŸèƒ½ï¼Œä»æ–‡æœ¬ä¸­æ¨¡ç³ŠåŒ¹é…æå–ï¼‰"""
    if not req.text or not req.text.strip():
        raise HTTPException(status_code=400, detail="æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º")
    
    # ä»æ–‡æœ¬ä¸­æå–è´¦å·ä¿¡æ¯
    extracted_accounts = extract_accounts_from_text(req.text)
    if not extracted_accounts:
        raise HTTPException(status_code=400, detail="æœªèƒ½ä»æ–‡æœ¬ä¸­æå–åˆ°æœ‰æ•ˆçš„è´¦å·ä¿¡æ¯ï¼Œè¯·ç¡®ä¿åŒ…å« NAMEã€SECURE_C_SESã€CSESIDXã€CONFIG_ID å­—æ®µ")
    
    lines = read_env_file()
    accounts = parse_accounts_from_env_lines(lines)
    
    # è·å–å·²å­˜åœ¨çš„è´¦å·æ ‡è¯†ï¼ˆç”¨äºå»é‡ï¼‰
    existing_config_ids = {acc["config_id"] for acc in accounts}
    existing_names = {acc["name"] for acc in accounts}
    # æå–å·²å­˜åœ¨è´¦å·çš„é‚®ç®±é›†åˆï¼ˆç”¨äºé‚®ç®±å»é‡ï¼‰
    existing_emails = set()
    for acc in accounts:
        email = extract_email_from_name(acc["name"])
        if email:
            existing_emails.add(email)
    
    # æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨çš„ç´¢å¼•
    existing_indices = {acc["index"] for acc in accounts if acc["index"] > 0}
    next_index = 1
    while next_index in existing_indices:
        next_index += 1
    
    created_accounts = []
    skipped_accounts = []
    seen_in_batch = set()  # ç”¨äºæ‰¹é‡æ·»åŠ å†…éƒ¨çš„å»é‡ï¼ˆCONFIG_IDï¼‰
    seen_emails_in_batch = set()  # ç”¨äºæ‰¹é‡æ·»åŠ å†…éƒ¨çš„é‚®ç®±å»é‡
    
    new_lines = []
    
    for acc_data in extracted_accounts:
        # è·å–å­—æ®µå€¼ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨ç©ºå­—ç¬¦ä¸²
        name = acc_data.get('name', '').strip() or f'account-{next_index}'
        secure_c_ses = acc_data.get('secure_c_ses', '').strip()
        csesidx = acc_data.get('csesidx', '').strip()
        config_id = acc_data.get('config_id', '').strip()
        host_c_oses = acc_data.get('host_c_oses', '').strip()
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        if not secure_c_ses or not csesidx or not config_id:
            skipped_accounts.append({
                "name": name,
                "reason": "ç¼ºå°‘å¿…éœ€å­—æ®µï¼ˆSECURE_C_SESã€CSESIDXã€CONFIG_IDï¼‰"
            })
            continue
        
        # å»é‡æ£€æŸ¥1ï¼šæ£€æŸ¥æ˜¯å¦ä¸å·²å­˜åœ¨çš„è´¦å·é‡å¤ï¼ˆä½¿ç”¨ CONFIG_IDï¼‰
        if config_id in existing_config_ids:
            skipped_accounts.append({
                "name": name,
                "reason": "CONFIG_ID å·²å­˜åœ¨"
            })
            continue
        
        # å»é‡æ£€æŸ¥2ï¼šæ£€æŸ¥æ˜¯å¦ä¸å·²å­˜åœ¨çš„è´¦å·åç§°é‡å¤
        if name in existing_names:
            skipped_accounts.append({
                "name": name,
                "reason": "è´¦å·åç§°å·²å­˜åœ¨"
            })
            continue
        
        # å»é‡æ£€æŸ¥3ï¼šé‚®ç®±å»é‡ - æ£€æŸ¥æ˜¯å¦ä¸å·²å­˜åœ¨çš„è´¦å·é‚®ç®±é‡å¤
        email = extract_email_from_name(name)
        if email:
            if email in existing_emails:
                skipped_accounts.append({
                    "name": name,
                    "reason": f"é‚®ç®± {email} å·²å­˜åœ¨"
                })
                continue
        
        # å»é‡æ£€æŸ¥4ï¼šæ£€æŸ¥æ‰¹é‡æ·»åŠ çš„è´¦å·ä¹‹é—´æ˜¯å¦é‡å¤ï¼ˆä½¿ç”¨ CONFIG_IDï¼‰
        if config_id in seen_in_batch:
            skipped_accounts.append({
                "name": name,
                "reason": "æ‰¹é‡æ·»åŠ ä¸­ CONFIG_ID é‡å¤"
            })
            continue
        
        # å»é‡æ£€æŸ¥5ï¼šæ£€æŸ¥æ‰¹é‡æ·»åŠ çš„è´¦å·åç§°æ˜¯å¦é‡å¤
        if name in {acc["name"] for acc in created_accounts}:
            skipped_accounts.append({
                "name": name,
                "reason": "æ‰¹é‡æ·»åŠ ä¸­è´¦å·åç§°é‡å¤"
            })
            continue
        
        # å»é‡æ£€æŸ¥6ï¼šæ‰¹é‡æ·»åŠ ä¸­çš„é‚®ç®±å»é‡
        if email and email in seen_emails_in_batch:
            skipped_accounts.append({
                "name": name,
                "reason": f"æ‰¹é‡æ·»åŠ ä¸­é‚®ç®± {email} é‡å¤"
            })
            continue
        
        # é€šè¿‡æ‰€æœ‰å»é‡æ£€æŸ¥ï¼Œæ·»åŠ åˆ°å¾…åˆ›å»ºåˆ—è¡¨
        seen_in_batch.add(config_id)
        if email:
            seen_emails_in_batch.add(email)
            existing_emails.add(email)  # æ›´æ–°å·²å­˜åœ¨é‚®ç®±é›†åˆï¼Œé¿å…åç»­é‡å¤
        
        # æ·»åŠ æ–°è´¦å·é…ç½®
        new_lines.append({"raw": f"# Account {next_index}: {name}@{next_index}", "type": "comment"})
        new_lines.append({"raw": f'ACCOUNT{next_index}_NAME="{name}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{next_index}_SECURE_C_SES="{secure_c_ses}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{next_index}_CSESIDX="{csesidx}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{next_index}_CONFIG_ID="{config_id}"', "type": "line"})
        if host_c_oses:
            new_lines.append({"raw": f'ACCOUNT{next_index}_HOST_C_OSES="{host_c_oses}"', "type": "line"})
        new_lines.append({"raw": "", "type": "line"})  # ç©ºè¡Œåˆ†éš”
        
        created_accounts.append({
            "index": next_index,
            "name": name
        })
        
        # æ›´æ–°å·²å­˜åœ¨çš„é›†åˆï¼ˆé¿å…åç»­é‡å¤ï¼‰
        existing_config_ids.add(config_id)
        existing_names.add(name)
        
        next_index += 1
        # ç¡®ä¿ç´¢å¼•ä¸å†²çª
        while next_index in existing_indices:
            next_index += 1
    
    if new_lines:
        lines.extend(new_lines)
        write_env_file(lines)
        # åŠ¨æ€é‡æ–°åŠ è½½è´¦å·é…ç½®
        reload_accounts_from_env_file()
        logger.info(f"âœ… ç®¡ç†å‘˜ {admin.username} æ‰¹é‡åˆ›å»ºäº† {len(created_accounts)} ä¸ªè´¦å·ï¼Œè·³è¿‡äº† {len(skipped_accounts)} ä¸ªé‡å¤è´¦å·")
    
    return {
        "message": f"æˆåŠŸåˆ›å»º {len(created_accounts)} ä¸ªè´¦å·",
        "created": created_accounts,
        "skipped": skipped_accounts,
        "total": len(extracted_accounts),
        "created_count": len(created_accounts),
        "skipped_count": len(skipped_accounts)
    }


@app.put("/admin/accounts/{account_index}", response_model=AccountResponse)
async def update_account(
    account_index: int,
    req: AccountRequest,
    admin: Admin = Depends(get_current_admin)
):
    """æ›´æ–°è´¦å·é…ç½®"""
    lines = read_env_file()
    accounts = parse_accounts_from_env_lines(lines)
    
    # æ£€æŸ¥è´¦å·æ˜¯å¦å­˜åœ¨
    account_exists = any(acc["index"] == account_index for acc in accounts)
    if not account_exists:
        raise HTTPException(status_code=404, detail="è´¦å·ä¸å­˜åœ¨")
    
    # é‚®ç®±å»é‡æ£€æŸ¥ï¼ˆæ’é™¤å½“å‰è´¦å·ï¼‰
    new_email = extract_email_from_name(req.name)
    if new_email:
        for acc in accounts:
            if acc["index"] == account_index:
                continue  # è·³è¿‡å½“å‰è´¦å·
            existing_email = extract_email_from_name(acc["name"])
            if existing_email and existing_email == new_email:
                raise HTTPException(
                    status_code=400,
                    detail=f"é‚®ç®± {new_email} å·²å­˜åœ¨äºè´¦å· {acc['name']} ä¸­"
                )
    
    # å¤„ç†æ—§æ ¼å¼è´¦å·ï¼ˆindex=0ï¼‰ï¼Œè½¬æ¢ä¸ºæ–°æ ¼å¼
    if account_index == 0:
        # åˆ é™¤æ—§æ ¼å¼çš„é…ç½®è¡Œ
        old_keys = ["SECURE_C_SES", "CSESIDX", "CONFIG_ID", "HOST_C_OSES"]
        new_lines = []
        for line_data in lines:
            line = line_data["raw"].strip()
            if "=" in line:
                key = line.split("=", 1)[0].strip()
                if key not in old_keys:
                    new_lines.append(line_data)
            else:
                new_lines.append(line_data)
        
        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨çš„ç´¢å¼•
        existing_indices = {acc["index"] for acc in accounts if acc["index"] > 0}
        next_index = 1
        while next_index in existing_indices:
            next_index += 1
        
        # æ·»åŠ æ–°æ ¼å¼çš„è´¦å·é…ç½®
        new_lines.append({"raw": f"# Account {next_index}: {req.name}@{next_index}", "type": "comment"})
        new_lines.append({"raw": f'ACCOUNT{next_index}_NAME="{req.name}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{next_index}_SECURE_C_SES="{req.secure_c_ses}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{next_index}_CSESIDX="{req.csesidx}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{next_index}_CONFIG_ID="{req.config_id}"', "type": "line"})
        if req.host_c_oses:
            new_lines.append({"raw": f'ACCOUNT{next_index}_HOST_C_OSES="{req.host_c_oses}"', "type": "line"})
        new_lines.append({"raw": "", "type": "line"})
        
        write_env_file(new_lines)
        
        # åŠ¨æ€é‡æ–°åŠ è½½è´¦å·é…ç½®
        reload_accounts_from_env_file()
        
        logger.info(f"âœ… ç®¡ç†å‘˜ {admin.username} æ›´æ–°äº†è´¦å·: {req.name} (ä»æ—§æ ¼å¼è½¬æ¢ä¸ºç´¢å¼•: {next_index})")
        
        return AccountResponse(
            index=next_index,
            name=req.name,
            secure_c_ses=req.secure_c_ses,
            csesidx=req.csesidx,
            config_id=req.config_id,
            host_c_oses=req.host_c_oses or "",
            status="unknown"
        )
    
    # æ›´æ–°æ–°æ ¼å¼è´¦å·é…ç½®
    new_lines = []
    i = 0
    in_account_section = False
    account_start = -1
    account_end = -1
    
    while i < len(lines):
        line = lines[i]["raw"]
        
        # æ£€æŸ¥æ˜¯å¦è¿›å…¥ç›®æ ‡è´¦å·åŒºåŸŸ
        if f"ACCOUNT{account_index}_" in line:
            if not in_account_section:
                in_account_section = True
                account_start = i
                # æ£€æŸ¥å‰é¢æ˜¯å¦æœ‰æ³¨é‡Š
                if i > 0 and lines[i-1]["raw"].strip().startswith("#"):
                    account_start = i - 1
        elif in_account_section:
            # æ£€æŸ¥æ˜¯å¦ç¦»å¼€è´¦å·åŒºåŸŸï¼ˆé‡åˆ°ä¸‹ä¸€ä¸ªè´¦å·æˆ–ç©ºè¡Œåçš„éè´¦å·è¡Œï¼‰
            if line.strip() and not line.startswith("#") and "ACCOUNT" not in line:
                # å¯èƒ½æ˜¯å…¶ä»–é…ç½®ï¼Œç»“æŸå½“å‰è´¦å·åŒºåŸŸ
                account_end = i
                break
            elif line.strip() == "" and i > account_start:
                # ç©ºè¡Œï¼Œå¯èƒ½æ˜¯è´¦å·åŒºåŸŸç»“æŸ
                account_end = i
                break
        
        i += 1
    
    if in_account_section and account_end == -1:
        account_end = len(lines)
    
    # é‡å»ºæ–‡ä»¶å†…å®¹
    if account_start >= 0:
        # ä¿ç•™è´¦å·åŒºåŸŸä¹‹å‰çš„å†…å®¹
        new_lines.extend(lines[:account_start])
        
        # æ·»åŠ æ›´æ–°åçš„è´¦å·é…ç½®
        account_name_line = f"# Account {account_index}: {req.name}@{account_index}"
        if account_start > 0 and lines[account_start-1]["raw"].strip().startswith("#"):
            # å¦‚æœå‰é¢æœ‰æ³¨é‡Šï¼Œæ›¿æ¢å®ƒ
            new_lines[-1] = {"raw": account_name_line, "type": "comment"}
        else:
            new_lines.append({"raw": account_name_line, "type": "comment"})
        
        new_lines.append({"raw": f'ACCOUNT{account_index}_NAME="{req.name}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{account_index}_SECURE_C_SES="{req.secure_c_ses}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{account_index}_CSESIDX="{req.csesidx}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{account_index}_CONFIG_ID="{req.config_id}"', "type": "line"})
        if req.host_c_oses:
            new_lines.append({"raw": f'ACCOUNT{account_index}_HOST_C_OSES="{req.host_c_oses}"', "type": "line"})
        new_lines.append({"raw": "", "type": "line"})  # ç©ºè¡Œåˆ†éš”
        
        # ä¿ç•™è´¦å·åŒºåŸŸä¹‹åçš„å†…å®¹
        new_lines.extend(lines[account_end:])
    else:
        # å¦‚æœæ‰¾ä¸åˆ°è´¦å·åŒºåŸŸï¼Œè¿½åŠ åˆ°æ–‡ä»¶æœ«å°¾
        new_lines = lines
        new_lines.append({"raw": f"# Account {account_index}: {req.name}@{account_index}", "type": "comment"})
        new_lines.append({"raw": f'ACCOUNT{account_index}_NAME="{req.name}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{account_index}_SECURE_C_SES="{req.secure_c_ses}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{account_index}_CSESIDX="{req.csesidx}"', "type": "line"})
        new_lines.append({"raw": f'ACCOUNT{account_index}_CONFIG_ID="{req.config_id}"', "type": "line"})
        if req.host_c_oses:
            new_lines.append({"raw": f'ACCOUNT{account_index}_HOST_C_OSES="{req.host_c_oses}"', "type": "line"})
        new_lines.append({"raw": "", "type": "line"})
    
    write_env_file(new_lines)
    
    # åŠ¨æ€é‡æ–°åŠ è½½è´¦å·é…ç½®
    reload_accounts_from_env_file()
    
    logger.info(f"âœ… ç®¡ç†å‘˜ {admin.username} æ›´æ–°äº†è´¦å·: {req.name} (ç´¢å¼•: {account_index})")
    
    return AccountResponse(
        index=account_index,
        name=req.name,
        secure_c_ses=req.secure_c_ses,
        csesidx=req.csesidx,
        config_id=req.config_id,
        host_c_oses=req.host_c_oses or "",
        status="unknown"
    )


@app.delete("/admin/accounts/{account_index}")
async def delete_account(
    account_index: int,
    admin: Admin = Depends(get_current_admin)
):
    """åˆ é™¤è´¦å·é…ç½®"""
    lines = read_env_file()
    accounts = parse_accounts_from_env_lines(lines)
    
    # æ£€æŸ¥è´¦å·æ˜¯å¦å­˜åœ¨
    account_exists = any(acc["index"] == account_index for acc in accounts)
    if not account_exists:
        raise HTTPException(status_code=404, detail="è´¦å·ä¸å­˜åœ¨")
    
    # å¤„ç†æ—§æ ¼å¼è´¦å·ï¼ˆindex=0ï¼‰
    if account_index == 0:
        # åˆ é™¤æ—§æ ¼å¼çš„é…ç½®è¡Œ
        old_keys = ["SECURE_C_SES", "CSESIDX", "CONFIG_ID", "HOST_C_OSES"]
        new_lines = []
        for line_data in lines:
            line = line_data["raw"].strip()
            if "=" in line:
                key = line.split("=", 1)[0].strip()
                if key not in old_keys:
                    new_lines.append(line_data)
            else:
                new_lines.append(line_data)
        
        write_env_file(new_lines)
        # åŠ¨æ€é‡æ–°åŠ è½½è´¦å·é…ç½®
        reload_accounts_from_env_file()
        logger.info(f"âœ… ç®¡ç†å‘˜ {admin.username} åˆ é™¤äº†æ—§æ ¼å¼è´¦å·")
        return {"message": "è´¦å·å·²åˆ é™¤"}
    
    # åˆ é™¤æ–°æ ¼å¼è´¦å·é…ç½®
    new_lines = []
    i = 0
    in_account_section = False
    account_start = -1
    account_end = -1
    
    while i < len(lines):
        line = lines[i]["raw"]
        
        # æ£€æŸ¥æ˜¯å¦è¿›å…¥ç›®æ ‡è´¦å·åŒºåŸŸ
        if f"ACCOUNT{account_index}_" in line:
            if not in_account_section:
                in_account_section = True
                account_start = i
                # æ£€æŸ¥å‰é¢æ˜¯å¦æœ‰æ³¨é‡Š
                if i > 0 and lines[i-1]["raw"].strip().startswith("#"):
                    account_start = i - 1
        elif in_account_section:
            # æ£€æŸ¥æ˜¯å¦ç¦»å¼€è´¦å·åŒºåŸŸ
            if line.strip() and not line.startswith("#") and "ACCOUNT" not in line:
                account_end = i
                break
            elif line.strip() == "" and i > account_start:
                account_end = i
                break
        
        i += 1
    
    if in_account_section and account_end == -1:
        account_end = len(lines)
    
    # é‡å»ºæ–‡ä»¶å†…å®¹ï¼ˆè·³è¿‡è´¦å·åŒºåŸŸï¼‰
    if account_start >= 0:
        new_lines.extend(lines[:account_start])
        new_lines.extend(lines[account_end:])
    else:
        new_lines = lines
    
    # é‡æ–°åˆ†é…ç´¢å¼•
    new_lines = reindex_accounts_in_file(new_lines)
    
    write_env_file(new_lines)
    
    # åŠ¨æ€é‡æ–°åŠ è½½è´¦å·é…ç½®
    reload_accounts_from_env_file()
    
    logger.info(f"âœ… ç®¡ç†å‘˜ {admin.username} åˆ é™¤äº†è´¦å· (ç´¢å¼•: {account_index})ï¼Œå·²è‡ªåŠ¨é‡æ–°åˆ†é…ç´¢å¼•")
    
    return {"message": "è´¦å·å·²åˆ é™¤ï¼Œç´¢å¼•å·²è‡ªåŠ¨é‡æ–°åˆ†é…"}


class BulkDeleteAccountRequest(BaseModel):
    """æ‰¹é‡åˆ é™¤è´¦å·è¯·æ±‚"""
    indices: List[int]  # è¦åˆ é™¤çš„è´¦å·ç´¢å¼•åˆ—è¡¨


@app.post("/admin/accounts/bulk-delete")
async def bulk_delete_accounts(
    req: BulkDeleteAccountRequest,
    admin: Admin = Depends(get_current_admin)
):
    """æ‰¹é‡åˆ é™¤è´¦å·"""
    if not req.indices:
        raise HTTPException(status_code=400, detail="è¯·é€‰æ‹©è¦åˆ é™¤çš„è´¦å·")
    
    lines = read_env_file()
    accounts = parse_accounts_from_env_lines(lines)
    
    # éªŒè¯è¦åˆ é™¤çš„è´¦å·æ˜¯å¦å­˜åœ¨
    existing_indices = {acc["index"] for acc in accounts}
    invalid_indices = [idx for idx in req.indices if idx not in existing_indices]
    if invalid_indices:
        raise HTTPException(status_code=404, detail=f"ä»¥ä¸‹è´¦å·ä¸å­˜åœ¨: {invalid_indices}")
    
    # ä¸å…è®¸åˆ é™¤é»˜è®¤è´¦å·ï¼ˆindex=0ï¼‰
    if 0 in req.indices:
        raise HTTPException(status_code=400, detail="ä¸èƒ½åˆ é™¤é»˜è®¤è´¦å·")
    
    # æŒ‰ç´¢å¼•ä»å¤§åˆ°å°æ’åºï¼Œä»åå¾€å‰åˆ é™¤ï¼Œé¿å…ç´¢å¼•å˜åŒ–å½±å“
    sorted_indices = sorted(req.indices, reverse=True)
    
    deleted_count = 0
    for account_index in sorted_indices:
        # åˆ é™¤è´¦å·é…ç½®
        new_lines = []
        i = 0
        in_account_section = False
        account_start = -1
        account_end = -1
        
        while i < len(lines):
            line = lines[i]["raw"]
            
            # æ£€æŸ¥æ˜¯å¦è¿›å…¥ç›®æ ‡è´¦å·åŒºåŸŸ
            if f"ACCOUNT{account_index}_" in line:
                if not in_account_section:
                    in_account_section = True
                    account_start = i
                    # æ£€æŸ¥å‰é¢æ˜¯å¦æœ‰æ³¨é‡Š
                    if account_start > 0 and lines[account_start - 1]["raw"].strip().startswith("#"):
                        account_start -= 1
            elif in_account_section:
                # æ£€æŸ¥æ˜¯å¦ç¦»å¼€è´¦å·åŒºåŸŸï¼ˆé‡åˆ°ç©ºè¡Œæˆ–ä¸‹ä¸€ä¸ªè´¦å·ï¼‰
                if not line.strip() or (line.strip().startswith("#") and "Account" in line and f"Account {account_index}" not in line):
                    account_end = i
                    break
                # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸‹ä¸€ä¸ªè´¦å·çš„é…ç½®
                if "ACCOUNT" in line and f"ACCOUNT{account_index}_" not in line:
                    account_end = i
                    break
            
            i += 1
        
        # å¦‚æœæ‰¾åˆ°äº†è´¦å·åŒºåŸŸï¼Œåˆ é™¤å®ƒ
        if account_start >= 0:
            if account_end == -1:
                account_end = len(lines)
            new_lines = lines[:account_start] + lines[account_end:]
            lines = new_lines
            deleted_count += 1
    
    if deleted_count > 0:
        # é‡æ–°åˆ†é…ç´¢å¼•
        lines = reindex_accounts_in_file(lines)
        write_env_file(lines)
        # åŠ¨æ€é‡æ–°åŠ è½½è´¦å·é…ç½®
        reload_accounts_from_env_file()
        logger.info(f"âœ… ç®¡ç†å‘˜ {admin.username} æ‰¹é‡åˆ é™¤äº† {deleted_count} ä¸ªè´¦å· (ç´¢å¼•: {req.indices})ï¼Œå·²è‡ªåŠ¨é‡æ–°åˆ†é…ç´¢å¼•")
    
    return {
        "message": f"æˆåŠŸåˆ é™¤ {deleted_count} ä¸ªè´¦å·ï¼Œç´¢å¼•å·²è‡ªåŠ¨é‡æ–°åˆ†é…",
        "deleted_count": deleted_count
    }


# ---------- ä¿æ´»ç­–ç•¥ç®¡ç†æ¥å£ ----------
class KeepAliveTaskRequest(BaseModel):
    is_enabled: bool
    schedule_time: str  # HH:MM æ ¼å¼
    api_keepalive_enabled: bool = True  # API ä¿æ´»æ˜¯å¦å¯ç”¨
    api_keepalive_interval: int = 30  # API ä¿æ´»é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
    auto_check_enabled: bool = False  # è‡ªåŠ¨æ£€æŸ¥æ˜¯å¦å¯ç”¨
    auto_check_interval: int = 60  # è‡ªåŠ¨æ£€æŸ¥é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
    auto_check_auto_fix: bool = True  # æ£€æµ‹åˆ°æ— æ•ˆæ—¶è‡ªåŠ¨ä¿®å¤


class KeepAliveTaskResponse(BaseModel):
    id: int
    is_enabled: bool
    schedule_time: str
    api_keepalive_enabled: bool
    api_keepalive_interval: int
    auto_check_enabled: bool = False
    auto_check_interval: int = 60
    auto_check_auto_fix: bool = True
    last_run_at: Optional[datetime]
    last_status: Optional[str]
    last_message: Optional[str]
    last_api_keepalive_at: Optional[datetime]
    last_auto_check_at: Optional[datetime] = None
    created_at: datetime
    updated_at: datetime


class KeepAliveLogResponse(BaseModel):
    id: int
    task_id: int
    started_at: datetime
    finished_at: Optional[datetime]
    status: str
    message: Optional[str]
    accounts_count: Optional[int]
    success_count: Optional[int]
    fail_count: Optional[int]


@app.get("/admin/keep-alive/task", response_model=KeepAliveTaskResponse)
async def get_keep_alive_task(
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """è·å–ä¿æ´»ä»»åŠ¡é…ç½®"""
    global current_keep_alive_process
    
    task = db.query(KeepAliveTask).first()
    if not task:
        # åˆ›å»ºé»˜è®¤ä»»åŠ¡
        task = KeepAliveTask(
            is_enabled=True,
            schedule_time="00:00",
            api_keepalive_enabled=True,
            api_keepalive_interval=30
        )
        db.add(task)
        db.commit()
        db.refresh(task)
    
    # æ£€æŸ¥å®é™…è¿›ç¨‹çŠ¶æ€ï¼Œå¦‚æœæ•°æ®åº“æ˜¾ç¤º"running"ä½†è¿›ç¨‹ä¸å­˜åœ¨ï¼Œæ›´æ–°çŠ¶æ€
    async with keep_alive_process_lock:
        is_actually_running = current_keep_alive_process is not None and current_keep_alive_process.poll() is None
    
    # å¦‚æœæ•°æ®åº“æ˜¾ç¤ºè¿è¡Œä¸­ï¼Œä½†å®é™…æ²¡æœ‰è¿›ç¨‹ï¼Œæ¸…ç†çŠ¶æ€
    if task.last_status == "running" and not is_actually_running:
        # æ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„æ—¥å¿—
        running_log = db.query(KeepAliveLog).filter(
            KeepAliveLog.status == "running"
        ).order_by(KeepAliveLog.started_at.desc()).first()
        
        if running_log:
            # æ›´æ–°æ—¥å¿—çŠ¶æ€
            running_log.status = "error"
            running_log.finished_at = get_beijing_time()
            running_log.message = "è¿›ç¨‹å¼‚å¸¸é€€å‡º"
            
            # æ›´æ–°æ‰€æœ‰è¿è¡Œä¸­çš„è´¦å·æ—¥å¿—
            running_account_logs = db.query(KeepAliveAccountLog).filter(
                KeepAliveAccountLog.task_log_id == running_log.id,
                KeepAliveAccountLog.status == "running"
            ).all()
            for acc_log in running_account_logs:
                acc_log.status = "error"
                acc_log.finished_at = get_beijing_time()
                acc_log.message = "è¿›ç¨‹å¼‚å¸¸é€€å‡º"
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task.last_status = "error" if running_log else task.last_status
        task.last_message = "è¿›ç¨‹å¼‚å¸¸é€€å‡º" if running_log else task.last_message
        db.commit()
    
    return KeepAliveTaskResponse(
        id=task.id,
        is_enabled=task.is_enabled,
        schedule_time=task.schedule_time,
        api_keepalive_enabled=getattr(task, 'api_keepalive_enabled', True),
        api_keepalive_interval=getattr(task, 'api_keepalive_interval', 30),
        auto_check_enabled=getattr(task, 'auto_check_enabled', False),
        auto_check_interval=getattr(task, 'auto_check_interval', 60),
        auto_check_auto_fix=getattr(task, 'auto_check_auto_fix', True),
        last_run_at=task.last_run_at,
        last_status=task.last_status,
        last_message=task.last_message,
        last_api_keepalive_at=getattr(task, 'last_api_keepalive_at', None),
        last_auto_check_at=getattr(task, 'last_auto_check_at', None),
        created_at=task.created_at,
        updated_at=task.updated_at
    )


@app.put("/admin/keep-alive/task", response_model=KeepAliveTaskResponse)
async def update_keep_alive_task(
    req: KeepAliveTaskRequest,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """æ›´æ–°ä¿æ´»ä»»åŠ¡é…ç½®"""
    # éªŒè¯æ—¶é—´æ ¼å¼
    try:
        hour, minute = map(int, req.schedule_time.split(":"))
        if not (0 <= hour <= 23 and 0 <= minute <= 59):
            raise ValueError("æ—¶é—´æ ¼å¼é”™è¯¯")
    except (ValueError, AttributeError):
        raise HTTPException(status_code=400, detail="æ—¶é—´æ ¼å¼é”™è¯¯ï¼Œåº”ä¸º HH:MM (24å°æ—¶åˆ¶)")
    
    # éªŒè¯ API ä¿æ´»é—´éš”
    if req.api_keepalive_interval < 5 or req.api_keepalive_interval > 1440:
        raise HTTPException(status_code=400, detail="API ä¿æ´»é—´éš”å¿…é¡»åœ¨ 5-1440 åˆ†é’Ÿä¹‹é—´")
    
    # éªŒè¯è‡ªåŠ¨æ£€æŸ¥é—´éš”
    if req.auto_check_interval < 5 or req.auto_check_interval > 1440:
        raise HTTPException(status_code=400, detail="è‡ªåŠ¨æ£€æŸ¥é—´éš”å¿…é¡»åœ¨ 5-1440 åˆ†é’Ÿä¹‹é—´")
    
    task = db.query(KeepAliveTask).first()
    if not task:
        task = KeepAliveTask(
            is_enabled=req.is_enabled,
            schedule_time=req.schedule_time,
            api_keepalive_enabled=req.api_keepalive_enabled,
            api_keepalive_interval=req.api_keepalive_interval,
            auto_check_enabled=req.auto_check_enabled,
            auto_check_interval=req.auto_check_interval,
            auto_check_auto_fix=req.auto_check_auto_fix
        )
        db.add(task)
    else:
        task.is_enabled = req.is_enabled
        task.schedule_time = req.schedule_time
        task.api_keepalive_enabled = req.api_keepalive_enabled
        task.api_keepalive_interval = req.api_keepalive_interval
        task.auto_check_enabled = req.auto_check_enabled
        task.auto_check_interval = req.auto_check_interval
        task.auto_check_auto_fix = req.auto_check_auto_fix
        task.updated_at = get_beijing_time()
    
    db.commit()
    db.refresh(task)
    
    # é‡æ–°è®¾ç½®è°ƒåº¦å™¨
    try:
        scheduler.remove_job("keep_alive_task")
        scheduler.remove_job("api_keepalive_task")
        scheduler.remove_job("auto_check_task")
    except Exception:
        # å¦‚æœä»»åŠ¡ä¸å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
        pass
    
    if task.is_enabled:
        try:
            hour, minute = map(int, task.schedule_time.split(":"))
            scheduler.add_job(
                execute_keep_alive_task,
                trigger=CronTrigger(hour=hour, minute=minute, timezone=BEIJING_TZ),
                id="keep_alive_task",
                replace_existing=True
            )
            logger.info(f"âœ… ä¿æ´»ä»»åŠ¡å·²æ›´æ–°ï¼Œæ¯æ—¥ {task.schedule_time} (åŒ—äº¬æ—¶é—´) æ‰§è¡Œ")
        except Exception as e:
            logger.error(f"âŒ è®¾ç½®ä¿æ´»ä»»åŠ¡è°ƒåº¦å™¨å¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail=f"è®¾ç½®è°ƒåº¦å™¨å¤±è´¥: {str(e)}")
    else:
        logger.info("â„¹ï¸ ä¿æ´»ä»»åŠ¡å·²ç¦ç”¨")
    
    # è®¾ç½®è‡ªåŠ¨æ£€æŸ¥è°ƒåº¦å™¨
    if task.auto_check_enabled:
        try:
            trigger = create_interval_trigger(task.auto_check_interval, BEIJING_TZ)
            scheduler.add_job(
                execute_auto_check_task,
                trigger=trigger,
                id="auto_check_task",
                replace_existing=True
            )
            logger.info(f"âœ… è‡ªåŠ¨æ£€æŸ¥ä»»åŠ¡å·²è®¾ç½®ï¼Œæ¯ {task.auto_check_interval} åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡")
        except Exception as e:
            logger.error(f"âŒ è®¾ç½®è‡ªåŠ¨æ£€æŸ¥è°ƒåº¦å™¨å¤±è´¥: {e}")
    else:
        logger.info("â„¹ï¸ è‡ªåŠ¨æ£€æŸ¥ä»»åŠ¡å·²ç¦ç”¨")
    
    # è®¾ç½® API ä¿æ´»è°ƒåº¦å™¨ï¼ˆä¸è‡ªåŠ¨æ£€æŸ¥ä½¿ç”¨ç›¸åŒçš„æ—¶é—´é—´éš”ï¼‰
    if task.api_keepalive_enabled:
        try:
            # å¦‚æœè‡ªåŠ¨æ£€æŸ¥å¯ç”¨ï¼Œä½¿ç”¨è‡ªåŠ¨æ£€æŸ¥çš„é—´éš”ï¼›å¦åˆ™ä½¿ç”¨ API ä¿æ´»è‡ªå·±çš„é—´éš”
            if task.auto_check_enabled:
                interval = task.auto_check_interval
                logger.info(f"âœ… Cookie æ£€æŸ¥ä»»åŠ¡å·²è®¾ç½®ï¼Œä¸è‡ªåŠ¨æ£€æŸ¥å…³è”ï¼Œæ¯ {interval} åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡")
            else:
                interval = task.api_keepalive_interval
                logger.info(f"âœ… Cookie æ£€æŸ¥ä»»åŠ¡å·²è®¾ç½®ï¼Œæ¯ {interval} åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡")
            
            trigger = create_interval_trigger(interval, BEIJING_TZ)
            scheduler.add_job(
                execute_api_keepalive_task,
                trigger=trigger,
                id="api_keepalive_task",
                replace_existing=True
            )
        except Exception as e:
            logger.error(f"âŒ è®¾ç½® Cookie æ£€æŸ¥è°ƒåº¦å™¨å¤±è´¥: {e}")
    else:
        logger.info("â„¹ï¸ Cookie æ£€æŸ¥ä»»åŠ¡å·²ç¦ç”¨")
    
    return KeepAliveTaskResponse(
        id=task.id,
        is_enabled=task.is_enabled,
        schedule_time=task.schedule_time,
        api_keepalive_enabled=task.api_keepalive_enabled,
        api_keepalive_interval=task.api_keepalive_interval,
        last_run_at=task.last_run_at,
        last_status=task.last_status,
        last_message=task.last_message,
        last_api_keepalive_at=getattr(task, 'last_api_keepalive_at', None),
        created_at=task.created_at,
        updated_at=task.updated_at
    )


@app.post("/admin/keep-alive/execute")
async def execute_keep_alive_manual(
    admin: Admin = Depends(get_current_admin)
):
    """æ‰‹åŠ¨æ‰§è¡Œä¿æ´»ä»»åŠ¡"""
    global current_keep_alive_process
    
    async with keep_alive_process_lock:
        if current_keep_alive_process is not None:
            raise HTTPException(status_code=400, detail="ä¿æ´»ä»»åŠ¡æ­£åœ¨æ‰§è¡Œä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆæˆ–å…ˆä¸­æ–­")
    
    logger.info(f"ğŸ”§ ç®¡ç†å‘˜ {admin.username} æ‰‹åŠ¨è§¦å‘ä¿æ´»ä»»åŠ¡")
    # åœ¨åå°æ‰§è¡Œï¼Œä¸é˜»å¡å“åº”
    asyncio.create_task(execute_keep_alive_task())
    return {"message": "ä¿æ´»ä»»åŠ¡å·²å¼€å§‹æ‰§è¡Œ"}


@app.post("/admin/keep-alive/cancel")
async def cancel_keep_alive_task(
    admin: Admin = Depends(get_current_admin)
):
    """ä¸­æ–­æ­£åœ¨æ‰§è¡Œçš„ä¿æ´»ä»»åŠ¡"""
    global current_keep_alive_process
    
    async with keep_alive_process_lock:
        if current_keep_alive_process is None:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰æ­£åœ¨æ‰§è¡Œçš„ä¿æ´»ä»»åŠ¡")
        
        try:
            # å…ˆå‘é€ä¸­æ–­ä¿¡å·ï¼Œè®©å­è¿›ç¨‹æœ‰æœºä¼šæ¸…ç†æµè§ˆå™¨
            logger.info("ğŸ›‘ æ­£åœ¨ä¸­æ–­ä¿æ´»ä»»åŠ¡ï¼Œç­‰å¾…æµè§ˆå™¨å…³é—­...")
            try:
                if sys.platform == 'win32':
                    # Windows ä¸Šå°è¯•å‘é€ SIGINTï¼ˆå¦‚æœæ”¯æŒï¼‰
                    try:
                        current_keep_alive_process.send_signal(signal.SIGINT)
                    except (AttributeError, ValueError):
                        # å¦‚æœä¸æ”¯æŒ send_signalï¼Œä½¿ç”¨ terminate
                        current_keep_alive_process.terminate()
                else:
                    # Unix ç³»ç»Ÿä¸Šä½¿ç”¨ SIGTERM
                    current_keep_alive_process.terminate()
            except Exception as e:
                logger.warning(f"å‘é€ä¸­æ–­ä¿¡å·å¤±è´¥: {e}ï¼Œå°è¯•ç›´æ¥ç»ˆæ­¢")
                # å¦‚æœå‘é€ä¿¡å·å¤±è´¥ï¼Œç›´æ¥ç»ˆæ­¢
                current_keep_alive_process.terminate()
            
            try:
                # ç­‰å¾…5ç§’ï¼Œè®©å­è¿›ç¨‹æœ‰æ—¶é—´æ¸…ç†æµè§ˆå™¨
                await asyncio.wait_for(
                    asyncio.to_thread(current_keep_alive_process.wait),
                    timeout=5
                )
                logger.info("âœ… ä¿æ´»ä»»åŠ¡å·²æ­£å¸¸ç»ˆæ­¢")
            except asyncio.TimeoutError:
                # å¦‚æœ5ç§’åè¿˜æ²¡ç»“æŸï¼Œå¼ºåˆ¶æ€æ­»
                logger.warning("âš ï¸ ä¿æ´»ä»»åŠ¡æœªåœ¨5ç§’å†…æ­£å¸¸ç»ˆæ­¢ï¼Œå¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹...")
                try:
                    current_keep_alive_process.kill()
                    await asyncio.wait_for(
                        asyncio.to_thread(current_keep_alive_process.wait),
                        timeout=2
                    )
                except Exception as e:
                    logger.error(f"å¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹å¤±è´¥: {e}")
            
            # æ— è®ºå­è¿›ç¨‹å¦‚ä½•ç»ˆæ­¢ï¼Œéƒ½å°è¯•å…³é—­ç”± Selenium å¯åŠ¨çš„ Edge æµè§ˆå™¨çª—å£ï¼ˆWindows ä¸Šï¼‰
            # æ³¨æ„ï¼šåªå…³é—­æ˜ç¡®ç”± Selenium å¯åŠ¨çš„ Edgeï¼Œä¸ä¼šå…³é—­ç”¨æˆ·æ­£åœ¨ä½¿ç”¨çš„ Edge
            if sys.platform == 'win32':
                try:
                    logger.info("ğŸ” æ£€æŸ¥å¹¶å…³é—­æ®‹ç•™çš„ Edge æµè§ˆå™¨çª—å£ï¼ˆä»…é™ä¿æ´»ä»»åŠ¡å¯åŠ¨çš„ï¼‰...")
                    closed_count = 0
                    
                    # ç›´æ¥å…³é—­ msedgedriver è¿›ç¨‹åŠå…¶æ‰€æœ‰å­è¿›ç¨‹ï¼ˆåŒ…æ‹¬ Edge æµè§ˆå™¨ï¼‰
                    # è¿™æ˜¯æœ€å¿«æœ€å¯é çš„æ–¹æ³•ï¼Œå› ä¸º Selenium å¯åŠ¨çš„ Edge éƒ½æ˜¯ msedgedriver çš„å­è¿›ç¨‹
                    try:
                        kill_driver_cmd = ['taskkill', '/F', '/IM', 'msedgedriver.exe', '/T']
                        kill_result = subprocess.run(
                            kill_driver_cmd,
                            capture_output=True,
                            text=True,
                            timeout=3,
                            creationflags=subprocess.CREATE_NO_WINDOW if hasattr(subprocess, 'CREATE_NO_WINDOW') else 0
                        )
                        if kill_result.returncode == 0:
                            # ç»Ÿè®¡å…³é—­çš„è¿›ç¨‹æ•°é‡ï¼ˆä»è¾“å‡ºä¸­æå–ï¼‰
                            output = kill_result.stdout or ""
                            if "æˆåŠŸ" in output or "successfully" in output.lower():
                                # å°è¯•ä»è¾“å‡ºä¸­æå–æ•°é‡
                                import re
                                match = re.search(r'(\d+)', output)
                                if match:
                                    closed_count = int(match.group(1))
                                else:
                                    closed_count = 1  # è‡³å°‘å…³é—­äº† msedgedriver
                    except subprocess.TimeoutError:
                        logger.debug("å…³é—­ msedgedriver è¶…æ—¶")
                    except Exception as e:
                        logger.debug(f"å…³é—­ msedgedriver æ—¶å‡ºé”™: {e}")
                    
                    if closed_count > 0:
                        time.sleep(0.5)  # å‡å°‘ç­‰å¾…æ—¶é—´
                        logger.info(f"âœ… å·²å…³é—­ {closed_count} ä¸ªç”±ä¿æ´»ä»»åŠ¡å¯åŠ¨çš„ Edge æµè§ˆå™¨çª—å£")
                    else:
                        logger.info("â„¹ï¸ æ²¡æœ‰å‘ç°æ®‹ç•™çš„ Edge æµè§ˆå™¨çª—å£ï¼ˆç”±ä¿æ´»ä»»åŠ¡å¯åŠ¨çš„ï¼‰")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ å°è¯•å…³é—­ Edge æµè§ˆå™¨æ—¶å‡ºé”™: {e}")
                    logger.info("ğŸ’¡ å¦‚æœ‰æ®‹ç•™çš„æµè§ˆå™¨çª—å£ï¼Œè¯·æ‰‹åŠ¨å…³é—­")
            
            # æ›´æ–°æ—¥å¿—çŠ¶æ€
            db = next(get_db())
            try:
                # æ‰¾åˆ°æœ€æ–°çš„è¿è¡Œä¸­çš„æ—¥å¿—
                running_log = db.query(KeepAliveLog).filter(
                    KeepAliveLog.status == "running"
                ).order_by(KeepAliveLog.started_at.desc()).first()
                
                if running_log:
                    running_log.status = "cancelled"
                    running_log.finished_at = get_beijing_time()
                    running_log.message = "ä»»åŠ¡è¢«ç®¡ç†å‘˜ä¸­æ–­"
                    
                    # æ›´æ–°æ‰€æœ‰è¿è¡Œä¸­çš„è´¦å·æ—¥å¿—
                    running_account_logs = db.query(KeepAliveAccountLog).filter(
                        KeepAliveAccountLog.task_log_id == running_log.id,
                        KeepAliveAccountLog.status == "running"
                    ).all()
                    for acc_log in running_account_logs:
                        acc_log.status = "cancelled"
                        acc_log.finished_at = get_beijing_time()
                        acc_log.message = "ä»»åŠ¡è¢«ä¸­æ–­"
                    
                    # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                    task = db.query(KeepAliveTask).first()
                    if task:
                        task.last_status = "cancelled"
                        task.last_message = "ä»»åŠ¡è¢«ç®¡ç†å‘˜ä¸­æ–­"
                    
                    db.commit()
                
            finally:
                db.close()
            
            current_keep_alive_process = None
            
            # å¦‚æœä¿æ´»ä»»åŠ¡å·²ç»æ›´æ–°äº†éƒ¨åˆ†è´¦å·é…ç½®ï¼Œé‡æ–°åŠ è½½è´¦å·é…ç½®
            try:
                reload_accounts_from_env_file()
                logger.info("ğŸ”„ ä¸­æ–­ä¿æ´»ä»»åŠ¡åå·²é‡æ–°åŠ è½½è´¦å·é…ç½®")
            except Exception as e:
                logger.error(f"âŒ é‡æ–°åŠ è½½è´¦å·é…ç½®å¤±è´¥: {e}")
            
            logger.info(f"ğŸ›‘ ç®¡ç†å‘˜ {admin.username} ä¸­æ–­äº†ä¿æ´»ä»»åŠ¡")
            return {"message": "ä¿æ´»ä»»åŠ¡å·²ä¸­æ–­"}
            
        except Exception as e:
            logger.error(f"âŒ ä¸­æ–­ä¿æ´»ä»»åŠ¡å¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail=f"ä¸­æ–­å¤±è´¥: {str(e)}")


class KeepAliveAccountLogResponse(BaseModel):
    id: int
    task_log_id: int
    account_name: str
    account_email: Optional[str]
    started_at: datetime
    finished_at: Optional[datetime]
    status: str
    message: Optional[str]


@app.get("/admin/keep-alive/logs", response_model=List[KeepAliveLogResponse])
async def get_keep_alive_logs(
    page: int = 1,
    page_size: int = 20,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """è·å–ä¿æ´»ä»»åŠ¡æ‰§è¡Œæ—¥å¿—"""
    offset = (page - 1) * page_size
    logs = db.query(KeepAliveLog).order_by(
        KeepAliveLog.started_at.desc()
    ).offset(offset).limit(page_size).all()
    
    return [
        KeepAliveLogResponse(
            id=log.id,
            task_id=log.task_id,
            started_at=log.started_at,
            finished_at=log.finished_at,
            status=log.status,
            message=log.message,
            accounts_count=log.accounts_count,
            success_count=log.success_count,
            fail_count=log.fail_count
        )
        for log in logs
    ]


@app.get("/admin/keep-alive/logs/{log_id}/accounts", response_model=List[KeepAliveAccountLogResponse])
async def get_keep_alive_account_logs(
    log_id: int,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """è·å–æŒ‡å®šä»»åŠ¡æ—¥å¿—çš„è´¦å·çº§åˆ«æ—¥å¿—"""
    # éªŒè¯ä»»åŠ¡æ—¥å¿—æ˜¯å¦å­˜åœ¨
    task_log = db.query(KeepAliveLog).filter(KeepAliveLog.id == log_id).first()
    if not task_log:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡æ—¥å¿—ä¸å­˜åœ¨")
    
    account_logs = db.query(KeepAliveAccountLog).filter(
        KeepAliveAccountLog.task_log_id == log_id
    ).order_by(KeepAliveAccountLog.started_at.asc()).all()
    
    return [
        KeepAliveAccountLogResponse(
            id=log.id,
            task_log_id=log.task_log_id,
            account_name=log.account_name,
            account_email=log.account_email,
            started_at=log.started_at,
            finished_at=log.finished_at,
            status=log.status,
            message=log.message
        )
        for log in account_logs
    ]


@app.delete("/admin/keep-alive/logs/{log_id}")
async def delete_keep_alive_log(
    log_id: int,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """åˆ é™¤æŒ‡å®šçš„ä¿æ´»ä»»åŠ¡æ—¥å¿—"""
    # éªŒè¯ä»»åŠ¡æ—¥å¿—æ˜¯å¦å­˜åœ¨
    task_log = db.query(KeepAliveLog).filter(KeepAliveLog.id == log_id).first()
    if not task_log:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡æ—¥å¿—ä¸å­˜åœ¨")
    
    # åˆ é™¤å…³è”çš„è´¦å·çº§åˆ«æ—¥å¿—
    db.query(KeepAliveAccountLog).filter(
        KeepAliveAccountLog.task_log_id == log_id
    ).delete()
    
    # åˆ é™¤ä»»åŠ¡æ—¥å¿—
    db.delete(task_log)
    db.commit()
    
    logger.info(f"ğŸ—‘ï¸ ç®¡ç†å‘˜ {admin.username} åˆ é™¤äº†ä¿æ´»ä»»åŠ¡æ—¥å¿— {log_id}")
    return {"message": "æ—¥å¿—å·²åˆ é™¤"}


@app.post("/admin/accounts/reload")
async def reload_accounts(
    admin: Admin = Depends(get_current_admin)
):
    """æ‰‹åŠ¨é‡æ–°åŠ è½½è´¦å·é…ç½®"""
    try:
        reload_accounts_from_env_file()
        logger.info(f"ğŸ”„ ç®¡ç†å‘˜ {admin.username} æ‰‹åŠ¨é‡æ–°åŠ è½½äº†è´¦å·é…ç½®")
        return {"message": "è´¦å·é…ç½®å·²é‡æ–°åŠ è½½"}
    except Exception as e:
        logger.error(f"âŒ é‡æ–°åŠ è½½è´¦å·é…ç½®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"é‡æ–°åŠ è½½å¤±è´¥: {str(e)}")


@app.post("/admin/keep-alive/logs/bulk-delete")
async def bulk_delete_keep_alive_logs(
    log_ids: List[int],
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """æ‰¹é‡åˆ é™¤ä¿æ´»ä»»åŠ¡æ—¥å¿—"""
    if not log_ids:
        raise HTTPException(status_code=400, detail="è¯·é€‰æ‹©è¦åˆ é™¤çš„æ—¥å¿—")
    
    # éªŒè¯æ‰€æœ‰æ—¥å¿—æ˜¯å¦å­˜åœ¨
    task_logs = db.query(KeepAliveLog).filter(
        KeepAliveLog.id.in_(log_ids)
    ).all()
    
    if len(task_logs) != len(log_ids):
        raise HTTPException(status_code=404, detail="éƒ¨åˆ†æ—¥å¿—ä¸å­˜åœ¨")
    
    # åˆ é™¤å…³è”çš„è´¦å·çº§åˆ«æ—¥å¿—
    db.query(KeepAliveAccountLog).filter(
        KeepAliveAccountLog.task_log_id.in_(log_ids)
    ).delete(synchronize_session=False)
    
    # åˆ é™¤ä»»åŠ¡æ—¥å¿—
    for task_log in task_logs:
        db.delete(task_log)
    
    db.commit()
    
    logger.info(f"ğŸ—‘ï¸ ç®¡ç†å‘˜ {admin.username} æ‰¹é‡åˆ é™¤äº† {len(log_ids)} æ¡ä¿æ´»ä»»åŠ¡æ—¥å¿—")
    return {"message": f"å·²åˆ é™¤ {len(log_ids)} æ¡æ—¥å¿—"}


@app.get("/admin/keep-alive/status")
async def get_keep_alive_status(
    admin: Admin = Depends(get_current_admin)
):
    """è·å–ä¿æ´»ä»»åŠ¡å½“å‰çŠ¶æ€ï¼ˆæ˜¯å¦æ­£åœ¨è¿è¡Œï¼‰"""
    global current_keep_alive_process
    
    async with keep_alive_process_lock:
        is_running = current_keep_alive_process is not None and current_keep_alive_process.poll() is None
    
    return {
        "is_running": is_running
    }


@app.post("/admin/auto-check/execute")
async def execute_auto_check_now(
    admin: Admin = Depends(get_current_admin)
):
    """ç«‹å³æ‰§è¡Œè‡ªåŠ¨æ£€æŸ¥ä»»åŠ¡"""
    try:
        # åœ¨åå°æ‰§è¡Œè‡ªåŠ¨æ£€æŸ¥ä»»åŠ¡
        asyncio.create_task(execute_auto_check_task())
        return {"message": "è‡ªåŠ¨æ£€æŸ¥ä»»åŠ¡å·²å¼€å§‹æ‰§è¡Œ"}
    except Exception as e:
        logger.error(f"æ‰§è¡Œè‡ªåŠ¨æ£€æŸ¥å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå¤±è´¥: {str(e)}")


@app.post("/admin/accounts/batch-check")
async def batch_check_accounts(
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """æ‰¹é‡æ£€æŸ¥æ‰€æœ‰è´¦å·çš„ Cookie çŠ¶æ€ï¼ˆAPI ä¿æ´»ï¼‰"""
    lines = read_env_file()
    accounts = parse_accounts_from_env_lines(lines)
    
    results = []
    check_time = get_beijing_time()
    
    for acc in accounts:
        test_acc = Account(
            name=acc["name"],
            secure_c_ses=acc["secure_c_ses"],
            csesidx=acc["csesidx"],
            config_id=acc["config_id"],
            host_c_oses=acc.get("host_c_oses", ""),
        )
        
        cookie_status = "unknown"
        error_msg = None
        expires_at = None
        
        try:
            jwt_token = await test_acc.jwt_mgr.get()
            if jwt_token:
                cookie_status = "valid"
                # å°è¯•è·å– Cookie è¿‡æœŸæ—¶é—´ï¼ˆä»…ä»å“åº”å¤´è·å–ï¼Œä¸ä¼°ç®—ï¼‰
                if hasattr(test_acc, '_cookie_expires_at') and test_acc._cookie_expires_at:
                    expires_at = test_acc._cookie_expires_at
                # å¦‚æœæ— æ³•ä»å“åº”å¤´è·å–ï¼Œexpires_at ä¿æŒä¸º None
                
                result_item = {
                    "index": acc["index"],
                    "name": acc["name"],
                    "cookie_status": cookie_status,
                    "last_check_at": check_time,
                    "expires_at": expires_at,
                    "error_message": None
                }
            else:
                cookie_status = "unknown"
                error_msg = "æ— æ³•è·å– JWT"
                result_item = {
                    "index": acc["index"],
                    "name": acc["name"],
                    "cookie_status": cookie_status,
                    "last_check_at": check_time,
                    "expires_at": None,
                    "error_message": error_msg
                }
        except HTTPException as e:
            error_msg = str(e.detail) if hasattr(e, 'detail') else str(e)
            if e.status_code == 401:
                cookie_status = "expired"
                error_msg = "Cookie å·²è¿‡æœŸ"
            elif e.status_code == 403:
                cookie_status = "forbidden"
                error_msg = "Cookie æ— æ•ˆæˆ–è¢«ç¦æ­¢"
            elif e.status_code == 429:
                cookie_status = "rate_limited"
                error_msg = "è¯·æ±‚è¿‡äºé¢‘ç¹"
            
            result_item = {
                "index": acc["index"],
                "name": acc["name"],
                "cookie_status": cookie_status,
                "last_check_at": check_time,
                "expires_at": None,
                "error_message": error_msg
            }
        except Exception as e:
            error_msg = str(e)
            result_item = {
                "index": acc["index"],
                "name": acc["name"],
                "cookie_status": "unknown",
                "last_check_at": check_time,
                "expires_at": None,
                "error_message": error_msg
            }
        
        results.append(result_item)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        try:
            account_status = db.query(AccountCookieStatus).filter(
                AccountCookieStatus.account_name == acc["name"]
            ).first()
            
            if account_status:
                # æ›´æ–°ç°æœ‰è®°å½•
                account_status.cookie_status = cookie_status
                account_status.last_check_at = check_time
                # åªæœ‰åœ¨ Cookie æœ‰æ•ˆæ—¶æ‰æ›´æ–°è¿‡æœŸæ—¶é—´ï¼Œé¿å…è¦†ç›–æœ‰æ•ˆçš„è¿‡æœŸæ—¶é—´
                if cookie_status == "valid" and expires_at:
                    account_status.expires_at = expires_at
                account_status.error_message = error_msg
                account_status.updated_at = check_time
            else:
                # åˆ›å»ºæ–°è®°å½•
                account_status = AccountCookieStatus(
                    account_name=acc["name"],
                    cookie_status=cookie_status,
                    last_check_at=check_time,
                    expires_at=expires_at if cookie_status == "valid" else None,
                    error_message=error_msg
                )
                db.add(account_status)
        except Exception as e:
            logger.error(f"ä¿å­˜è´¦å· Cookie çŠ¶æ€å¤±è´¥ [{acc['name']}]: {e}")
    
    # æ‰¹é‡æäº¤
    try:
        db.commit()
    except Exception as e:
        logger.error(f"æ‰¹é‡ä¿å­˜ Cookie çŠ¶æ€å¤±è´¥: {e}")
        db.rollback()
    
    return {"results": results}


@app.post("/admin/accounts/{account_index}/test")
async def test_account(
    account_index: int,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """æµ‹è¯•è´¦å·æ˜¯å¦å¯ç”¨ï¼ˆAPI ä¿æ´»æ£€æŸ¥ï¼‰"""
    lines = read_env_file()
    accounts = parse_accounts_from_env_lines(lines)
    
    # æ‰¾åˆ°ç›®æ ‡è´¦å·
    target_account = None
    for acc in accounts:
        if acc["index"] == account_index:
            target_account = acc
            break
    
    if not target_account:
        raise HTTPException(status_code=404, detail="è´¦å·ä¸å­˜åœ¨")
    
    # åˆ›å»ºä¸´æ—¶è´¦å·å¯¹è±¡è¿›è¡Œæµ‹è¯•
    test_acc = Account(
        name=target_account["name"],
        secure_c_ses=target_account["secure_c_ses"],
        csesidx=target_account["csesidx"],
        config_id=target_account["config_id"],
        host_c_oses=target_account.get("host_c_oses", ""),
    )
    
    check_time = get_beijing_time()
    cookie_status = "unknown"
    error_msg = None
    expires_at = None
    
    try:
        # å°è¯•è·å– JWTï¼ˆè¿™ä¼šéªŒè¯ Cookie æ˜¯å¦æœ‰æ•ˆï¼‰
        jwt_token = await test_acc.jwt_mgr.get()
        if jwt_token:
            cookie_status = "valid"
            
            # å°è¯•è·å– Cookie è¿‡æœŸæ—¶é—´ï¼ˆä»…ä»å“åº”å¤´è·å–ï¼Œä¸ä¼°ç®—ï¼‰
            if hasattr(test_acc, '_cookie_expires_at') and test_acc._cookie_expires_at:
                expires_at = test_acc._cookie_expires_at
            # å¦‚æœæ— æ³•ä»å“åº”å¤´è·å–ï¼Œexpires_at ä¿æŒä¸º None
            
            result = {
                "status": "success",
                "message": "è´¦å·æµ‹è¯•æˆåŠŸï¼ŒCookie æœ‰æ•ˆ",
                "cookie_status": cookie_status,
                "last_check_at": check_time,
                "expires_at": expires_at,
                "error_message": None
            }
        else:
            cookie_status = "unknown"
            error_msg = "æ— æ³•è·å– JWT"
            result = {
                "status": "error",
                "message": "æ— æ³•è·å– JWT",
                "cookie_status": cookie_status,
                "last_check_at": check_time,
                "expires_at": None,
                "error_message": error_msg
            }
    except HTTPException as e:
        # æ ¹æ®é”™è¯¯ç åˆ¤æ–­ Cookie çŠ¶æ€
        error_msg = str(e.detail) if hasattr(e, 'detail') else str(e)
        
        if e.status_code == 401:
            cookie_status = "expired"
            error_msg = "Cookie å·²è¿‡æœŸï¼Œéœ€è¦é‡æ–°ç™»å½•"
        elif e.status_code == 403:
            cookie_status = "forbidden"
            error_msg = "Cookie æ— æ•ˆæˆ–è¢«ç¦æ­¢è®¿é—®"
        elif e.status_code == 429:
            cookie_status = "rate_limited"
            error_msg = "è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•"
        
        logger.error(f"è´¦å·æµ‹è¯•å¤±è´¥ [{target_account['name']}]: {e.status_code} - {error_msg}")
        result = {
            "status": "error",
            "message": f"è´¦å·æµ‹è¯•å¤±è´¥: {error_msg}",
            "cookie_status": cookie_status,
            "last_check_at": check_time,
            "expires_at": None,
            "error_message": error_msg
        }
    except Exception as e:
        logger.error(f"è´¦å·æµ‹è¯•å¤±è´¥: {e}")
        error_msg = str(e)
        result = {
            "status": "error",
            "message": f"è´¦å·æµ‹è¯•å¤±è´¥: {error_msg}",
            "cookie_status": "unknown",
            "last_check_at": check_time,
            "expires_at": None,
            "error_message": error_msg
        }
    
    # ä¿å­˜åˆ°æ•°æ®åº“
    try:
        account_status = db.query(AccountCookieStatus).filter(
            AccountCookieStatus.account_name == target_account["name"]
        ).first()
        
        if account_status:
            # æ›´æ–°ç°æœ‰è®°å½•
            account_status.cookie_status = cookie_status
            account_status.last_check_at = check_time
            # åªæœ‰åœ¨ Cookie æœ‰æ•ˆæ—¶æ‰æ›´æ–°è¿‡æœŸæ—¶é—´ï¼Œé¿å…è¦†ç›–æœ‰æ•ˆçš„è¿‡æœŸæ—¶é—´
            if cookie_status == "valid" and expires_at:
                account_status.expires_at = expires_at
            account_status.error_message = error_msg
            account_status.updated_at = check_time
        else:
            # åˆ›å»ºæ–°è®°å½•
            account_status = AccountCookieStatus(
                account_name=target_account["name"],
                cookie_status=cookie_status,
                last_check_at=check_time,
                expires_at=expires_at if cookie_status == "valid" else None,
                error_message=error_msg
            )
            db.add(account_status)
        
        db.commit()
    except Exception as e:
        logger.error(f"ä¿å­˜è´¦å· Cookie çŠ¶æ€å¤±è´¥: {e}")
        db.rollback()
    
    return result


@app.post("/admin/accounts/{account_index}/login")
async def login_account(
    account_index: int,
    admin: Admin = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """
    é‡æ–°ç™»å½•è´¦å·å¹¶æ›´æ–° Cookie
    ä½¿ç”¨ Selenium è‡ªåŠ¨åŒ–ç™»å½•æµç¨‹
    ç™»å½•æˆåŠŸåæµè§ˆå™¨ä¿æŒæ‰“å¼€çŠ¶æ€
    """
    lines = read_env_file()
    accounts = parse_accounts_from_env_lines(lines)
    
    # æ‰¾åˆ°ç›®æ ‡è´¦å·
    target_account = None
    for acc in accounts:
        if acc["index"] == account_index:
            target_account = acc
            break
    
    if not target_account:
        raise HTTPException(status_code=404, detail="è´¦å·ä¸å­˜åœ¨")
    
    # è·å–è´¦å·é‚®ç®±ï¼ˆä» name å­—æ®µä¸­æå–æˆ–ä½¿ç”¨ name ä½œä¸ºé‚®ç®±ï¼‰
    account_email = target_account["name"]
    
    # æ£€æŸ¥ç™»å½•è„šæœ¬æ˜¯å¦å­˜åœ¨
    login_script_path = os.path.join(BASE_DIR, "gemini_business_login_selenium.py")
    if not os.path.exists(login_script_path):
        raise HTTPException(status_code=500, detail="ç™»å½•è„šæœ¬ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»º gemini_business_login_selenium.py")
    
    logger.info(f"ğŸ”‘ å¼€å§‹ç™»å½•è´¦å·: {account_email} (ç´¢å¼•: {account_index})")
    
    try:
        # åˆ›å»ºä¸´æ—¶çš„é‚®ç®±åˆ—è¡¨æ–‡ä»¶
        temp_email_file = os.path.join(BASE_DIR, f"temp_login_email_{account_index}.txt")
        with open(temp_email_file, 'w', encoding='utf-8') as f:
            f.write(account_email)
        
        # è®¾ç½®ç¯å¢ƒå˜é‡æŒ‡å®šè¦ç™»å½•çš„é‚®ç®±æ–‡ä»¶
        env = os.environ.copy()
        env['LOGIN_EMAIL_FILE'] = temp_email_file
        env['LOGIN_SINGLE_ACCOUNT'] = account_email
        env['LOGIN_ACCOUNT_INDEX'] = str(account_index)
        
        # è®¾ç½®ç¯å¢ƒå˜é‡å¼ºåˆ¶ Python ä½¿ç”¨ UTF-8
        env['PYTHONIOENCODING'] = 'utf-8'
        env['PYTHONUTF8'] = '1'
        
        # æ‰§è¡Œç™»å½•è„šæœ¬ï¼ˆä½¿ç”¨ CREATE_NEW_PROCESS_GROUP ä½¿å…¶ç‹¬ç«‹è¿è¡Œï¼‰
        # è¿™æ ·å³ä½¿ API è¿”å›ï¼Œè„šæœ¬å’Œæµè§ˆå™¨ä»ç„¶ä¿æŒè¿è¡Œ
        if sys.platform == 'win32':
            # Windows: ä½¿ç”¨ CREATE_NEW_PROCESS_GROUP åˆ›å»ºç‹¬ç«‹è¿›ç¨‹
            process = subprocess.Popen(
                [sys.executable, "-u", login_script_path],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                cwd=BASE_DIR,
                env=env,
                creationflags=subprocess.CREATE_NEW_PROCESS_GROUP
            )
        else:
            # Linux/Mac: ä½¿ç”¨ start_new_session åˆ›å»ºç‹¬ç«‹ä¼šè¯
            process = subprocess.Popen(
                [sys.executable, "-u", login_script_path],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                cwd=BASE_DIR,
                env=env,
                start_new_session=True
            )
        
        # å®æ—¶è¯»å–è¾“å‡ºï¼Œæ£€æµ‹ç™»å½•æˆåŠŸçš„æ ‡å¿—
        output_lines = []
        login_success = False
        config_saved = False
        start_time = time.time()
        max_wait_time = 300  # æœ€å¤šç­‰å¾… 5 åˆ†é’Ÿ
        
        def decode_line(raw_bytes):
            """å°è¯•å¤šç§ç¼–ç è§£ç """
            if isinstance(raw_bytes, str):
                return raw_bytes
            for encoding in ['utf-8', 'gbk', 'gb2312', 'cp936']:
                try:
                    return raw_bytes.decode(encoding)
                except:
                    continue
            return raw_bytes.decode('utf-8', errors='replace')
        
        while time.time() - start_time < max_wait_time:
            # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
            poll_result = process.poll()
            
            # éé˜»å¡è¯»å–ä¸€è¡Œè¾“å‡º
            try:
                raw_line = process.stdout.readline()
                if raw_line:
                    line = decode_line(raw_line).strip()
                    output_lines.append(line)
                    logger.info(f"ç™»å½•è„šæœ¬è¾“å‡º: {line}")
                    
                    # æ£€æµ‹ç™»å½•æˆåŠŸå¹¶é…ç½®å·²ä¿å­˜çš„æ ‡å¿—ï¼ˆä½¿ç”¨å¤šç§åŒ¹é…æ–¹å¼ï¼‰
                    line_lower = line.lower()
                    if "gemini_business_login_configs.txt" in line or "login_configs" in line_lower:
                        config_saved = True
                        logger.info("âœ… æ£€æµ‹åˆ°é…ç½®æ–‡ä»¶å·²ä¿å­˜")
                    if "ç™»å½•æˆåŠŸ" in line or "login success" in line_lower or "ç™»å½•æµç¨‹å®Œæˆ" in line or "å·²è·³è½¬åˆ°ä¸šåŠ¡é¡µé¢" in line:
                        login_success = True
                        logger.info("âœ… æ£€æµ‹åˆ°ç™»å½•æˆåŠŸ")
                    
                    # å¦‚æœé…ç½®å·²ä¿å­˜ï¼Œå¯ä»¥æå‰è¿”å›
                    if config_saved and login_success:
                        logger.info(f"âœ… ç™»å½•æˆåŠŸä¸”é…ç½®å·²ä¿å­˜ï¼Œæµè§ˆå™¨å°†ä¿æŒæ‰“å¼€")
                        break
                    
                    # æ£€æµ‹ç™»å½•å¤±è´¥
                    if "ç™»å½•å¤±è´¥" in line or "ç™»å½•è¿‡ç¨‹å‡ºé”™" in line or "login failed" in line_lower:
                        logger.warning(f"æ£€æµ‹åˆ°ç™»å½•å¤±è´¥: {line}")
                        break
                else:
                    # æ²¡æœ‰æ–°è¾“å‡ºï¼ŒçŸ­æš‚ç­‰å¾…
                    await asyncio.sleep(0.1)
            except Exception as e:
                logger.debug(f"è¯»å–è¾“å‡ºå¼‚å¸¸: {e}")
                await asyncio.sleep(0.1)
            
            # å¦‚æœè¿›ç¨‹å·²ç»“æŸ
            if poll_result is not None:
                # è¯»å–å‰©ä½™è¾“å‡º
                remaining = process.stdout.read()
                if remaining:
                    remaining_text = decode_line(remaining)
                    for rem_line in remaining_text.strip().split('\n'):
                        if rem_line.strip():
                            output_lines.append(rem_line.strip())
                            logger.info(f"ç™»å½•è„šæœ¬è¾“å‡º: {rem_line.strip()}")
                            if "gemini_business_login_configs.txt" in rem_line or "login_configs" in rem_line.lower():
                                config_saved = True
                            if "ç™»å½•æˆåŠŸ" in rem_line or "ç™»å½•æµç¨‹å®Œæˆ" in rem_line or "å·²è·³è½¬åˆ°ä¸šåŠ¡é¡µé¢" in rem_line:
                                login_success = True
                # è¿›ç¨‹å·²ç»“æŸï¼Œè·³å‡ºå¾ªç¯
                logger.info(f"ç™»å½•è„šæœ¬è¿›ç¨‹å·²ç»“æŸï¼Œè¿”å›ç : {poll_result}")
                break
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_email_file):
            try:
                os.remove(temp_email_file)
            except:
                pass
        
        # æ£€æŸ¥ç™»å½•ç»“æœ
        if login_success or config_saved:
            # ç™»å½•æˆåŠŸï¼Œæ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦æœ‰æ›´æ–°
            config_file = os.path.join(BASE_DIR, "gemini_business_login_configs.txt")
            if os.path.exists(config_file):
                # è¯»å–é…ç½®æ–‡ä»¶ä¸­çš„æœ€æ–°é…ç½®
                with open(config_file, 'r', encoding='utf-8') as f:
                    config_content = f.read()
                
                # è§£ææœ€æ–°çš„é…ç½®ï¼ˆæŸ¥æ‰¾å¯¹åº”é‚®ç®±çš„é…ç½®ï¼‰
                new_config = parse_login_config(config_content, account_email)
                
                if new_config:
                    # æ›´æ–° .env æ–‡ä»¶ä¸­çš„è´¦å·é…ç½®
                    update_account_in_env(account_index, new_config)
                    
                    # é‡æ–°åŠ è½½é…ç½®
                    try:
                        reload_accounts_from_env_file()
                    except Exception as e:
                        logger.warning(f"é‡æ–°åŠ è½½è´¦å·é…ç½®å¤±è´¥: {e}")
                    
                    # æ›´æ–°æ•°æ®åº“ä¸­çš„ Cookie çŠ¶æ€
                    check_time = get_beijing_time()
                    account_status = db.query(AccountCookieStatus).filter(
                        AccountCookieStatus.account_name == target_account["name"]
                    ).first()
                    
                    if account_status:
                        account_status.cookie_status = "valid"
                        account_status.last_check_at = check_time
                        account_status.error_message = None
                        account_status.updated_at = check_time
                    else:
                        account_status = AccountCookieStatus(
                            account_name=target_account["name"],
                            cookie_status="valid",
                            last_check_at=check_time,
                            error_message=None
                        )
                        db.add(account_status)
                    
                    db.commit()
                    
                    logger.info(f"âœ… è´¦å·ç™»å½•æˆåŠŸ: {account_email}ï¼Œæµè§ˆå™¨ä¿æŒæ‰“å¼€")
                    return {
                        "status": "success",
                        "message": f"è´¦å· {account_email} ç™»å½•æˆåŠŸï¼ŒCookie å·²æ›´æ–°ã€‚æµè§ˆå™¨ä¿æŒæ‰“å¼€çŠ¶æ€ã€‚"
                    }
                else:
                    logger.warning(f"âš ï¸ æœªèƒ½ä»é…ç½®æ–‡ä»¶ä¸­è§£æåˆ°è´¦å· {account_email} çš„é…ç½®")
                    return {
                        "status": "warning",
                        "message": f"ç™»å½•è„šæœ¬æ‰§è¡Œå®Œæˆï¼Œä½†æœªèƒ½è§£æåˆ°æ–°çš„é…ç½®"
                    }
            else:
                logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
                return {
                    "status": "warning",
                    "message": "ç™»å½•è„šæœ¬æ‰§è¡Œå®Œæˆï¼Œä½†é…ç½®æ–‡ä»¶ä¸å­˜åœ¨"
                }
        else:
            # ç™»å½•å¤±è´¥æˆ–è¶…æ—¶
            error_msg = "\n".join(output_lines[-10:]) if output_lines else "æœªçŸ¥é”™è¯¯"
            logger.error(f"âŒ è´¦å·ç™»å½•å¤±è´¥: {account_email}")
            # ç»ˆæ­¢è„šæœ¬è¿›ç¨‹
            try:
                process.terminate()
            except:
                pass
            raise HTTPException(status_code=500, detail=f"ç™»å½•å¤±è´¥: {error_msg}")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ç™»å½•è´¦å·å¼‚å¸¸: {e}")
        raise HTTPException(status_code=500, detail=f"ç™»å½•å¼‚å¸¸: {str(e)}")


def parse_login_config(config_content: str, target_email: str) -> Optional[Dict[str, str]]:
    """
    ä»ç™»å½•é…ç½®æ–‡ä»¶å†…å®¹ä¸­è§£ææŒ‡å®šé‚®ç®±çš„é…ç½®
    
    Args:
        config_content: é…ç½®æ–‡ä»¶å†…å®¹
        target_email: ç›®æ ‡é‚®ç®±
        
    Returns:
        é…ç½®å­—å…¸ï¼ŒåŒ…å« secure_c_ses, csesidx, config_id, host_c_oses
    """
    # æŒ‰è´¦å·å—åˆ†å‰²
    blocks = config_content.split("# " + "-" * 60)
    
    for block in blocks:
        lines = block.strip().split('\n')
        config = {}
        email_found = False
        
        for line in lines:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            
            if '=' in line:
                key, value = line.split('=', 1)
                key = key.strip().upper()
                value = value.strip().strip('"').strip("'")
                
                if key == 'NAME':
                    if value == target_email or target_email in value:
                        email_found = True
                    config['name'] = value
                elif key == 'SECURE_C_SES':
                    config['secure_c_ses'] = value
                elif key == 'CSESIDX':
                    config['csesidx'] = value
                elif key == 'CONFIG_ID':
                    config['config_id'] = value
                elif key == 'HOST_C_OSES':
                    config['host_c_oses'] = value
        
        # å¦‚æœæ‰¾åˆ°äº†ç›®æ ‡é‚®ç®±çš„é…ç½®ï¼Œè¿”å›
        if email_found and config.get('secure_c_ses') and config.get('csesidx') and config.get('config_id'):
            return config
    
    return None


def update_account_in_env(account_index: int, new_config: Dict[str, str]):
    """
    æ›´æ–° .env æ–‡ä»¶ä¸­æŒ‡å®šè´¦å·çš„é…ç½®
    
    Args:
        account_index: è´¦å·ç´¢å¼•
        new_config: æ–°çš„é…ç½®å­—å…¸
    """
    env_file = os.path.join(BASE_DIR, ".env")
    
    if not os.path.exists(env_file):
        logger.warning(f".env æ–‡ä»¶ä¸å­˜åœ¨: {env_file}")
        return
    
    with open(env_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # æ ¹æ®è´¦å·ç´¢å¼•ç¡®å®šç¯å¢ƒå˜é‡å‰ç¼€
    if account_index == 0:
        prefix = ""  # é»˜è®¤è´¦å·æ²¡æœ‰å‰ç¼€
    else:
        prefix = f"ACCOUNT{account_index}_"
    
    # æ›´æ–°æˆ–æ·»åŠ é…ç½®
    updated_keys = set()
    new_lines = []
    
    for line in lines:
        line_stripped = line.strip()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è¦æ›´æ–°çš„é…ç½®é¡¹
        updated = False
        for config_key, env_suffix in [
            ('secure_c_ses', 'SECURE_C_SES'),
            ('csesidx', 'CSESIDX'),
            ('config_id', 'CONFIG_ID'),
            ('host_c_oses', 'HOST_C_OSES')
        ]:
            env_key = f"{prefix}{env_suffix}"
            if line_stripped.startswith(f"{env_key}=") or line_stripped.startswith(f"{env_key} ="):
                if config_key in new_config and new_config[config_key]:
                    new_lines.append(f'{env_key}="{new_config[config_key]}"\n')
                    updated_keys.add(config_key)
                    updated = True
                break
        
        if not updated:
            new_lines.append(line)
    
    # æ·»åŠ ç¼ºå¤±çš„é…ç½®é¡¹
    for config_key, env_suffix in [
        ('secure_c_ses', 'SECURE_C_SES'),
        ('csesidx', 'CSESIDX'),
        ('config_id', 'CONFIG_ID'),
        ('host_c_oses', 'HOST_C_OSES')
    ]:
        if config_key not in updated_keys and config_key in new_config and new_config[config_key]:
            env_key = f"{prefix}{env_suffix}"
            new_lines.append(f'{env_key}="{new_config[config_key]}"\n')
    
    # å†™å›æ–‡ä»¶
    with open(env_file, 'w', encoding='utf-8') as f:
        f.writelines(new_lines)
    
    logger.info(f"âœ… å·²æ›´æ–° .env æ–‡ä»¶ä¸­è´¦å· {account_index} çš„é…ç½®")


# ---------- API å¯†é’¥éªŒè¯ä¸­é—´ä»¶ ----------
async def verify_api_key_middleware(request: Request, call_next):
    """éªŒè¯ API å¯†é’¥"""
    from fastapi.responses import JSONResponse
    import time as time_module
    
    # åªå¯¹ /v1/ å¼€å¤´çš„è·¯å¾„è¿›è¡ŒéªŒè¯
    if request.url.path.startswith("/v1/"):
        auth_header = request.headers.get("Authorization")
        start_time = time_module.time()
        
        if not auth_header or not auth_header.startswith("Bearer "):
            return JSONResponse(
                status_code=401,
                content={"detail": "ç¼ºå°‘ API å¯†é’¥"}
            )
        
        api_key = auth_header.replace("Bearer ", "")
        key_hash = hash_api_key(api_key)
        
        # è·å–æ•°æ®åº“ä¼šè¯
        db = next(get_db())
        db_key = None
        client_ip = request.client.host if request.client else "unknown"
        
        try:
            db_key = db.query(APIKey).filter(APIKey.key_hash == key_hash).first()
            
            if not db_key:
                return JSONResponse(
                    status_code=401,
                    content={"detail": "æ— æ•ˆçš„ API å¯†é’¥"}
                )
            
            if not db_key.is_active:
                return JSONResponse(
                    status_code=401,
                    content={"detail": "API å¯†é’¥å·²è¢«æ’¤é”€"}
                )
            
            # ç¡®ä¿ expires_at æ˜¯ aware datetime ä»¥ä¾¿æ¯”è¾ƒ
            expires_at = ensure_aware(db_key.expires_at)
            if expires_at < get_beijing_time():
                return JSONResponse(
                    status_code=401,
                    content={"detail": "API å¯†é’¥å·²è¿‡æœŸ"}
                )
            
            # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡ï¼ˆå­˜å‚¨æ—¶ä½¿ç”¨ naive datetimeï¼‰
            db_key.usage_count += 1
            db_key.last_used_at = ensure_naive(get_beijing_time())
            db.commit()
            
            # å­˜å‚¨åˆ°è¯·æ±‚çŠ¶æ€ï¼Œç”¨äºåç»­è®°å½•
            request.state.api_key_id = db_key.id
            request.state.start_time = start_time
            request.state.client_ip = client_ip
            
        except Exception as e:
            logger.error(f"API key validation error: {e}")
            return JSONResponse(
                status_code=500,
                content={"detail": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}
            )
        finally:
            db.close()
    
    # æ‰§è¡Œå®é™…è¯·æ±‚
    response = await call_next(request)
    
    # è®°å½•è°ƒç”¨æ—¥å¿—
    if request.url.path.startswith("/v1/") and hasattr(request.state, "api_key_id"):
        db = next(get_db())
        try:
            # å°è¯•ä»è¯·æ±‚ä½“è·å–æ¨¡å‹ä¿¡æ¯
            model = "unknown"
            if hasattr(request.state, "model"):
                model = request.state.model
            
            response_time = int((time_module.time() - request.state.start_time) * 1000)
            
            log_entry = APICallLog(
                api_key_id=request.state.api_key_id,
                timestamp=ensure_naive(get_beijing_time()),
                model=model,
                status="success" if response.status_code < 400 else "error",
                error_message=None if response.status_code < 400 else f"HTTP {response.status_code}",
                ip_address=request.state.client_ip,
                endpoint=request.url.path,
                response_time=response_time
            )
            db.add(log_entry)
            db.commit()
            
            # å¹¿æ’­æ›´æ–°æ¶ˆæ¯
            await manager.broadcast("update")
        except Exception as e:
            logger.error(f"Failed to log API call: {e}")
        finally:
            db.close()
    
    return response

app.middleware("http")(verify_api_key_middleware)


@app.post("/admin/chat/completions")
async def admin_chat(
    req: ChatRequest,
    admin: Admin = Depends(get_current_admin)
):
    """ç®¡ç†å‘˜ä¸“ç”¨çš„èŠå¤©æ¥å£ï¼Œæ— éœ€ API å¯†é’¥"""
    # å¤ç”¨ç°æœ‰çš„èŠå¤©é€»è¾‘ï¼Œä½†ä¸è®°å½•åˆ° API è°ƒç”¨æ—¥å¿—
    request = Request({"type": "http", "method": "POST", "path": "/admin/chat/completions"})
    request.state.model = req.model
    
    # 1. æ¨¡å‹æ ¡éªŒ
    if req.model not in MODEL_MAPPING:
        raise HTTPException(
            status_code=404, detail=f"Model '{req.model}' not found."
        )

    if ACCOUNT_POOL is None:
        raise HTTPException(
            status_code=500,
            detail="No Gemini business accounts configured",
        )

    # 2. è§£æè¯·æ±‚å†…å®¹
    last_text, current_images = parse_last_message(req.messages)

    # 3. é”šå®šå¯¹è¯ & è´¦å·
    conv_key = get_conversation_key([m.dict() for m in req.messages])
    account = ACCOUNT_POOL.get_for_conversation(conv_key)
    cached = SESSION_CACHE.get(conv_key)

    if cached:
        google_session = cached["session_id"]
        text_to_send = last_text
        logger.info(
            f"â™»ï¸ ç®¡ç†å‘˜å¯¹è¯å»¶ç»­æ—§å¯¹è¯[{req.model}] è´¦å·={account.name} session={google_session[-12:]}"
        )
        cached["updated_at"] = time.time()
        is_retry_mode = False
    else:
        logger.info(f"ğŸ†• ç®¡ç†å‘˜å¼€å¯æ–°å¯¹è¯ [{req.model}] ä½¿ç”¨è´¦å· {account.name}")

        google_session: Optional[str] = None
        first_error: Optional[Exception] = None
        tried_accounts = set()

        while True:
            tried_accounts.add(account.name)
            try:
                google_session = await create_google_session(account)
                break
            except HTTPException as e:
                if e.status_code in (401, 403, 429):
                    account.mark_quota_error(e.status_code, str(e.detail))
                    alt = ACCOUNT_POOL.get_alternative(account.name)
                    if not alt or alt.name in tried_accounts:
                        if first_error:
                            raise first_error
                        raise e
                    first_error = e
                    account = alt
                    continue
                raise

        SESSION_CACHE[conv_key] = {
            "session_id": google_session,
            "updated_at": time.time(),
            "account": account.name,
        }
        text_to_send = build_full_context_text(req.messages)
        is_retry_mode = True

    chat_id = f"chatcmpl-admin-{uuid.uuid4().hex[:8]}"
    created_time = int(time.time())

    # 4. å°è£…ç”Ÿæˆé€»è¾‘
    async def response_wrapper():
        nonlocal account

        retry_count = 0
        max_retries = 2

        current_text = text_to_send
        current_retry_mode = is_retry_mode
        current_file_ids: List[str] = []

        while retry_count <= max_retries:
            try:
                cached_session = SESSION_CACHE.get(conv_key)
                if not cached_session:
                    new_sess = await create_google_session(account)
                    SESSION_CACHE[conv_key] = {
                        "session_id": new_sess,
                        "updated_at": time.time(),
                        "account": account.name,
                    }
                    cached_session = SESSION_CACHE[conv_key]

                current_session = cached_session["session_id"]

                # A. å¦‚æœæœ‰å›¾ç‰‡ä¸”è¿˜æ²¡ä¸Šä¼ åˆ°å½“å‰ Sessionï¼Œå…ˆä¸Šä¼ 
                if current_images and not current_file_ids:
                    for img in current_images:
                        fid = await upload_context_file(
                            account, current_session, img["mime"], img["data"]
                        )
                        current_file_ids.append(fid)

                # B. å‡†å¤‡æ–‡æœ¬ (é‡è¯•æ¨¡å¼ä¸‹å‘å…¨æ–‡)
                if current_retry_mode:
                    current_text = build_full_context_text(req.messages)

                # C. å‘èµ·å¯¹è¯
                async for chunk in stream_chat_generator(
                    account,
                    current_session,
                    current_text,
                    current_file_ids,
                    req.model,
                    chat_id,
                    created_time,
                    req.stream,
                ):
                    yield chunk
                break

            except (httpx.ConnectError, httpx.ReadTimeout, ssl.SSLError,
                    asyncio.TimeoutError) as e:
                retry_count += 1
                if retry_count > max_retries:
                    logger.error(f"ç½‘ç»œé”™è¯¯é‡è¯•å¤±è´¥ [{account.name}]: {e}")
                    raise HTTPException(status_code=503, detail="Service Unavailable")
                logger.warning(f"ç½‘ç»œé”™è¯¯ï¼Œé‡è¯• {retry_count}/{max_retries} [{account.name}]")
                await asyncio.sleep(1)
                continue

            except HTTPException as e:
                if e.status_code in (401, 403, 429):
                    account.mark_quota_error(e.status_code, str(e.detail))
                    alt = ACCOUNT_POOL.get_alternative(account.name)
                    if alt and alt.name != account.name:
                        logger.info(f"åˆ‡æ¢åˆ°å¤‡ç”¨è´¦å·: {alt.name}")
                        account = alt
                        retry_count = 0
                        continue
                raise

    if req.stream:
        return StreamingResponse(
            response_wrapper(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            },
        )

    # éæµå¼å“åº”
    full_content = ""
    async for chunk_str in response_wrapper():
        if chunk_str.startswith("data: [DONE]"):
            break
        if chunk_str.startswith("data: "):
            try:
                data = json.loads(chunk_str[6:])
                delta = data["choices"][0]["delta"]
                if "content" in delta:
                    full_content += delta["content"]
            except Exception:
                pass

    response_data = {
        "id": chat_id,
        "object": "chat.completion",
        "created": created_time,
        "model": req.model,
        "choices": [
            {
                "index": 0,
                "message": {"role": "assistant", "content": full_content},
                "finish_reason": "stop",
            }
        ],
        "usage": {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0,
        },
    }

    return response_data


@app.post("/v1/chat/completions")
async def chat(req: ChatRequest, request: Request):
    # è®°å½•æ¨¡å‹åˆ°è¯·æ±‚çŠ¶æ€
    request.state.model = req.model
    
    # 1. æ¨¡å‹æ ¡éªŒ
    if req.model not in MODEL_MAPPING:
        raise HTTPException(
            status_code=404, detail=f"Model '{req.model}' not found."
        )

    if ACCOUNT_POOL is None:
        raise HTTPException(
            status_code=500,
            detail="No Gemini business accounts configured",
        )

    # 2. è§£æè¯·æ±‚å†…å®¹
    last_text, current_images = parse_last_message(req.messages)

    # 3. é”šå®šå¯¹è¯ & è´¦å·
    conv_key = get_conversation_key([m.dict() for m in req.messages])
    account = ACCOUNT_POOL.get_for_conversation(conv_key)
    cached = SESSION_CACHE.get(conv_key)

    if cached:
        google_session = cached["session_id"]
        text_to_send = last_text
        logger.info(
            f"â™»ï¸ å»¶ç»­æ—§å¯¹è¯[{req.model}] è´¦å·={account.name} session={google_session[-12:]}"
        )
        cached["updated_at"] = time.time()
        is_retry_mode = False
    else:
        logger.info(f"ğŸ†• å¼€å¯æ–°å¯¹è¯ [{req.model}] ä½¿ç”¨è´¦å· {account.name}")

        google_session: Optional[str] = None
        first_error: Optional[Exception] = None
        tried_accounts = set()

        while True:
            tried_accounts.add(account.name)
            try:
                google_session = await create_google_session(account)
                break
            except HTTPException as e:
                if e.status_code in (401, 403, 429):
                    account.mark_quota_error(e.status_code, str(e.detail))
                    alt = ACCOUNT_POOL.get_alternative(account.name)
                    if not alt or alt.name in tried_accounts:
                        first_error = e
                        break
                    logger.info(
                        f"createSession é…é¢å—é™ï¼Œåˆ‡æ¢è´¦å· {account.name} -> {alt.name}"
                    )
                    account = alt
                    continue
                first_error = e
                break
            except Exception as e:
                first_error = e
                break

        if not google_session:
            if isinstance(first_error, HTTPException):
                raise first_error
            raise HTTPException(status_code=500, detail="No available account")

        text_to_send = build_full_context_text(req.messages)
        SESSION_CACHE[conv_key] = {
            "session_id": google_session,
            "updated_at": time.time(),
            "account": account.name,
        }
        is_retry_mode = True

    chat_id = f"chatcmpl-{uuid.uuid4()}"
    created_time = int(time.time())

    # 4. å°è£…ç”Ÿæˆé€»è¾‘ï¼ˆå«å›¾ç‰‡ä¸Šä¼ ã€é‡è¯•å’Œè´¦å·åˆ‡æ¢ï¼‰
    async def response_wrapper():
        nonlocal account

        retry_count = 0
        max_retries = 2

        current_text = text_to_send
        current_retry_mode = is_retry_mode
        current_file_ids: List[str] = []

        while retry_count <= max_retries:
            try:
                cached_session = SESSION_CACHE.get(conv_key)
                if not cached_session:
                    new_sess = await create_google_session(account)
                    SESSION_CACHE[conv_key] = {
                        "session_id": new_sess,
                        "updated_at": time.time(),
                        "account": account.name,
                    }
                    cached_session = SESSION_CACHE[conv_key]

                current_session = cached_session["session_id"]

                # A. å¦‚æœæœ‰å›¾ç‰‡ä¸”è¿˜æ²¡ä¸Šä¼ åˆ°å½“å‰ Sessionï¼Œå…ˆä¸Šä¼ 
                if current_images and not current_file_ids:
                    for img in current_images:
                        fid = await upload_context_file(
                            account, current_session, img["mime"], img["data"]
                        )
                        current_file_ids.append(fid)

                # B. å‡†å¤‡æ–‡æœ¬ (é‡è¯•æ¨¡å¼ä¸‹å‘å…¨æ–‡)
                if current_retry_mode:
                    current_text = build_full_context_text(req.messages)

                # C. å‘èµ·å¯¹è¯
                async for chunk in stream_chat_generator(
                    account,
                    current_session,
                    current_text,
                    current_file_ids,
                    req.model,
                    chat_id,
                    created_time,
                    req.stream,
                ):
                    yield chunk
                break

            except (httpx.ConnectError, httpx.ReadTimeout, ssl.SSLError, HTTPException) as e:
                retry_count += 1
                logger.warning(
                    f"âš ï¸ è¯·æ±‚å¼‚å¸¸ (é‡è¯• {retry_count}/{max_retries}) è´¦å·={account.name}: {e}"
                )

                status_code = getattr(e, "status_code", None)

                # å…ˆåˆ¤å®šé…é¢/æƒé™ç±»é”™è¯¯ï¼Œå°è¯•åˆ‡æ¢è´¦å·
                if isinstance(e, HTTPException) and status_code in (401, 403, 429):
                    account.mark_quota_error(status_code, str(e.detail))
                    alt = ACCOUNT_POOL.get_alternative(account.name)
                    if alt:
                        logger.info(f"ğŸ” åˆ‡æ¢åˆ°å¤‡ç”¨è´¦å· {alt.name}")
                        account = alt
                        try:
                            new_sess = await create_google_session(account)
                            SESSION_CACHE[conv_key] = {
                                "session_id": new_sess,
                                "updated_at": time.time(),
                                "account": account.name,
                            }
                            current_retry_mode = True
                            current_file_ids = []
                            continue
                        except Exception as create_err:
                            logger.error(
                                f"å¤‡ç”¨è´¦å·åˆ›å»º Session å¤±è´¥: {create_err}"
                            )
                            if req.stream:
                                yield "data: " + json.dumps(
                                    {
                                        "error": {
                                            "message": "All accounts exhausted"
                                        }
                                    }
                                ) + "\n\n"
                                return
                            raise

                # éé…é¢é”™è¯¯æˆ–åˆ‡æ¢å¤±è´¥ï¼Œå°è¯•å½“å‰è´¦å·é‡å»º session
                if retry_count <= max_retries:
                    logger.info("ğŸ”„ å°è¯•é‡å»º Session...")
                    try:
                        new_sess = await create_google_session(account)
                        SESSION_CACHE[conv_key] = {
                            "session_id": new_sess,
                            "updated_at": time.time(),
                            "account": account.name,
                        }
                        current_retry_mode = True
                        current_file_ids = []
                    except Exception as create_err:
                        logger.error(f"Session é‡å»ºå¤±è´¥: {create_err}")
                        if req.stream:
                            yield "data: " + json.dumps(
                                {
                                    "error": {
                                        "message": "Session Recovery Failed"
                                    }
                                }
                            ) + "\n\n"
                            return
                        raise
                else:
                    if req.stream:
                        yield "data: " + json.dumps(
                            {"error": {"message": f"Final Error: {e}"}}
                        ) + "\n\n"
                        return
                    raise

    if req.stream:
        return StreamingResponse(
            response_wrapper(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            },
        )

    full_content = ""
    async for chunk_str in response_wrapper():
        if chunk_str.startswith("data: [DONE]"):
            break
        if chunk_str.startswith("data: "):
            try:
                data = json.loads(chunk_str[6:])
                delta = data["choices"][0]["delta"]
                if "content" in delta:
                    full_content += delta["content"]
            except Exception:
                pass

    response_data = {
        "id": chat_id,
        "object": "chat.completion",
        "created": created_time,
        "model": req.model,
        "choices": [
            {
                "index": 0,
                "message": {"role": "assistant", "content": full_content},
                "finish_reason": "stop",
            }
        ],
        "usage": {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0,
        },
    }

    return response_data


async def stream_chat_generator(
    account: Account,
    session: str,
    text_content: str,
    file_ids: List[str],
    model_name: str,
    chat_id: str,
    created_time: int,
    is_stream: bool = True,
):
    jwt = await account.jwt_mgr.get()
    headers = get_common_headers(jwt)

    body: Dict[str, Any] = {
        "configId": account.config_id,
        "additionalParams": {"token": "-"},
        "streamAssistRequest": {
            "session": session,
            "query": {"parts": [{"text": text_content}]},
            "filter": "",
            "fileIds": file_ids,
            "answerGenerationMode": "NORMAL",
            "toolsSpec": {
                "webGroundingSpec": {},
                "toolRegistry": "default_tool_registry",
                "imageGenerationSpec": {},
                "videoGenerationSpec": {},
            },
            "languageCode": "zh-CN",
            "userMetadata": {"timeZone": "Asia/Shanghai"},
            "assistSkippingMode": "REQUEST_ASSIST",
        },
    }

    target_model_id = MODEL_MAPPING.get(model_name)
    if target_model_id:
        body["streamAssistRequest"]["assistGenerationConfig"] = {
            "modelId": target_model_id
        }

    if is_stream:
        chunk = create_chunk(
            chat_id, created_time, model_name, {"role": "assistant"}, None
        )
        yield f"data: {chunk}\n\n"

    r = await http_client.post(
        "https://biz-discoveryengine.googleapis.com/v1alpha/locations/global/widgetStreamAssist",
        headers=headers,
        json=body,
    )

    if r.status_code != 200:
        logger.error(
            f"widgetStreamAssist å¤±è´¥ [{account.name}]: {r.status_code} {r.text}"
        )
        if r.status_code in (401, 403, 429):
            account.mark_quota_error(r.status_code, r.text)
        raise HTTPException(status_code=r.status_code, detail=f"Upstream Error {r.text}")

    try:
        data_list = r.json()
    except Exception as e:  # noqa: BLE001
        logger.error(f"JSON è§£æå¤±è´¥ [{account.name}]: {e}")
        raise HTTPException(status_code=502, detail="Invalid JSON response")

    # ========== ç¬¬ä¸€æ­¥ï¼šæ”¶é›†æ–‡æœ¬å†…å®¹å’Œæ€è€ƒè¿‡ç¨‹ ==========
    full_content = ""
    generated_images: List[ChatImage] = []
    thinking_parts = []

    for data in data_list:
        for reply in (
            data.get("streamAssistResponse", {})
            .get("answer", {})
            .get("replies", [])
        ):
            # æå– API è¿”å›çš„ thought å­—æ®µ
            thought = reply.get("thought", "")
            if thought:
                thinking_parts.append(thought)
            
            # æå–æ­£æ–‡å†…å®¹
            text = (
                reply.get("groundedContent", {})
                .get("content", {})
                .get("text", "")
            )
            if text and not thought:
                full_content += text

    # ========== ç¬¬äºŒæ­¥ï¼šä»æ­£æ–‡ä¸­æå– **æ ‡é¢˜** æ ¼å¼çš„æ€è€ƒæ ‡é¢˜ ==========
    lines = full_content.splitlines()
    filtered_lines = []
    thinking_titles = []
    
    for line in lines:
        # åŒ¹é…å•ç‹¬æˆè¡Œçš„ **æ ‡é¢˜** æ ¼å¼
        m = re.match(r'^\s*\*\*([^*]+)\*\*\s*$', line)
        if m:
            title_text = m.group(1).strip()
            # åˆ¤æ–­æ˜¯å¦æ˜¯æ€è€ƒæ ‡é¢˜ï¼šè‹±æ–‡çŸ­è¯­ï¼Œé•¿åº¦é€‚ä¸­ï¼Œä¸è¶…è¿‡6ä¸ªå•è¯
            if (re.match(r'^[A-Za-z\s\'\-\(\)]+$', title_text) and 
                len(title_text) < 100 and 
                len(title_text.split()) <= 6):
                thinking_titles.append(title_text)
                continue  # è·³è¿‡æ€è€ƒæ ‡é¢˜è¡Œ
        filtered_lines.append(line)
    
    if thinking_titles:
        thinking_parts.extend(thinking_titles)
    
    # æ›´æ–°æ­£æ–‡å†…å®¹ï¼ˆå·²ç§»é™¤æ€è€ƒæ ‡é¢˜ï¼‰
    full_content = "\n".join(filtered_lines).strip()

    # ========== ç¬¬ä¸‰æ­¥ï¼šå¤„ç†å¹¶å‘é€æ€è€ƒè¿‡ç¨‹ ==========
    if thinking_parts:
        thinking_content = "\n\n".join(thinking_parts)
        thinking_html = f"<details><summary>æ˜¾ç¤ºæ€è·¯</summary>\n\n{thinking_content}\n\n</details>\n\n"
        full_content = thinking_html + full_content
        
        if is_stream:
            # å‘é€ thinking å­—æ®µï¼ˆå…¼å®¹æ”¯æŒè¯¥å­—æ®µçš„å‰ç«¯ï¼‰
            thinking_chunk = create_chunk(
                chat_id, created_time, model_name, {"thinking": thinking_content}, None
            )
            yield f"data: {thinking_chunk}\n\n"
        logger.info(f"ğŸ“ æå–åˆ° {len(thinking_parts)} ä¸ªæ€è€ƒæ­¥éª¤ [{account.name}]")

    # ========== ç¬¬å››æ­¥ï¼šæµå¼å‘é€æ­£æ–‡å†…å®¹ï¼ˆé€å­—è¾“å‡ºï¼‰ ==========
    if full_content:
        if is_stream:
            # æµå¼è¾“å‡ºï¼šå°†å†…å®¹åˆ†å—å‘é€ï¼Œæ¨¡æ‹Ÿé€å­—è¾“å‡º
            # ä½¿ç”¨è¾ƒå°çš„åˆ†å—å’Œé€‚å½“çš„å»¶è¿Ÿï¼Œå®ç°å¹³æ»‘çš„æµå¼æ•ˆæœ
            chunk_size = 4  # æ¯æ¬¡å‘é€4ä¸ªå­—ç¬¦ï¼Œå¹³è¡¡æµç•…åº¦å’Œæ€§èƒ½
            sent_length = 0
            total_chunks = 0
            
            while sent_length < len(full_content):
                # è®¡ç®—æœ¬æ¬¡è¦å‘é€çš„å†…å®¹
                end_pos = min(sent_length + chunk_size, len(full_content))
                delta_content = full_content[sent_length:end_pos]
                
                if delta_content:
                    chunk = create_chunk(
                        chat_id, created_time, model_name, {"content": delta_content}, None
                    )
                    yield f"data: {chunk}\n\n"
                    sent_length = end_pos
                    total_chunks += 1
                    # æ·»åŠ å»¶è¿Ÿï¼Œæ¨¡æ‹ŸçœŸå®æµå¼è¾“å‡ºï¼ˆ30msï¼Œçº¦æ¯ç§’33ä¸ªå­—ç¬¦ï¼‰
                    # è¿™ä¸ªé€Ÿåº¦æ—¢ä¸ä¼šå¤ªå¿«ä¹Ÿä¸ä¼šå¤ªæ…¢ï¼Œé€‚åˆå¤§å¤šæ•°å®¢æˆ·ç«¯
                    await asyncio.sleep(0.03)
            
            logger.debug(f"ğŸ“¤ æµå¼å‘é€å®Œæˆ: {total_chunks} ä¸ªæ•°æ®å—, æ€»é•¿åº¦ {len(full_content)} å­—ç¬¦")
        else:
            # éæµå¼ï¼šä¸€æ¬¡æ€§å‘é€å®Œæ•´å†…å®¹
            chunk = create_chunk(
                chat_id, created_time, model_name, {"content": full_content}, None
            )
            yield f"data: {chunk}\n\n"

    # ========== ç¬¬äº”æ­¥ï¼šè§£æå¹¶ä¸‹è½½ç”Ÿæˆçš„å›¾ç‰‡ ==========
    image_file_ids, response_session = parse_images_from_response(data_list)
    
    if response_session and response_session != session:
        logger.info(f"ğŸ”„ æ£€æµ‹åˆ°æ–° Session [{account.name}]: ...{response_session[-15:]}")

    if image_file_ids:
        logger.info(f"ğŸ–¼ï¸  æ£€æµ‹åˆ° {len(image_file_ids)} ä¸ªç”Ÿæˆå›¾ç‰‡ [{account.name}]")
        session_for_download = response_session or session

        try:
            file_metadata = await get_session_file_metadata(account, session_for_download)
            existing_image_count = 0

            for idx, finfo in enumerate(image_file_ids):
                fid = finfo["fileId"]
                mime = finfo["mimeType"]
                meta = file_metadata.get(fid, {})
                file_name = meta.get("name")
                session_path = meta.get("session") or session_for_download

                image_index = existing_image_count + idx + 1
                img = await save_generated_image(account, session_path, fid, file_name, mime, chat_id, image_index)
                generated_images.append(img)

        except Exception as e:
            logger.error(f"âŒ å¤„ç†ç”Ÿæˆå›¾ç‰‡å¤±è´¥ [{account.name}]: {e}", exc_info=True)

    # ========== ç¬¬å…­æ­¥ï¼šå°†å›¾ç‰‡é“¾æ¥æ·»åŠ åˆ°æ–‡æœ¬å†…å®¹ä¸­ ==========
    if generated_images:
        image_markdown = "\n\n"
        for img in generated_images:
            if img.base64_data:
                image_markdown += f"![ç”Ÿæˆçš„å›¾ç‰‡](data:{img.mime_type};base64,{img.base64_data})\n\n"
        
        if image_markdown.strip():
            full_content += image_markdown
            if is_stream:
                chunk = create_chunk(
                    chat_id, created_time, model_name, {"content": image_markdown}, None
                )
                yield f"data: {chunk}\n\n"
            logger.info(f"âœ… å·²å°† {len(generated_images)} å¼ å›¾ç‰‡æ·»åŠ åˆ°å›å¤ä¸­ [{account.name}]")

    if is_stream:
        final_chunk = create_chunk(
            chat_id, created_time, model_name, {}, "stop"
        )
        yield f"data: {final_chunk}\n\n"
        yield "data: [DONE]\n\n"


# ---------- ä¿æ´»ä»»åŠ¡è°ƒåº¦å™¨ ----------
scheduler = AsyncIOScheduler(timezone=BEIJING_TZ)

# å½“å‰è¿è¡Œçš„ä¿æ´»ä»»åŠ¡è¿›ç¨‹ï¼ˆç”¨äºä¸­æ–­ï¼‰
current_keep_alive_process: Optional[subprocess.Popen] = None
keep_alive_process_lock = asyncio.Lock()


def create_interval_trigger(interval_minutes: int, timezone):
    """
    æ ¹æ®é—´éš”åˆ†é’Ÿæ•°åˆ›å»ºåˆé€‚çš„è§¦å‘å™¨
    
    Args:
        interval_minutes: é—´éš”åˆ†é’Ÿæ•°ï¼ˆ5-1440ï¼‰
        timezone: æ—¶åŒºå¯¹è±¡
        
    Returns:
        è§¦å‘å™¨å¯¹è±¡ï¼ˆCronTrigger æˆ– IntervalTriggerï¼‰
    """
    if interval_minutes <= 59:
        # å°äºç­‰äº 59 åˆ†é’Ÿï¼Œä½¿ç”¨ CronTrigger çš„åˆ†é’Ÿçº§åˆ«
        return CronTrigger(minute=f"*/{interval_minutes}", timezone=timezone)
    else:
        # å¤§äº 59 åˆ†é’Ÿï¼Œä½¿ç”¨ IntervalTriggerï¼ˆç›´æ¥ä½¿ç”¨åˆ†é’Ÿæ•°ï¼‰
        return IntervalTrigger(minutes=interval_minutes, timezone=timezone)


async def execute_api_keepalive_task():
    """æ‰§è¡Œ Cookie æ£€æŸ¥ä»»åŠ¡ - æ£€æŸ¥è´¦å· Cookie æ˜¯å¦æœ‰æ•ˆï¼Œå¤±æ•ˆåˆ™è§¦å‘ä¿æ´»"""
    db = next(get_db())
    try:
        task = db.query(KeepAliveTask).first()
        if not task or not getattr(task, 'api_keepalive_enabled', True):
            logger.debug("Cookie æ£€æŸ¥ä»»åŠ¡å·²ç¦ç”¨ï¼Œè·³è¿‡æ‰§è¡Œ")
            return
        
        logger.info("ğŸ”„ å¼€å§‹æ‰§è¡Œ Cookie æ£€æŸ¥ä»»åŠ¡...")
        
        if ACCOUNT_POOL is None or not ACCOUNT_POOL.accounts:
            logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨è´¦å·ï¼Œè·³è¿‡ Cookie æ£€æŸ¥")
            return
        
        # é‡æ–°åŠ è½½è´¦å·é…ç½®
        try:
            reload_accounts_from_env_file()
        except Exception as e:
            logger.warning(f"âš ï¸ é‡æ–°åŠ è½½è´¦å·é…ç½®å¤±è´¥: {e}")
        
        success_count = 0
        fail_count = 0
        total_accounts = len(ACCOUNT_POOL.accounts)
        invalid_accounts = []  # è®°å½•æ— æ•ˆçš„è´¦å·ï¼Œç”¨äºè‡ªåŠ¨ä¿®å¤
        check_time = ensure_naive(get_beijing_time())  # è½¬æ¢ä¸º naive datetime ç”¨äºæ•°æ®åº“å­˜å‚¨
        
        # å¯¹æ¯ä¸ªè´¦å·æ‰§è¡Œä¸€æ¬¡ç®€å•çš„ API è°ƒç”¨
        for account in ACCOUNT_POOL.accounts:
            if not account.is_available():
                logger.debug(f"â­ï¸ è·³è¿‡ä¸å¯ç”¨è´¦å·: {account.name}")
                fail_count += 1
                continue
            
            cookie_status = "unknown"
            error_msg = None
            expires_at = None
            
            try:
                # åªéªŒè¯ JWT æ˜¯å¦æœ‰æ•ˆï¼Œé€šè¿‡åˆ·æ–° JWT æ¥ä¿æŒä¼šè¯æ´»è·ƒ
                # è¿™ç§æ–¹å¼æ›´è½»é‡ï¼Œä¸ä¼šäº§ç”Ÿå®é™…çš„ API è°ƒç”¨
                jwt = await account.jwt_mgr.get()
                if jwt:
                    cookie_status = "valid"
                    success_count += 1
                    logger.debug(f"âœ… Cookie æœ‰æ•ˆ: {account.name} (JWT åˆ·æ–°æˆåŠŸ)")
                    
                    # å°è¯•è·å– Cookie è¿‡æœŸæ—¶é—´ï¼ˆä»…ä»å“åº”å¤´è·å–ï¼Œä¸ä¼°ç®—ï¼‰
                    if hasattr(account, '_cookie_expires_at') and account._cookie_expires_at:
                        expires_at = account._cookie_expires_at
                else:
                    cookie_status = "unknown"
                    error_msg = "æ— æ³•è·å– JWT"
                    fail_count += 1
                    logger.warning(f"âš ï¸ Cookie æ£€æŸ¥å¤±è´¥ [{account.name}]: æ— æ³•è·å– JWT")
                    invalid_accounts.append(account.name)
                        
            except HTTPException as e:
                fail_count += 1
                error_msg = str(e.detail) if hasattr(e, 'detail') else str(e)
                if e.status_code in (401, 403):
                    # Cookie æ— æ•ˆï¼Œè®°å½•åˆ°å¾…ä¿®å¤åˆ—è¡¨
                    if e.status_code == 401:
                        cookie_status = "expired"
                        error_msg = "Cookie å·²è¿‡æœŸ"
                    elif e.status_code == 403:
                        cookie_status = "forbidden"
                        error_msg = "Cookie æ— æ•ˆæˆ–è¢«ç¦æ­¢"
                    account.mark_quota_error(e.status_code, str(e.detail))
                    invalid_accounts.append(account.name)
                    logger.warning(f"âš ï¸ Cookie æ— æ•ˆ [{account.name}]: {e.status_code} - å°†è§¦å‘ä¿æ´»")
                elif e.status_code == 429:
                    cookie_status = "rate_limited"
                    error_msg = "è¯·æ±‚è¿‡äºé¢‘ç¹"
                    account.mark_quota_error(e.status_code, str(e.detail))
                    logger.warning(f"âš ï¸ Cookie æ£€æŸ¥å¤±è´¥ [{account.name}]: è¯·æ±‚è¿‡äºé¢‘ç¹")
                else:
                    logger.warning(f"âš ï¸ Cookie æ£€æŸ¥å¤±è´¥ [{account.name}]: {e.status_code}")
            except Exception as e:
                fail_count += 1
                error_msg = str(e)
                logger.warning(f"âš ï¸ Cookie æ£€æŸ¥å¼‚å¸¸ [{account.name}]: {str(e)}")
            
            # ä¿å­˜æ£€æŸ¥ç»“æœåˆ°æ•°æ®åº“
            try:
                account_status = db.query(AccountCookieStatus).filter(
                    AccountCookieStatus.account_name == account.name
                ).first()
                
                if account_status:
                    # æ›´æ–°ç°æœ‰è®°å½•
                    account_status.cookie_status = cookie_status
                    account_status.last_check_at = check_time
                    # åªæœ‰åœ¨ Cookie æœ‰æ•ˆæ—¶æ‰æ›´æ–°è¿‡æœŸæ—¶é—´ï¼Œé¿å…è¦†ç›–æœ‰æ•ˆçš„è¿‡æœŸæ—¶é—´
                    if cookie_status == "valid" and expires_at:
                        account_status.expires_at = expires_at
                    account_status.error_message = error_msg
                    account_status.updated_at = check_time
                else:
                    # åˆ›å»ºæ–°è®°å½•
                    account_status = AccountCookieStatus(
                        account_name=account.name,
                        cookie_status=cookie_status,
                        last_check_at=check_time,
                        expires_at=expires_at if cookie_status == "valid" else None,
                        error_message=error_msg
                    )
                    db.add(account_status)
            except Exception as e:
                logger.error(f"ä¿å­˜è´¦å· Cookie çŠ¶æ€å¤±è´¥ [{account.name}]: {e}")
        
        # æ‰¹é‡æäº¤æ‰€æœ‰è´¦å·çŠ¶æ€æ›´æ–°
        try:
            db.commit()
            logger.debug(f"âœ… å·²ä¿å­˜ {total_accounts} ä¸ªè´¦å·çš„ Cookie çŠ¶æ€åˆ°æ•°æ®åº“")
        except Exception as e:
            logger.error(f"æ‰¹é‡ä¿å­˜ Cookie çŠ¶æ€å¤±è´¥: {e}")
            db.rollback()
        
        # å¦‚æœå¯ç”¨äº†è‡ªåŠ¨ä¿®å¤ï¼Œä¸”æ£€æµ‹åˆ°æ— æ•ˆè´¦å·ï¼Œåˆ™è°ƒç”¨æµè§ˆå™¨ä¿æ´»æ¥ä¿®å¤
        if invalid_accounts and getattr(task, 'auto_check_auto_fix', True):
            logger.info(f"ğŸ”§ æ£€æµ‹åˆ° {len(invalid_accounts)} ä¸ªæ— æ•ˆè´¦å·ï¼Œå¼€å§‹ä¿æ´»: {', '.join(invalid_accounts)}")
            try:
                # è°ƒç”¨æµè§ˆå™¨ä¿æ´»æ¥ä¿®å¤è¿™äº›è´¦å·
                # æ³¨æ„ï¼šè¿™é‡Œåªä¿®å¤æ— æ•ˆçš„è´¦å·ï¼Œæœ‰æ•ˆçš„è´¦å·ä¸å¤„ç†
                await execute_keep_alive_task_for_accounts(invalid_accounts)
                logger.info(f"âœ… ä¿æ´»å®Œæˆ: {len(invalid_accounts)} ä¸ªè´¦å·")
            except Exception as e:
                logger.error(f"âŒ ä¿æ´»å¤±è´¥: {e}")
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ï¼ˆä¸ Cookie çŠ¶æ€ä¸€èµ·æäº¤ï¼‰
        task.last_api_keepalive_at = get_beijing_time()
        task.last_message = f"Cookie æ£€æŸ¥å®Œæˆ: æœ‰æ•ˆ {success_count}/{total_accounts}"
        
        # å†æ¬¡æäº¤ä»»åŠ¡çŠ¶æ€ï¼ˆå¦‚æœä¹‹å‰å·²ç»æäº¤è¿‡ï¼Œè¿™é‡Œä¼šæ›´æ–°ä»»åŠ¡çŠ¶æ€ï¼‰
        try:
            db.commit()
            logger.info(f"âœ… Cookie æ£€æŸ¥ä»»åŠ¡å®Œæˆ: æœ‰æ•ˆ {success_count}/{total_accounts}ï¼Œå·²æ›´æ–° Cookie çŠ¶æ€")
        except Exception as e:
            logger.error(f"æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
            db.rollback()
        
    except Exception as e:
        logger.error(f"âŒ Cookie æ£€æŸ¥ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        if task:
            task.last_message = f"Cookie æ£€æŸ¥å¤±è´¥: {str(e)}"
            db.commit()
    finally:
        db.close()


async def execute_keep_alive_task_for_accounts(account_names: List[str] = None):
    """
    æ‰§è¡Œä¿æ´»ä»»åŠ¡ï¼ˆä»…é’ˆå¯¹æŒ‡å®šçš„è´¦å·ï¼‰
    
    Args:
        account_names: è¦å¤„ç†çš„è´¦å·åç§°åˆ—è¡¨ï¼Œå¦‚æœä¸º None åˆ™å¤„ç†æ‰€æœ‰è´¦å·
    """
    global current_keep_alive_process
    
    # å¦‚æœæŒ‡å®šäº†è´¦å·åˆ—è¡¨ï¼Œéœ€è¦ä¿®æ”¹ keep_alive_env.py æ¥åªå¤„ç†è¿™äº›è´¦å·
    # è¿™é‡Œæˆ‘ä»¬é€šè¿‡ç¯å¢ƒå˜é‡ä¼ é€’è´¦å·åˆ—è¡¨
    if account_names:
        import json
        os.environ['KEEP_ALIVE_TARGET_ACCOUNTS'] = json.dumps(account_names)
        logger.info(f"ğŸ¯ ä¿æ´»ä»»åŠ¡å°†åªå¤„ç†ä»¥ä¸‹è´¦å·: {', '.join(account_names)}")
    else:
        os.environ.pop('KEEP_ALIVE_TARGET_ACCOUNTS', None)
    
    # è°ƒç”¨åŸæœ‰çš„ä¿æ´»ä»»åŠ¡
    await execute_keep_alive_task()


async def execute_auto_check_task():
    """æ‰§è¡Œè‡ªåŠ¨æ£€æŸ¥ä»»åŠ¡ - æ£€æŸ¥æ‰€æœ‰è´¦å·çš„ Cookie çŠ¶æ€ï¼Œå¦‚æœæ— æ•ˆåˆ™è‡ªåŠ¨ä¿®å¤"""
    db = next(get_db())
    try:
        task = db.query(KeepAliveTask).first()
        if not task or not getattr(task, 'auto_check_enabled', False):
            logger.debug("è‡ªåŠ¨æ£€æŸ¥ä»»åŠ¡å·²ç¦ç”¨ï¼Œè·³è¿‡æ‰§è¡Œ")
            return
        
        logger.info("ğŸ” å¼€å§‹æ‰§è¡Œè‡ªåŠ¨æ£€æŸ¥ä»»åŠ¡...")
        
        if ACCOUNT_POOL is None or not ACCOUNT_POOL.accounts:
            logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨è´¦å·ï¼Œè·³è¿‡è‡ªåŠ¨æ£€æŸ¥")
            return
        
        # é‡æ–°åŠ è½½è´¦å·é…ç½®
        try:
            reload_accounts_from_env_file()
        except Exception as e:
            logger.warning(f"âš ï¸ é‡æ–°åŠ è½½è´¦å·é…ç½®å¤±è´¥: {e}")
        
        invalid_accounts = []  # è®°å½•æ— æ•ˆçš„è´¦å·
        valid_count = 0
        total_accounts = len(ACCOUNT_POOL.accounts)
        check_time = ensure_naive(get_beijing_time())  # è½¬æ¢ä¸º naive datetime ç”¨äºæ•°æ®åº“å­˜å‚¨
        
        # æ£€æŸ¥æ¯ä¸ªè´¦å·çš„ Cookie çŠ¶æ€
        for account in ACCOUNT_POOL.accounts:
            if not account.is_available():
                logger.debug(f"â­ï¸ è·³è¿‡ä¸å¯ç”¨è´¦å·: {account.name}")
                continue
            
            cookie_status = "unknown"
            error_msg = None
            expires_at = None
            
            try:
                # éªŒè¯ JWT æ˜¯å¦æœ‰æ•ˆ
                jwt = await account.jwt_mgr.get()
                if jwt:
                    cookie_status = "valid"
                    valid_count += 1
                    logger.debug(f"âœ… Cookie æœ‰æ•ˆ: {account.name}")
                    
                    # å°è¯•è·å– Cookie è¿‡æœŸæ—¶é—´ï¼ˆä»…ä»å“åº”å¤´è·å–ï¼Œä¸ä¼°ç®—ï¼‰
                    if hasattr(account, '_cookie_expires_at') and account._cookie_expires_at:
                        expires_at = account._cookie_expires_at
                else:
                    cookie_status = "unknown"
                    error_msg = "æ— æ³•è·å– JWT"
                    invalid_accounts.append(account.name)
                    logger.warning(f"âš ï¸ Cookie æ— æ•ˆ [{account.name}]: æ— æ³•è·å– JWT")
                        
            except HTTPException as e:
                error_msg = str(e.detail) if hasattr(e, 'detail') else str(e)
                if e.status_code in (401, 403):
                    # Cookie æ— æ•ˆ
                    if e.status_code == 401:
                        cookie_status = "expired"
                        error_msg = "Cookie å·²è¿‡æœŸ"
                    elif e.status_code == 403:
                        cookie_status = "forbidden"
                        error_msg = "Cookie æ— æ•ˆæˆ–è¢«ç¦æ­¢"
                    invalid_accounts.append(account.name)
                    logger.warning(f"âš ï¸ Cookie æ— æ•ˆ [{account.name}]: {e.status_code}")
                elif e.status_code == 429:
                    cookie_status = "rate_limited"
                    error_msg = "è¯·æ±‚è¿‡äºé¢‘ç¹"
                    logger.warning(f"âš ï¸ è¯·æ±‚è¿‡äºé¢‘ç¹ [{account.name}]")
            except Exception as e:
                error_msg = str(e)
                logger.warning(f"âš ï¸ æ£€æŸ¥å¼‚å¸¸ [{account.name}]: {str(e)}")
            
            # ä¿å­˜æ£€æŸ¥ç»“æœåˆ°æ•°æ®åº“
            try:
                account_status = db.query(AccountCookieStatus).filter(
                    AccountCookieStatus.account_name == account.name
                ).first()
                
                if account_status:
                    # æ›´æ–°ç°æœ‰è®°å½•
                    account_status.cookie_status = cookie_status
                    account_status.last_check_at = check_time
                    # åªæœ‰åœ¨ Cookie æœ‰æ•ˆæ—¶æ‰æ›´æ–°è¿‡æœŸæ—¶é—´ï¼Œé¿å…è¦†ç›–æœ‰æ•ˆçš„è¿‡æœŸæ—¶é—´
                    if cookie_status == "valid" and expires_at:
                        account_status.expires_at = expires_at
                    account_status.error_message = error_msg
                    account_status.updated_at = check_time
                else:
                    # åˆ›å»ºæ–°è®°å½•
                    account_status = AccountCookieStatus(
                        account_name=account.name,
                        cookie_status=cookie_status,
                        last_check_at=check_time,
                        expires_at=expires_at if cookie_status == "valid" else None,
                        error_message=error_msg
                    )
                    db.add(account_status)
            except Exception as e:
                logger.error(f"ä¿å­˜è´¦å· Cookie çŠ¶æ€å¤±è´¥ [{account.name}]: {e}")
        
        # æ‰¹é‡æäº¤æ‰€æœ‰è´¦å·çŠ¶æ€æ›´æ–°
        try:
            db.commit()
            logger.info(f"âœ… å·²ä¿å­˜ {total_accounts} ä¸ªè´¦å·çš„ Cookie çŠ¶æ€åˆ°æ•°æ®åº“ï¼ˆæœ€åæ£€æŸ¥æ—¶é—´: {check_time}ï¼‰")
        except Exception as e:
            logger.error(f"æ‰¹é‡ä¿å­˜ Cookie çŠ¶æ€å¤±è´¥: {e}")
            db.rollback()
        
        # å¦‚æœå¯ç”¨äº†è‡ªåŠ¨ä¿®å¤ï¼Œä¸”æ£€æµ‹åˆ°æ— æ•ˆè´¦å·ï¼Œåˆ™è°ƒç”¨æµè§ˆå™¨ä¿æ´»æ¥ä¿®å¤
        if invalid_accounts and getattr(task, 'auto_check_auto_fix', True):
            logger.info(f"ğŸ”§ æ£€æµ‹åˆ° {len(invalid_accounts)} ä¸ªæ— æ•ˆè´¦å·ï¼Œå¼€å§‹ä¿æ´»: {', '.join(invalid_accounts)}")
            try:
                # è°ƒç”¨æµè§ˆå™¨ä¿æ´»æ¥ä¿®å¤è¿™äº›è´¦å·
                await execute_keep_alive_task_for_accounts(invalid_accounts)
                logger.info(f"âœ… ä¿æ´»å®Œæˆ: {len(invalid_accounts)} ä¸ªè´¦å·")
            except Exception as e:
                logger.error(f"âŒ ä¿æ´»å¤±è´¥: {e}")
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task.last_auto_check_at = get_beijing_time()
        task.last_message = f"è‡ªåŠ¨æ£€æŸ¥å®Œæˆ: æœ‰æ•ˆ {valid_count}/{total_accounts}, æ— æ•ˆ {len(invalid_accounts)}"
        db.commit()
        
        logger.info(f"âœ… è‡ªåŠ¨æ£€æŸ¥ä»»åŠ¡å®Œæˆ: æœ‰æ•ˆ {valid_count}/{total_accounts}, æ— æ•ˆ {len(invalid_accounts)}")
        
    except Exception as e:
        logger.error(f"âŒ è‡ªåŠ¨æ£€æŸ¥ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        if task:
            task.last_message = f"è‡ªåŠ¨æ£€æŸ¥å¤±è´¥: {str(e)}"
            db.commit()
    finally:
        db.close()


async def execute_keep_alive_task():
    """æ‰§è¡Œä¿æ´»ä»»åŠ¡"""
    global current_keep_alive_process
    
    db = next(get_db())
    log_entry = None
    try:
        # è·å–ä¿æ´»ä»»åŠ¡é…ç½®
        task = db.query(KeepAliveTask).first()
        if not task:
            # å¦‚æœæ²¡æœ‰ä»»åŠ¡é…ç½®ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤çš„
            task = KeepAliveTask(
                is_enabled=True,
                schedule_time="00:00"
            )
            db.add(task)
            db.commit()
            db.refresh(task)
        
        if not task.is_enabled:
            logger.info("ä¿æ´»ä»»åŠ¡å·²ç¦ç”¨ï¼Œè·³è¿‡æ‰§è¡Œ")
            return
        
        logger.info("ğŸ”„ å¼€å§‹æ‰§è¡Œä¿æ´»ä»»åŠ¡...")
        
        # åœ¨å¼€å§‹æ‰§è¡Œå‰ï¼Œå…ˆé‡æ–°åŠ è½½ä¸€æ¬¡è´¦å·é…ç½®ï¼ˆä»¥é˜².envæ–‡ä»¶å·²è¢«éƒ¨åˆ†æ›´æ–°ï¼‰
        try:
            reload_accounts_from_env_file()
            logger.info("ğŸ”„ ä¿æ´»ä»»åŠ¡å¼€å§‹å‰å·²é‡æ–°åŠ è½½è´¦å·é…ç½®")
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿æ´»ä»»åŠ¡å¼€å§‹å‰é‡æ–°åŠ è½½è´¦å·é…ç½®å¤±è´¥: {e}")
        
        # åˆ›å»ºæ‰§è¡Œæ—¥å¿—
        log_entry = KeepAliveLog(
            task_id=task.id,
            started_at=get_beijing_time(),
            status="running"
        )
        db.add(log_entry)
        db.commit()
        db.refresh(log_entry)
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task.last_run_at = get_beijing_time()
        task.last_status = "running"
        task.last_message = "æ‰§è¡Œä¸­..."
        db.commit()
        
        try:
            # æ‰§è¡Œ keep_alive_env.py è„šæœ¬ï¼ˆä» .env æ–‡ä»¶è¯»å–è´¦å·ï¼‰
            script_path = os.path.join(BASE_DIR, "keep_alive_env.py")
            if not os.path.exists(script_path):
                raise FileNotFoundError(f"ä¿æ´»è„šæœ¬ä¸å­˜åœ¨: {script_path}")
            
            # ä½¿ç”¨ subprocess.Popen æ‰§è¡Œè„šæœ¬ï¼Œä»¥ä¾¿å¯ä»¥ä¸­æ–­
            async with keep_alive_process_lock:
                current_keep_alive_process = subprocess.Popen(
                    [sys.executable, "-u", script_path],  # -u å‚æ•°ç¡®ä¿æ— ç¼“å†²è¾“å‡º
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,  # å°† stderr åˆå¹¶åˆ° stdoutï¼Œç¡®ä¿é”™è¯¯ä¹Ÿèƒ½è¢«è¯»å–
                    text=True,
                    encoding='utf-8',  # æ˜ç¡®æŒ‡å®š UTF-8 ç¼–ç ï¼Œç¡®ä¿ Unicode å­—ç¬¦æ­£ç¡®æ˜¾ç¤º
                    errors='replace',  # é‡åˆ°ç¼–ç é”™è¯¯æ—¶æ›¿æ¢è€Œä¸æ˜¯æŠ¥é”™
                    cwd=BASE_DIR,
                    bufsize=0  # æ— ç¼“å†²
                )
            
            # å®æ—¶è¯»å–è¾“å‡ºå¹¶è§£æè´¦å·æ—¥å¿—
            output_lines = []
            account_logs_dict = {}  # å­˜å‚¨è´¦å·çº§åˆ«çš„æ—¥å¿— {account_name: account_log}
            account_index_to_log = {}  # å­˜å‚¨è´¦å·ç´¢å¼•åˆ°æ—¥å¿—çš„æ˜ å°„ {account_index: account_log}
            
            # åœ¨åå°è¯»å–è¾“å‡º
            async def read_output():
                nonlocal account_logs_dict, account_index_to_log
                try:
                    while True:
                        # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
                        if current_keep_alive_process.poll() is not None:
                            # è¿›ç¨‹å·²ç»“æŸï¼Œè¯»å–å‰©ä½™è¾“å‡º
                            remaining = await asyncio.to_thread(
                                lambda: current_keep_alive_process.stdout.read()
                            )
                            if remaining:
                                for line in remaining.strip().split('\n'):
                                    if line.strip():
                                        output_lines.append(line.strip())
                                        logger.info(f"ä¿æ´»è¾“å‡º: {line.strip()}")
                            break
                        
                        # è¯»å–ä¸€è¡Œè¾“å‡º
                        line = await asyncio.to_thread(
                            lambda: current_keep_alive_process.stdout.readline()
                        )
                        if not line:
                            await asyncio.sleep(0.1)  # çŸ­æš‚ç­‰å¾…
                            continue
                        
                        line = line.strip()
                        if line:
                            output_lines.append(line)
                            logger.info(f"ä¿æ´»è¾“å‡º: {line}")
                            
                            # è§£æè´¦å·çº§åˆ«çš„æ—¥å¿—ï¼šæ ¼å¼å¦‚ "[1/3] å¼€å§‹æ›´æ–°è´¦å·: user@example.com (user@example.com) - 2024-01-01 12:00:00"
                            # æˆ– "[1/3] æ›´æ–°æˆåŠŸè´¦å·: user@example.com (user@example.com) - 2024-01-01 12:00:00 (è€—æ—¶: 1åˆ†30ç§’)"
                            account_match = re.search(r'\[(\d+)/(\d+)\]\s*(å¼€å§‹æ›´æ–°|æ›´æ–°æˆåŠŸ|æ›´æ–°å¤±è´¥).*?è´¦å·:\s*([^(]+)(?:\(([^)]+)\))?', line)
                            if account_match:
                                account_index = account_match.group(1)
                                total_accounts = account_match.group(2)
                                action = account_match.group(3)
                                account_name = account_match.group(4).strip()
                                account_email = account_match.group(5).strip() if account_match.group(5) else extract_email_from_name(account_name)
                                
                                # å¦‚æœè´¦å·æ—¥å¿—å·²å­˜åœ¨ï¼Œæ›´æ–°çŠ¶æ€ï¼›å¦åˆ™åˆ›å»ºæ–°æ—¥å¿—
                                if account_name in account_logs_dict:
                                    account_log = account_logs_dict[account_name]
                                    if "æˆåŠŸ" in action:
                                        account_log.status = "success"
                                    elif "å¤±è´¥" in action:
                                        account_log.status = "error"
                                    account_log.finished_at = get_beijing_time()
                                    # ç´¯ç§¯æ‰€æœ‰æ—¥å¿—è¡Œåˆ° message ä¸­
                                    if account_log.message:
                                        account_log.message = account_log.message + "\n" + line
                                    else:
                                        account_log.message = line
                                else:
                                    # åˆ›å»ºè´¦å·æ—¥å¿—
                                    account_log = KeepAliveAccountLog(
                                        task_log_id=log_entry.id,
                                        account_name=account_name,
                                        account_email=account_email,
                                        started_at=get_beijing_time(),
                                        status="running" if "å¼€å§‹" in action else ("success" if "æˆåŠŸ" in action else "error"),
                                        message=line
                                    )
                                    account_logs_dict[account_name] = account_log
                                    account_index_to_log[int(account_index)] = account_log  # ä¿å­˜ç´¢å¼•æ˜ å°„
                                    db.add(account_log)
                                
                                db.commit()
                            else:
                                # å¦‚æœä¸æ˜¯è´¦å·çº§åˆ«çš„æ—¥å¿—ï¼Œå°è¯•å…³è”åˆ°å¯¹åº”çš„è´¦å·æ—¥å¿—
                                # æŸ¥æ‰¾åŒ…å«è´¦å·ç´¢å¼•çš„è¡Œï¼Œå¦‚ "[1/21] éœ€è¦éªŒè¯ç " æˆ– "[1/21] âœ… æ‰¾åˆ°éªŒè¯ç "
                                index_match = re.search(r'\[(\d+)/(\d+)\]', line)
                                if index_match:
                                    account_index = int(index_match.group(1))
                                    # é€šè¿‡è´¦å·ç´¢å¼•æ‰¾åˆ°å¯¹åº”çš„è´¦å·æ—¥å¿—
                                    if account_index in account_index_to_log:
                                        account_log = account_index_to_log[account_index]
                                        # ç´¯ç§¯æ—¥å¿—åˆ° message ä¸­
                                        if account_log.message:
                                            account_log.message = account_log.message + "\n" + line
                                        else:
                                            account_log.message = line
                                        db.commit()
                                    elif account_logs_dict:
                                        # å¦‚æœç´¢å¼•æ˜ å°„ä¸­æ²¡æœ‰ï¼Œä½¿ç”¨æœ€ååˆ›å»ºçš„è´¦å·æ—¥å¿—ï¼ˆå‘åå…¼å®¹ï¼‰
                                        last_account_log = max(account_logs_dict.values(), key=lambda x: x.started_at)
                                        if last_account_log:
                                            if last_account_log.message:
                                                last_account_log.message = last_account_log.message + "\n" + line
                                            else:
                                                last_account_log.message = line
                                            db.commit()
                except Exception as e:
                    logger.error(f"è¯»å–ä¿æ´»è¾“å‡ºå¼‚å¸¸: {e}")
            
            # å¯åŠ¨åå°è¯»å–ä»»åŠ¡
            read_task = asyncio.create_task(read_output())
            
            # ç­‰å¾…è¿›ç¨‹å®Œæˆæˆ–ä¸­æ–­
            try:
                returncode = await asyncio.wait_for(
                    asyncio.to_thread(current_keep_alive_process.wait),
                    timeout=3600  # 1å°æ—¶è¶…æ—¶
                )
            except asyncio.TimeoutError:
                # è¶…æ—¶ï¼Œç»ˆæ­¢è¿›ç¨‹
                current_keep_alive_process.terminate()
                try:
                    await asyncio.wait_for(
                        asyncio.to_thread(current_keep_alive_process.wait),
                        timeout=5
                    )
                except asyncio.TimeoutError:
                    current_keep_alive_process.kill()
                returncode = -1
                status = "error"
                message = "æ‰§è¡Œè¶…æ—¶ï¼ˆè¶…è¿‡1å°æ—¶ï¼‰"
            except Exception as e:
                returncode = -1
                status = "error"
                message = f"æ‰§è¡Œå¼‚å¸¸: {str(e)[:200]}"
            finally:
                # ç­‰å¾…è¯»å–ä»»åŠ¡å®Œæˆ
                try:
                    await asyncio.wait_for(read_task, timeout=2)
                except (asyncio.TimeoutError, asyncio.CancelledError):
                    read_task.cancel()
                    try:
                        await read_task
                    except:
                        pass
            
            # è¯»å–å‰©ä½™è¾“å‡ºï¼ˆç”±äº stderr å·²åˆå¹¶åˆ° stdoutï¼Œè¿™é‡Œåªéœ€è¦è¯»å– stdoutï¼‰
            stderr_content = ""
            try:
                # ç”±äº stderr å·²åˆå¹¶åˆ° stdoutï¼Œè¿™é‡Œä¸å†å•ç‹¬è¯»å– stderr
                # æ‰€æœ‰è¾“å‡ºï¼ˆåŒ…æ‹¬é”™è¯¯ï¼‰éƒ½å·²ç»åœ¨ read_output ä¸­è¯»å–äº†
                pass
            except Exception as e:
                logger.error(f"è¯»å–è¿›ç¨‹è¾“å‡ºå¤±è´¥: {e}")
                stderr_content = str(e)
            
            output = '\n'.join(output_lines)
            
            # æå–æ±‡æ€»ä¿¡æ¯ï¼ˆåŒ…å« "æ€»è´¦å·æ•°"ã€"æˆåŠŸ"ã€"å¤±è´¥"ã€"æˆåŠŸç‡"ã€"æ€»è€—æ—¶" ç­‰ï¼‰
            summary_lines = []
            for line in output_lines:
                if any(keyword in line for keyword in ["æ€»è´¦å·æ•°", "æˆåŠŸ:", "å¤±è´¥:", "æˆåŠŸç‡", "æ€»è€—æ—¶", "æ›´æ–°ç»Ÿè®¡", "=" * 10]):
                    summary_lines.append(line)
            summary_output = '\n'.join(summary_lines) if summary_lines else None
            
            # è§£æç»Ÿè®¡ä¿¡æ¯
            success_match = re.search(r'æˆåŠŸ:\s*(\d+)', output)
            fail_match = re.search(r'å¤±è´¥:\s*(\d+)', output)
            total_match = re.search(r'æ€»è´¦å·æ•°:\s*(\d+)', output)
            
            accounts_count = int(total_match.group(1)) if total_match else len(account_logs_dict)
            success_count = int(success_match.group(1)) if success_match else len([log for log in account_logs_dict.values() if log.status == "success"])
            fail_count = int(fail_match.group(1)) if fail_match else len([log for log in account_logs_dict.values() if log.status == "error"])
            
            if returncode == 0:
                status = "success"
                message = f"æˆåŠŸæ›´æ–° {success_count}/{accounts_count} ä¸ªè´¦å·"
                # å¦‚æœæœ‰æ±‡æ€»ä¿¡æ¯ï¼Œæ·»åŠ åˆ° message ä¸­
                if summary_output:
                    message = message + "\n\n" + summary_output
            else:
                status = "error"
                error_msg = stderr_content[:200] if stderr_content else output[-200:] if output else 'æœªçŸ¥é”™è¯¯'
                message = f"æ‰§è¡Œå¤±è´¥: {error_msg}"
                # å¦‚æœæœ‰æ±‡æ€»ä¿¡æ¯ï¼Œä¹Ÿæ·»åŠ åˆ° message ä¸­
                if summary_output:
                    message = message + "\n\n" + summary_output
            
            # æ›´æ–°æ‰€æœ‰è´¦å·æ—¥å¿—çš„ç»“æŸæ—¶é—´
            for acc_log in account_logs_dict.values():
                if acc_log.finished_at is None:
                    acc_log.finished_at = get_beijing_time()
                    if acc_log.status == "running":
                        acc_log.status = "error"
                        acc_log.message = (acc_log.message or "") + " (è¿›ç¨‹å¼‚å¸¸ç»“æŸ)"
                    db.commit()
            
            # æ›´æ–°æ—¥å¿—
            log_entry.finished_at = get_beijing_time()
            log_entry.status = status
            log_entry.message = message
            log_entry.accounts_count = accounts_count
            log_entry.success_count = success_count
            log_entry.fail_count = fail_count
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            task.last_status = status
            task.last_message = message
            task.updated_at = get_beijing_time()
            
            db.commit()
            db.close()
            
            # é‡æ–°åŠ è½½è´¦å·é…ç½®ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°çš„ csesidx ç­‰é…ç½®
            try:
                reload_accounts_from_env_file()
                logger.info("ğŸ”„ ä¿æ´»ä»»åŠ¡å®Œæˆåå·²é‡æ–°åŠ è½½è´¦å·é…ç½®")
            except Exception as e:
                logger.error(f"âŒ é‡æ–°åŠ è½½è´¦å·é…ç½®å¤±è´¥: {e}")
            
            logger.info(f"âœ… ä¿æ´»ä»»åŠ¡æ‰§è¡Œå®Œæˆ: {message}")
            
        except Exception as e:
            status = "error"
            message = f"æ‰§è¡Œå¼‚å¸¸: {str(e)[:200]}"
            if log_entry:
                log_entry.finished_at = get_beijing_time()
                log_entry.status = status
                log_entry.message = message
            task.last_status = status
            task.last_message = message
            db.commit()
            logger.error(f"âŒ ä¿æ´»ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
        finally:
            async with keep_alive_process_lock:
                current_keep_alive_process = None
            
    except Exception as e:
        logger.error(f"âŒ ä¿æ´»ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
    finally:
        db.close()


def setup_keep_alive_scheduler():
    """è®¾ç½®ä¿æ´»ä»»åŠ¡è°ƒåº¦å™¨"""
    db = next(get_db())
    try:
        # è·å–æˆ–åˆ›å»ºä¿æ´»ä»»åŠ¡é…ç½®
        task = db.query(KeepAliveTask).first()
        if not task:
            task = KeepAliveTask(
                is_enabled=True,
                schedule_time="00:00",
                api_keepalive_enabled=True,
                api_keepalive_interval=30
            )
            db.add(task)
            db.commit()
            db.refresh(task)
        
        # å¦‚æœä»»åŠ¡å·²å¯ç”¨ï¼Œæ·»åŠ å®šæ—¶ä»»åŠ¡
        if task.is_enabled:
            # è§£ææ—¶é—´ï¼ˆHH:MMæ ¼å¼ï¼‰
            hour, minute = map(int, task.schedule_time.split(":"))
            
            # æ·»åŠ æ¯æ—¥å®šæ—¶ä»»åŠ¡ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰
            scheduler.add_job(
                execute_keep_alive_task,
                trigger=CronTrigger(hour=hour, minute=minute, timezone=BEIJING_TZ),
                id="keep_alive_task",
                replace_existing=True
            )
            logger.info(f"âœ… ä¿æ´»ä»»åŠ¡å·²è®¾ç½®ï¼Œæ¯æ—¥ {task.schedule_time} (åŒ—äº¬æ—¶é—´) æ‰§è¡Œ")
        else:
            logger.info("â„¹ï¸ ä¿æ´»ä»»åŠ¡å·²ç¦ç”¨")
        
        # è®¾ç½®è‡ªåŠ¨æ£€æŸ¥è°ƒåº¦å™¨
        auto_check_enabled = getattr(task, 'auto_check_enabled', False)
        if auto_check_enabled:
            try:
                interval = getattr(task, 'auto_check_interval', 60)
                trigger = create_interval_trigger(interval, BEIJING_TZ)
                scheduler.add_job(
                    execute_auto_check_task,
                    trigger=trigger,
                    id="auto_check_task",
                    replace_existing=True
                )
                logger.info(f"âœ… è‡ªåŠ¨æ£€æŸ¥ä»»åŠ¡å·²è®¾ç½®ï¼Œæ¯ {interval} åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡")
            except Exception as e:
                logger.error(f"âŒ è®¾ç½®è‡ªåŠ¨æ£€æŸ¥è°ƒåº¦å™¨å¤±è´¥: {e}")
        else:
            logger.info("â„¹ï¸ è‡ªåŠ¨æ£€æŸ¥ä»»åŠ¡å·²ç¦ç”¨")
        
        # è®¾ç½® API ä¿æ´»è°ƒåº¦å™¨ï¼ˆä¸è‡ªåŠ¨æ£€æŸ¥ä½¿ç”¨ç›¸åŒçš„æ—¶é—´é—´éš”ï¼‰
        if getattr(task, 'api_keepalive_enabled', True):
            try:
                # å¦‚æœè‡ªåŠ¨æ£€æŸ¥å¯ç”¨ï¼Œä½¿ç”¨è‡ªåŠ¨æ£€æŸ¥çš„é—´éš”ï¼›å¦åˆ™ä½¿ç”¨ API ä¿æ´»è‡ªå·±çš„é—´éš”
                if auto_check_enabled:
                    interval = getattr(task, 'auto_check_interval', 60)
                    logger.info(f"âœ… Cookie æ£€æŸ¥ä»»åŠ¡å·²è®¾ç½®ï¼Œä¸è‡ªåŠ¨æ£€æŸ¥å…³è”ï¼Œæ¯ {interval} åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡")
                else:
                    interval = getattr(task, 'api_keepalive_interval', 30)
                    logger.info(f"âœ… Cookie æ£€æŸ¥ä»»åŠ¡å·²è®¾ç½®ï¼Œæ¯ {interval} åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡")
                
                trigger = create_interval_trigger(interval, BEIJING_TZ)
                scheduler.add_job(
                    execute_api_keepalive_task,
                    trigger=trigger,
                    id="api_keepalive_task",
                    replace_existing=True
                )
            except Exception as e:
                logger.error(f"âŒ è®¾ç½® Cookie æ£€æŸ¥è°ƒåº¦å™¨å¤±è´¥: {e}")
        else:
            logger.info("â„¹ï¸ Cookie æ£€æŸ¥ä»»åŠ¡å·²ç¦ç”¨")
            
    except Exception as e:
        logger.error(f"âŒ è®¾ç½®ä¿æ´»ä»»åŠ¡è°ƒåº¦å™¨å¤±è´¥: {e}")
    finally:
        db.close()


if __name__ == "__main__":
    # è‡³å°‘éœ€è¦æœ‰ä¸€ä¸ªè´¦å·é…ç½®
    if not ACCOUNTS:
        logger.error("No Gemini business accounts configured.")
        logger.error(
            "Set SECURE_C_SES/CSESIDX/CONFIG_ID or ACCOUNT1_* env variables first."
        )
        raise SystemExit(1)

    import uvicorn
    
    # è®¾ç½®ä¿¡å·å¤„ç†ï¼Œç¡®ä¿ Ctrl+C èƒ½å¿«é€Ÿå“åº”
    def signal_handler(signum, frame):
        """å¤„ç†ä¸­æ–­ä¿¡å·"""
        logger.info("\nğŸ›‘ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­æœåŠ¡...")
        # è®¾ç½®ä¸€ä¸ªæ ‡å¿—ï¼Œè®© uvicorn çŸ¥é“è¦å…³é—­
        import sys
        sys.exit(0)
    
    # æ³¨å†Œä¿¡å·å¤„ç†ï¼ˆWindows å’Œ Unix éƒ½æ”¯æŒï¼‰
    try:
        if hasattr(signal, 'SIGINT'):
            signal.signal(signal.SIGINT, signal_handler)
        if hasattr(signal, 'SIGTERM'):
            try:
                signal.signal(signal.SIGTERM, signal_handler)
            except (ValueError, OSError):
                # Windows ä¸Š SIGTERM å¯èƒ½ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯
                pass
    except Exception as e:
        logger.warning(f"âš ï¸ æ³¨å†Œä¿¡å·å¤„ç†å¤±è´¥: {e}")

    # ä½¿ç”¨ uvicorn è¿è¡Œï¼Œè®¾ç½®è¶…æ—¶å’Œä¼˜é›…å…³é—­
    uvicorn.run(
        "main:app", 
        host="0.0.0.0", 
        port=5000,
        reload=True,
        timeout_keep_alive=5,  # ä¿æŒè¿æ¥è¶…æ—¶
        timeout_graceful_shutdown=10  # ä¼˜é›…å…³é—­è¶…æ—¶ï¼ˆç§’ï¼‰
    )
